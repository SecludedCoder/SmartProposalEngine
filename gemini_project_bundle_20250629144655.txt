================================================================================
# ==============================================================================
# Project Code Bundle for LLM Context
# ==============================================================================
#
# This file contains information about a software project, generated by the
# 'bundle_project.py' script to provide context to a Large Language Model (LLM).
#
# Script Execution Directory: E:/Work-2025/ProjectPython/SmartProposalEngine
# Output Mode: 1 (Full Bundle)
#
# Content Details:
# - Complete scanned project structure (respecting directory exclusions).
#   - Filtered file structure (showing included files).
#   - Summary of filtering rules.
#   - Concatenated content of included files.
#
# Please use this content as a reference for understanding the project.
#
# Script Version: 1.3.0
# Generation Time: 2025-06-29 14:46:55 
# ==============================================================================

# Full Project Structure (Scan Results - Respects EXCLUDE_DIRS):
# SmartProposalEngine/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â””â”€â”€ logo.png
â”‚   â””â”€â”€ styles/
â”‚       â””â”€â”€ custom.css
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”œâ”€â”€ model_interface.py
â”‚   â”œâ”€â”€ prompt_manager.py
â”‚   â””â”€â”€ session_manager.py
â”œâ”€â”€ llm_providers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_provider.py
â”‚   â”œâ”€â”€ gemini_provider.py
â”‚   â””â”€â”€ qwen_provider.py
â”œâ”€â”€ output/
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 0_ğŸ”‘_Configuration.py
â”‚   â”œâ”€â”€ 1_ğŸ“„_Input_Processing.py
â”‚   â”œâ”€â”€ 2_ğŸ”_Deep_Analysis.py
â”‚   â”œâ”€â”€ 3_ğŸ“‹_Proposal_Generation.py
â”‚   â”œâ”€â”€ 4_ğŸš€_One_Click_Generation.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ business_negotiation.md
â”‚   â”‚   â”œâ”€â”€ customer_interview.md
â”‚   â”‚   â””â”€â”€ internal_meeting.md
â”‚   â”œâ”€â”€ proposal/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ project_proposal.md
â”‚   â”‚   â”œâ”€â”€ quotation_proposal.md
â”‚   â”‚   â””â”€â”€ solution_brief.md
â”‚   â”œâ”€â”€ transcription/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multi_speaker.md
â”‚   â”‚   â”œâ”€â”€ optimization.md
â”‚   â”‚   â””â”€â”€ single_speaker.md
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analysis_service.py
â”‚   â”œâ”€â”€ base_service.py
â”‚   â”œâ”€â”€ document_service.py
â”‚   â”œâ”€â”€ proposal_service.py
â”‚   â””â”€â”€ transcription_service.py
â”œâ”€â”€ tests/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”œâ”€â”€ format_utils.py
â”‚   â”œâ”€â”€ ui_utils.py
â”‚   â””â”€â”€ validation_utils.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py
â”œâ”€â”€ app_config.ini
â”œâ”€â”€ bundle_project.py
â”œâ”€â”€ env_example_file.sh
â”œâ”€â”€ models.conf
â”œâ”€â”€ README.md
â”œâ”€â”€ readme_file.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_app.py
â””â”€â”€ SmartProposal Engine å•†ä¸šåŒ–æ–¹æ¡ˆ.docx
# ============================================================

# Included File Structure (After Filtering):
# SmartProposalEngine/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”œâ”€â”€ model_interface.py
â”‚   â”œâ”€â”€ prompt_manager.py
â”‚   â””â”€â”€ session_manager.py
â”œâ”€â”€ llm_providers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_provider.py
â”‚   â”œâ”€â”€ gemini_provider.py
â”‚   â””â”€â”€ qwen_provider.py
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 0_ğŸ”‘_Configuration.py
â”‚   â”œâ”€â”€ 1_ğŸ“„_Input_Processing.py
â”‚   â”œâ”€â”€ 2_ğŸ”_Deep_Analysis.py
â”‚   â”œâ”€â”€ 3_ğŸ“‹_Proposal_Generation.py
â”‚   â”œâ”€â”€ 4_ğŸš€_One_Click_Generation.py
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ business_negotiation.md
â”‚   â”‚   â”œâ”€â”€ customer_interview.md
â”‚   â”‚   â””â”€â”€ internal_meeting.md
â”‚   â”œâ”€â”€ proposal/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ project_proposal.md
â”‚   â”‚   â”œâ”€â”€ quotation_proposal.md
â”‚   â”‚   â””â”€â”€ solution_brief.md
â”‚   â”œâ”€â”€ transcription/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multi_speaker.md
â”‚   â”‚   â”œâ”€â”€ optimization.md
â”‚   â”‚   â””â”€â”€ single_speaker.md
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analysis_service.py
â”‚   â”œâ”€â”€ base_service.py
â”‚   â”œâ”€â”€ document_service.py
â”‚   â”œâ”€â”€ proposal_service.py
â”‚   â””â”€â”€ transcription_service.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”œâ”€â”€ format_utils.py
â”‚   â”œâ”€â”€ ui_utils.py
â”‚   â””â”€â”€ validation_utils.py
â”œâ”€â”€ app.py
â”œâ”€â”€ app_config.ini
â”œâ”€â”€ env_example_file.sh
â”œâ”€â”€ models.conf
â”œâ”€â”€ README.md
â”œâ”€â”€ readme_file.md
â””â”€â”€ run_app.py
# ============================================================

# Bundle Configuration Summary:
# Root Directory: E:/Work-2025/ProjectPython/SmartProposalEngine
# Applied Filters (Exclusions first, then Inclusion Scope + Extension Filter):
# - Hardcoded Exclusions: ['bundle_project.py', 'gemini_project_bundle.txt']
# - Config Excluded Dirs: ['__pycache__', '.venv', 'venv', '.git', '.idea', 'build', 'dist', 'node_modules', 'logs', 'tests_output', 'htmlcov', '.pytest_cache', '.mypy_cache', '*.egg-info', '.tox', 'task', 'log', 'input_files', 'Chunking - Copy-ç¬¬ä¸€é˜¶æ®µå¤‡ä»½ï¼Œæš‚æ—¶ä¸åˆ ', 'database', 'scripts', 'docs', 'docs_usage', 'test', 'merged_table_descriptions', 'backup', 'data', 'export', 'temp_data', 'core_backup20250218', 'temp_data', 'docs_api', 'temp', 'dev_tools', 'docs', 'in use', 'output_files', 'record_files', 'temp_segments', 'input']
# - Config Excluded Files: ['.env', 'local_settings.py', '.DS_Store', 'Thumbs.db', 'åƒé‡Œå‘½ç¨¿.txt', 'project_context_for_llm.txt', 'scan_directory.py', 'merge_code.py', 'all_code.txt', 'api_key.txt', 'bundle_project.py', 'dir_struct_bazi_foundation.txt', 'gemini_project_bundle.txt']
# - Config Excluded Extensions: ['.pyc', '.log', '.tmp', '.bak', '.swp', '.swo', '.swn', '.coverage']
# - Inclusion Scope: All files not excluded by above rules.
# - Extension Filter: Files must match ['.py', '.yaml', '.yml', '.json', '.toml', '.ini', '.md', 'requirements.txt', 'Dockerfile', '.dockerignore', '.sh', '.bat', '.csv', '.conf']
# Note: The full project structure (respecting Excluded Dirs) was listed earlier.
# ============================================================


--- File: app.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/app.py
åŠŸèƒ½è¯´æ˜: SmartProposal Engineä¸»åº”ç”¨å…¥å£
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-29
ç‰ˆæœ¬: 1.1.0
"""

import os
import sys
import time
import streamlit as st
from pathlib import Path
import configparser
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from core.session_manager import SessionManager
from core.model_interface import ModelInterface
from utils.file_utils import ensure_directory_exists

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="SmartProposal Engine",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://github.com/smartproposal/engine',
        'Report a bug': 'https://github.com/smartproposal/engine/issues',
        'About': """
        # SmartProposal Engine

        æ™ºèƒ½å•†ä¸šæ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿ

        ç‰ˆæœ¬: 1.1.0
        """
    }
)


def load_custom_css():
    """åŠ è½½è‡ªå®šä¹‰CSSæ ·å¼"""
    css_file = Path(__file__).parent / "assets" / "styles" / "custom.css"
    if css_file.exists():
        #ã€ä¿®æ”¹ã€‘æ˜ç¡®æŒ‡å®šUTF-8ç¼–ç è¯»å–CSSæ–‡ä»¶
        with open(css_file, 'r', encoding='utf-8') as f:
            st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)
    else:
        # é»˜è®¤æ ·å¼
        st.markdown("""
        <style>
        /* ä¸»æ ‡é¢˜æ ·å¼ */
        .main-header {
            font-size: 2.5rem;
            font-weight: bold;
            color: #1f77b4;
            text-align: center;
            margin-bottom: 1rem;
            padding: 1rem 0;
            border-bottom: 3px solid #e0e0e0;
        }

        /* åŠŸèƒ½å¡ç‰‡æ ·å¼ */
        .feature-card {
            background-color: #f8f9fa;
            border-radius: 10px;
            padding: 1.5rem;
            margin-bottom: 1rem;
            border: 1px solid #e0e0e0;
            transition: all 0.3s ease;
        }

        .feature-card:hover {
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            transform: translateY(-2px);
        }

        /* ç»Ÿè®¡ä¿¡æ¯æ ·å¼ */
        .stat-card {
            background-color: #ffffff;
            border-radius: 8px;
            padding: 1rem;
            text-align: center;
            border: 1px solid #e0e0e0;
        }

        .stat-number {
            font-size: 2rem;
            font-weight: bold;
            color: #1f77b4;
        }

        .stat-label {
            font-size: 0.9rem;
            color: #666;
            margin-top: 0.5rem;
        }

        /* ä¾§è¾¹æ æ ·å¼ */
        .css-1d391kg {
            background-color: #f8f9fa;
        }

        /* æŒ‰é’®æ ·å¼å¢å¼º */
        .stButton > button {
            background-color: #1f77b4;
            color: white;
            border: none;
            padding: 0.5rem 2rem;
            border-radius: 5px;
            font-weight: bold;
            transition: all 0.3s ease;
        }

        .stButton > button:hover {
            background-color: #145a8b;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }

        /* æˆåŠŸæ¶ˆæ¯æ ·å¼ */
        .success-message {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 1rem;
            border-radius: 5px;
            margin: 1rem 0;
        }

        /* é”™è¯¯æ¶ˆæ¯æ ·å¼ */
        .error-message {
            background-color: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
            padding: 1rem;
            border-radius: 5px;
            margin: 1rem 0;
        }
        </style>
        """, unsafe_allow_html=True)


def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    # åˆå§‹åŒ–SessionManager
    if 'session_manager' not in st.session_state:
        st.session_state.session_manager = SessionManager()

    # åˆå§‹åŒ–å…¶ä»–ä¼šè¯å˜é‡
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.api_key_configured = False  # æ–°å¢ï¼šæ ‡è®°API Keyæ˜¯å¦å·²é…ç½®
        st.session_state.model_provider = None  # æ–°å¢ï¼šå­˜å‚¨é€‰æ‹©çš„æ¨¡å‹æä¾›å•†
        st.session_state.processing_history = []
        st.session_state.current_workflow = None
        st.session_state.last_activity = datetime.now()

    # åˆå§‹åŒ–æ¨¡å‹æ¥å£ï¼ˆä¸ç«‹å³è¿›è¡ŒAPI Keyé…ç½®ï¼‰
    if 'model_interface' not in st.session_state:
        try:
            st.session_state.model_interface = ModelInterface()
            # å¦‚æœä½¿ç”¨å†…éƒ¨keyï¼Œå®ƒåœ¨__init__ä¸­å·²ç»åˆå§‹åŒ–äº†
            if st.session_state.model_interface.is_initialized:
                st.session_state.api_key_configured = True
                st.session_state.model_provider = st.session_state.model_interface.provider
        except Exception as e:
            st.session_state.api_key_configured = False
            st.session_state.model_error = str(e)


def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        'temp',
        'output',
        'prompts/analysis',
        'prompts/proposal',
        'prompts/transcription'
    ]

    for directory in directories:
        ensure_directory_exists(directory)


def load_config():
    """åŠ è½½åº”ç”¨é…ç½®"""
    config_path = Path(__file__).parent / "app_config.ini"
    config = configparser.ConfigParser()

    if config_path.exists():
        # ã€ä¿®æ”¹ã€‘æ˜ç¡®æŒ‡å®šUTF-8ç¼–ç è¯»å–é…ç½®æ–‡ä»¶
        config.read(config_path, encoding='utf-8')
        st.session_state.config = config
    else:
        st.warning("é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        st.session_state.config = None


def show_initialization_page():
    """æ˜¾ç¤ºAPI Keyå’Œæ¨¡å‹æä¾›å•†è®¾ç½®é¡µé¢"""
    st.title("ğŸš€ æ¬¢è¿ä½¿ç”¨ SmartProposal Engine")
    st.header("è¯·å…ˆå®Œæˆç³»ç»Ÿè®¾ç½®")

    st.info("ä¸ºäº†ä½¿ç”¨æœ¬ç³»ç»Ÿçš„AIåŠŸèƒ½ï¼Œæ‚¨éœ€è¦æä¾›ä¸€ä¸ªæœ‰æ•ˆçš„API Keyã€‚")

    config = st.session_state.config
    providers_str = config.get('MODEL_PROVIDERS', 'available_providers', fallback='Gemini')
    providers = [p.strip() for p in providers_str.split(',')]
    default_provider = config.get('MODEL_PROVIDERS', 'default_provider', fallback='Gemini')

    col1, col2 = st.columns(2)
    with col1:
        selected_provider = st.selectbox(
            "1. é€‰æ‹©æ¨¡å‹æä¾›å•†",
            options=providers,
            index=providers.index(default_provider) if default_provider in providers else 0
        )

    with col2:
        api_key = st.text_input(
            "2. è¾“å…¥æ‚¨çš„API Key",
            type="password",
            help=f"è¯·è¾“å…¥ {selected_provider} çš„ API Key"
        )

    if st.button("ä¿å­˜å¹¶å¼€å§‹ä½¿ç”¨", type="primary", use_container_width=True):
        if not api_key:
            st.error("API Key ä¸èƒ½ä¸ºç©ºï¼")
        else:
            with st.spinner("æ­£åœ¨éªŒè¯å’Œåˆå§‹åŒ–æ¨¡å‹..."):
                try:
                    # è·å–æ¨¡å‹æ¥å£å®ä¾‹å¹¶è¿›è¡Œåˆå§‹åŒ–
                    model_interface = st.session_state.model_interface
                    model_interface.initialize_model(api_key, selected_provider)

                    # æ›´æ–°ä¼šè¯çŠ¶æ€
                    st.session_state.api_key_configured = True
                    st.session_state.model_provider = selected_provider

                    # è®¾ç½®é»˜è®¤æ¨¡å‹
                    for task in ['transcription', 'analysis', 'proposal']:
                        default_model_key = f'{task}_model'
                        if config.has_option('MODEL_SETTINGS', default_model_key):
                            default_model = config.get('MODEL_SETTINGS', default_model_key)
                            model_interface.set_model(task, default_model)

                    st.success("åˆå§‹åŒ–æˆåŠŸï¼ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªã€‚")
                    time.sleep(1)
                    st.rerun()

                except Exception as e:
                    st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
                    st.error("è¯·æ£€æŸ¥æ‚¨çš„API Keyå’Œç½‘ç»œè¿æ¥åé‡è¯•ã€‚")


def show_sidebar():
    """æ˜¾ç¤ºä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("## ğŸš€ SmartProposal Engine")
        st.markdown("---")

        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        if st.session_state.get('api_key_configured'):
            st.success(f"âœ… ç³»ç»Ÿå·²å°±ç»ª ({st.session_state.get('model_provider')})")
        else:
            st.error("âš ï¸ ç³»ç»Ÿæœªé…ç½®")

        st.markdown("---")

        # æ–°å¢ï¼šæ¨¡å‹é…ç½®éƒ¨åˆ†
        st.markdown("### âš™ï¸ æ¨¡å‹é…ç½®")
        model_interface = st.session_state.get('model_interface')
        provider = st.session_state.get('model_provider')

        if model_interface and provider:
            available_models = model_interface.get_available_models(provider)
            model_options = [m['api_name'] for m in available_models]

            def format_func(name):
                model_conf = model_interface.all_models.get(name)
                if model_conf:
                    return f"{model_conf.display_name} ({name.split('/')[-1]})"
                return name

            # è½¬å½•æ¨¡å‹
            current_trans_model = model_interface.get_model_name('transcription')
            trans_index = model_options.index(current_trans_model) if current_trans_model in model_options else 0
            selected_trans_model = st.selectbox(
                "è½¬å½•æ¨¡å‹",
                options=model_options,
                index=trans_index,
                format_func=format_func,
                key='transcription_model_selector'
            )
            model_interface.set_model('transcription', selected_trans_model)

            # åˆ†ææ¨¡å‹
            current_analysis_model = model_interface.get_model_name('analysis')
            analysis_index = model_options.index(
                current_analysis_model) if current_analysis_model in model_options else 0
            selected_analysis_model = st.selectbox(
                "åˆ†ææ¨¡å‹",
                options=model_options,
                index=analysis_index,
                format_func=format_func,
                key='analysis_model_selector'
            )
            model_interface.set_model('analysis', selected_analysis_model)

            # æ–¹æ¡ˆç”Ÿæˆæ¨¡å‹
            current_proposal_model = model_interface.get_model_name('proposal')
            proposal_index = model_options.index(
                current_proposal_model) if current_proposal_model in model_options else 0
            selected_proposal_model = st.selectbox(
                "æ–¹æ¡ˆæ¨¡å‹",
                options=model_options,
                index=proposal_index,
                format_func=format_func,
                key='proposal_model_selector'
            )
            model_interface.set_model('proposal', selected_proposal_model)
        else:
            st.caption("è¯·å…ˆå®Œæˆç³»ç»Ÿè®¾ç½®ä»¥é…ç½®æ¨¡å‹ã€‚")

        st.markdown("---")

        # åŠŸèƒ½å¯¼èˆªè¯´æ˜
        st.markdown("### ğŸ§­ åŠŸèƒ½å¯¼èˆª")
        st.info("""
        **1. ğŸ“¥ å†…å®¹è¾“å…¥**: ä¸Šä¼ éŸ³é¢‘æˆ–æ–‡æ¡£
        **2. ğŸ” æ·±åº¦åˆ†æ**: å•†ä¸šæ´å¯Ÿåˆ†æ
        **3. ğŸ“ æ–¹æ¡ˆç”Ÿæˆ**: ç”Ÿæˆä¸“ä¸šæ–¹æ¡ˆ
        **4. âœ¨ ä¸€é”®ç”Ÿæˆ**: ç«¯åˆ°ç«¯å¤„ç†
        """)

        st.markdown("---")

        # å¤„ç†ç»Ÿè®¡
        if 'processing_history' in st.session_state:
            st.markdown("### ğŸ“Š å¤„ç†ç»Ÿè®¡")
            total_processed = len(st.session_state.processing_history)
            st.metric("å·²å¤„ç†æ–‡ä»¶", total_processed)

        # ä¼šè¯ä¿¡æ¯
        if 'last_activity' in st.session_state:
            st.markdown("---")
            st.markdown("### â„¹ï¸ ä¼šè¯ä¿¡æ¯")
            st.text(f"æœ€åæ´»åŠ¨: {st.session_state.last_activity.strftime('%H:%M:%S')}")

        # ç³»ç»Ÿè®¾ç½®
        st.markdown("---")
        st.markdown("### ğŸ› ï¸ ç³»ç»Ÿæ“ä½œ")

        if st.button("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶"):
            session_manager = st.session_state.get('session_manager')
            if session_manager:
                session_manager.cleanup_all_temp_files()
                st.success("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")

        if st.button("ğŸ”„ é‡ç½®ä¼šè¯"):
            # ä¿ç•™å…³é”®é…ç½®ä¿¡æ¯
            api_configured = st.session_state.get('api_key_configured', False)
            provider = st.session_state.get('model_provider')
            model_if = st.session_state.get('model_interface')
            app_config = st.session_state.get('config')

            for key in list(st.session_state.keys()):
                del st.session_state[key]

            # æ¢å¤å…³é”®çŠ¶æ€
            st.session_state.api_key_configured = api_configured
            st.session_state.model_provider = provider
            st.session_state.model_interface = model_if
            st.session_state.config = app_config

            # é‡æ–°åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
            initialize_session_state()
            st.rerun()


def show_main_page():
    """æ˜¾ç¤ºä¸»é¡µé¢"""
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸš€ SmartProposal Engine</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666;">æ™ºèƒ½å•†ä¸šæ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿ</p>',
                unsafe_allow_html=True)

    st.markdown("---")

    # ç³»ç»Ÿä»‹ç»
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨SmartProposal Engine

        SmartProposal Engineæ˜¯ä¸€ä¸ªæ™ºèƒ½åŒ–çš„å•†ä¸šæ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿï¼Œèƒ½å¤Ÿå¸®åŠ©æ‚¨å¿«é€Ÿå°†åŸå§‹ä¿¡æ¯è½¬åŒ–ä¸ºä¸“ä¸šçš„å•†ä¸šæ–‡æ¡£ã€‚

        **æ ¸å¿ƒåŠŸèƒ½ï¼š**
        - ğŸ¤ **æ™ºèƒ½è½¬å½•**ï¼šæ”¯æŒéŸ³é¢‘æ–‡ä»¶çš„é«˜ç²¾åº¦è½¬å½•ï¼Œè¯†åˆ«å¤šè¯´è¯äººå¯¹è¯
        - ğŸ” **æ·±åº¦åˆ†æ**ï¼šåŸºäºAIçš„å•†ä¸šæ´å¯Ÿåˆ†æï¼Œæå–å…³é”®ä¿¡æ¯
        - ğŸ“ **æ–¹æ¡ˆç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”Ÿæˆä¸“ä¸šçš„é¡¹ç›®å»ºè®®ä¹¦å’Œå•†ä¸šæ–¹æ¡ˆ
        - âœ¨ **ç«¯åˆ°ç«¯å¤„ç†**ï¼šä¸€é”®å®Œæˆä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆæ–¹æ¡ˆçš„å…¨æµç¨‹

        **é€‚ç”¨åœºæ™¯ï¼š**
        - å®¢æˆ·è®¿è°ˆè®°å½•åˆ†æ
        - å•†åŠ¡è°ˆåˆ¤è¦ç‚¹æå–
        - å†…éƒ¨ä¼šè®®å†³ç­–æ•´ç†
        - éœ€æ±‚æ”¶é›†ä¸åˆ†æ
        - é¡¹ç›®æ–¹æ¡ˆå¿«é€Ÿç”Ÿæˆ
        """)

    with col2:
        # å¿«é€Ÿå¼€å§‹æŒ‡å—
        st.markdown("""
        ### âš¡ å¿«é€Ÿå¼€å§‹

        **æ­¥éª¤ 1**: é€‰æ‹©å·¦ä¾§å¯¼èˆªä¸­çš„åŠŸèƒ½æ¨¡å—

        **æ­¥éª¤ 2**: ä¸Šä¼ æ‚¨çš„éŸ³é¢‘æˆ–æ–‡æ¡£æ–‡ä»¶

        **æ­¥éª¤ 3**: é€‰æ‹©åˆé€‚çš„åˆ†ææ¨¡æ¿

        **æ­¥éª¤ 4**: è·å–AIç”Ÿæˆçš„ä¸“ä¸šæ–¹æ¡ˆ

        ---

        ğŸ’¡ **æç¤º**: é¦–æ¬¡ä½¿ç”¨å»ºè®®ä»"ä¸€é”®ç”Ÿæˆ"åŠŸèƒ½å¼€å§‹ï¼Œä½“éªŒå®Œæ•´æµç¨‹
        """)

    st.markdown("---")

    # åŠŸèƒ½å¡ç‰‡å±•ç¤º
    st.markdown("### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¨¡å—")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div class="feature-card">
        <h4>ğŸ“¥ å†…å®¹è¾“å…¥å¤„ç†</h4>
        <p>æ”¯æŒå¤šç§æ ¼å¼çš„å†…å®¹è¾“å…¥ï¼š</p>
        <ul>
        <li>éŸ³é¢‘æ–‡ä»¶ï¼šm4a, mp3, wavç­‰</li>
        <li>æ–‡æ¡£æ–‡ä»¶ï¼šdocx, pdf, txt</li>
        <li>æ–‡æœ¬ç›´æ¥è¾“å…¥</li>
        </ul>
        <p>æ™ºèƒ½è¯†åˆ«è¯´è¯äººï¼Œä¼˜åŒ–è½¬å½•è´¨é‡</p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div class="feature-card">
        <h4>ğŸ§  æ·±åº¦åˆ†æå¼•æ“</h4>
        <p>åŸºäºåœºæ™¯çš„æ™ºèƒ½åˆ†æï¼š</p>
        <ul>
        <li>å®¢æˆ·éœ€æ±‚æ´å¯Ÿ</li>
        <li>å•†åŠ¡è°ˆåˆ¤è¦ç‚¹</li>
        <li>ä¼šè®®å†³ç­–æå–</li>
        <li>è‡ªå®šä¹‰åˆ†ææ¨¡æ¿</li>
        </ul>
        <p>æä¾›ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š</p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="feature-card">
        <h4>ğŸ’¡ æ–¹æ¡ˆæ™ºèƒ½ç”Ÿæˆ</h4>
        <p>ä¸“ä¸šæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆï¼š</p>
        <ul>
        <li>é¡¹ç›®å»ºè®®ä¹¦</li>
        <li>å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆ</li>
        <li>è§£å†³æ–¹æ¡ˆç®€æŠ¥</li>
        <li>ä¼šè®®çºªè¦</li>
        </ul>
        <p>èåˆä¼ä¸šèƒ½åŠ›ï¼Œå®šåˆ¶åŒ–è¾“å‡º</p>
        </div>
        """, unsafe_allow_html=True)

        st.markdown("""
        <div class="feature-card">
        <h4>ğŸš€ ä¸€é”®å…¨æµç¨‹å¤„ç†</h4>
        <p>ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–å¤„ç†ï¼š</p>
        <ul>
        <li>æ‰¹é‡æ–‡ä»¶å¤„ç†</li>
        <li>è‡ªåŠ¨æµç¨‹ç¼–æ’</li>
        <li>è¿›åº¦å®æ—¶è·Ÿè¸ª</li>
        <li>ç»“æœæ‰¹é‡ä¸‹è½½</li>
        </ul>
        <p>å¤§å¹…æå‡å·¥ä½œæ•ˆç‡</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # ä½¿ç”¨ç»Ÿè®¡
    if 'processing_history' in st.session_state and st.session_state.processing_history:
        st.markdown("### ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown("""
            <div class="stat-card">
            <div class="stat-number">{}</div>
            <div class="stat-label">æ€»å¤„ç†æ•°</div>
            </div>
            """.format(len(st.session_state.processing_history)), unsafe_allow_html=True)

    # é¡µè„š
    st.markdown("---")
    st.markdown("""
    <p style="text-align: center; color: #888;">
    SmartProposal Engine v1.1.0 | 
    Powered by AI | 
    Â© 2025 SmartProposal Team
    </p>
    """, unsafe_allow_html=True)


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½è‡ªå®šä¹‰CSS
    load_custom_css()

    # åˆå§‹åŒ–
    load_config()
    initialize_session_state()
    create_directories()

    # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
    if st.session_state.get('initialized'):
        st.session_state.last_activity = datetime.now()

    # "å®ˆå«"é€»è¾‘ï¼šæ£€æŸ¥API Keyæ˜¯å¦å·²é…ç½®
    if not st.session_state.get('api_key_configured'):
        show_initialization_page()
    else:
        # å¦‚æœå·²é…ç½®ï¼Œæ˜¾ç¤ºæ­£å¸¸åº”ç”¨ç•Œé¢
        show_sidebar()
        show_main_page()


if __name__ == "__main__":
    main()

--- File: app_config.ini ---
# ==============================================================================
# File: app_config.ini (ä¿®æ”¹å)
# ==============================================================================
# SmartProposal Engine åº”ç”¨ç¨‹åºæ ¸å¿ƒé…ç½®æ–‡ä»¶
#
# æ­¤æ–‡ä»¶ç”¨äºé…ç½®åº”ç”¨çš„åŸºæœ¬è¡Œä¸ºã€åŠŸèƒ½å¼€å…³å’Œé»˜è®¤è®¾ç½®ã€‚
# ä¿®æ”¹æ­¤æ–‡ä»¶åï¼Œé€šå¸¸éœ€è¦é‡å¯åº”ç”¨æ‰èƒ½ç”Ÿæ•ˆã€‚

[API_SETTINGS]
# æ˜¯å¦ä½¿ç”¨å­˜å‚¨åœ¨æœ¬åœ°æ–‡ä»¶ä¸­çš„APIå¯†é’¥ã€‚
# å¦‚æœè®¾ç½®ä¸º trueï¼Œåº”ç”¨å°†å°è¯•ä» api_key_file æŒ‡å®šçš„æ–‡ä»¶ä¸­è¯»å–å¯†é’¥ã€‚
# å¦‚æœè®¾ç½®ä¸º falseï¼Œåº”ç”¨å°†è¦æ±‚ç”¨æˆ·åœ¨UIä¸­è¾“å…¥å¯†é’¥ã€‚
use_internal_api_key = false
# å½“ use_internal_api_key = true æ—¶ï¼Œä»æ­¤æ–‡ä»¶è¯»å–APIå¯†é’¥ã€‚
api_key_file = api_key.txt

[MODEL_PROVIDERS]
# å¯ç”¨çš„æ¨¡å‹æä¾›å•†åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ã€‚
# åº”ç”¨å¯åŠ¨æ—¶ä¼šè¯»å–æ­¤åˆ—è¡¨ï¼Œå¹¶åœ¨UIä¸­ä½œä¸ºé€‰é¡¹æä¾›ç»™ç”¨æˆ·ã€‚
# ã€ä¿®æ”¹ã€‘åœ¨è¿™é‡Œæ–°å¢äº† "Qwen"
available_providers = Gemini,Qwen
# ç”¨æˆ·é¦–æ¬¡æ‰“å¼€åº”ç”¨æˆ–é‡ç½®ä¼šè¯æ—¶ï¼Œé»˜è®¤é€‰æ‹©çš„æä¾›å•†ã€‚
default_provider = Gemini

[MODEL_SETTINGS]
# ä¸ºä¸åŒä»»åŠ¡è®¾ç½®é»˜è®¤çš„æ¨¡å‹ã€‚
# æ³¨æ„ï¼šè¿™äº›åªæ˜¯åˆå§‹é»˜è®¤å€¼ï¼Œç”¨æˆ·å¯ä»¥åœ¨UIä¾§è¾¹æ ä¸­éšæ—¶æ›´æ”¹ã€‚
# æ¨¡å‹åç§°å¿…é¡»ä¸ models.conf æ–‡ä»¶ä¸­å®šä¹‰çš„ model_api_name ä¸€è‡´ã€‚
transcription_model = models/gemini-2.5-flash
analysis_model = models/gemini-2.5-pro
proposal_model = models.gemini-2.5-pro

[FEATURE_SETTINGS]
# åŠŸèƒ½å¼€å…³ï¼Œç”¨äºå¯ç”¨æˆ–ç¦ç”¨åº”ç”¨çš„æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ã€‚
enable_deep_analysis = true
enable_proposal_generation = true
enable_custom_prompts = true
enable_batch_processing = true

[TEMPLATE_SETTINGS]
# é»˜è®¤æ¨¡æ¿è®¾ç½®ã€‚å½“ç”¨æˆ·æœªåšé€‰æ‹©æ—¶ï¼Œç³»ç»Ÿå°†ä½¿ç”¨è¿™äº›æ¨¡æ¿ã€‚
# æ¨¡æ¿åç§°åº”ä¸ prompts/ ç›®å½•ä¸‹ç›¸åº”å­ç›®å½•ä¸­çš„æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰å¯¹åº”ã€‚
default_analysis_template = customer_interview
default_proposal_template = project_proposal
# å­˜å‚¨Promptæ¨¡æ¿çš„æ ¹ç›®å½•ã€‚
template_directory = prompts/

[FILE_SETTINGS]
# æ–‡ä»¶ä¸Šä¼ ç›¸å…³çš„é™åˆ¶å’Œç›®å½•é…ç½®ã€‚
max_file_size_mb = 200
# å…è®¸ä¸Šä¼ çš„éŸ³é¢‘å’Œæ–‡æ¡£æ–‡ä»¶æ ¼å¼ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸å¸¦ç‚¹ã€‚
allowed_audio_formats = m4a,mp3,wav,aac,ogg,flac
allowed_document_formats = docx,pdf,txt
# å­˜å‚¨ä¸´æ—¶æ–‡ä»¶çš„ç›®å½•ã€‚
temp_directory = temp/
# å­˜å‚¨æœ€ç»ˆè¾“å‡ºæ–‡ä»¶çš„ç›®å½•ã€‚
output_directory = output/

--- File: core/__init__.py ---

--- File: core/document_processor.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/document_processor.py
åŠŸèƒ½è¯´æ˜: æ–‡æ¡£å¤„ç†å™¨ï¼Œè´Ÿè´£åè°ƒå„ç§æ–‡æ¡£å’ŒéŸ³é¢‘å¤„ç†æœåŠ¡
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
from typing import Dict, List, Optional, Union, Tuple, Any
from pathlib import Path
from datetime import datetime
import mimetypes

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.base_service import ProcessingResult
from services.transcription_service import TranscriptionService
from services.document_service import DocumentService
from utils.file_utils import get_file_type, get_file_extension, validate_file_size
from utils.validation_utils import validate_file_type


class DocumentProcessor:
    """
    æ–‡æ¡£å¤„ç†å™¨

    ä¸»è¦åŠŸèƒ½:
    1. ç»Ÿä¸€çš„æ–‡ä»¶å¤„ç†æ¥å£
    2. è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶ç±»å‹å¹¶è°ƒç”¨ç›¸åº”æœåŠ¡
    3. æ”¯æŒéŸ³é¢‘å’Œæ–‡æ¡£çš„ç»Ÿä¸€å¤„ç†
    4. æ‰¹é‡æ–‡ä»¶å¤„ç†æ”¯æŒ

    ä½¿ç”¨ç¤ºä¾‹:
        processor = DocumentProcessor()
        result = processor.process_file(file_path, options)
    """

    def __init__(self):
        """åˆå§‹åŒ–æ–‡æ¡£å¤„ç†å™¨"""
        self.transcription_service = TranscriptionService()
        self.document_service = DocumentService()
        self.supported_types = self._get_supported_types()

    def _get_supported_types(self) -> Dict[str, List[str]]:
        """è·å–æ”¯æŒçš„æ–‡ä»¶ç±»å‹"""
        return {
            'audio': ['.m4a', '.mp3', '.wav', '.aac', '.ogg', '.flac', '.mp4'],
            'document': ['.docx', '.pdf', '.txt', '.doc', '.rtf', '.odt']
        }

    def process_file(self,
                     file_path: Union[str, Path],
                     options: Optional[Dict] = None) -> ProcessingResult:
        """
        å¤„ç†å•ä¸ªæ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            options: å¤„ç†é€‰é¡¹
                - max_file_size_mb: æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶
                - enable_text_optimization: æ˜¯å¦å¯ç”¨æ–‡æœ¬ä¼˜åŒ–ï¼ˆéŸ³é¢‘ï¼‰
                - extract_metadata: æ˜¯å¦æå–å…ƒæ•°æ®ï¼ˆæ–‡æ¡£ï¼‰
                - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        options = options or {}
        progress_callback = options.get('progress_callback')

        try:
            # éªŒè¯æ–‡ä»¶
            file_path = Path(file_path)
            if not file_path.exists():
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

            # éªŒè¯æ–‡ä»¶å¤§å°
            max_size_mb = options.get('max_file_size_mb', 200)
            is_valid_size, size_msg = validate_file_size(file_path, max_size_mb)
            if not is_valid_size:
                raise ValueError(size_msg)

            # è·å–æ–‡ä»¶ç±»å‹
            file_type = get_file_type(file_path)
            file_ext = get_file_extension(file_path)

            if progress_callback:
                progress_callback(f"æ­£åœ¨å¤„ç† {file_type} æ–‡ä»¶: {file_path.name}")

            # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ç›¸åº”æœåŠ¡
            if file_type == 'audio':
                # éŸ³é¢‘æ–‡ä»¶ä½¿ç”¨è½¬å½•æœåŠ¡
                result = self.transcription_service.process(
                    file_path,
                    options=options
                )
            elif file_type == 'document':
                # æ–‡æ¡£æ–‡ä»¶ä½¿ç”¨æ–‡æ¡£æœåŠ¡
                result = self.document_service.process(
                    file_path,
                    options=options
                )
            else:
                # å°è¯•ä½œä¸ºæ–‡æœ¬æ–‡æ¡£å¤„ç†
                if progress_callback:
                    progress_callback(f"æœªçŸ¥æ–‡ä»¶ç±»å‹ {file_ext}ï¼Œå°è¯•ä½œä¸ºæ–‡æœ¬å¤„ç†")

                result = self.document_service.process(
                    file_path,
                    options=options
                )

            # æ·»åŠ å¤„ç†å™¨ä¿¡æ¯åˆ°å…ƒæ•°æ®
            result.metadata['processor'] = 'DocumentProcessor'
            result.metadata['file_type_detected'] = file_type

            return result

        except Exception as e:
            if progress_callback:
                progress_callback(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

            return ProcessingResult(
                content='',
                metadata={
                    'error': str(e),
                    'file_path': str(file_path),
                    'processor': 'DocumentProcessor'
                },
                source_type='unknown',
                processing_time=0,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )

    def process_text_input(self,
                           text: str,
                           input_type: str = 'text',
                           options: Optional[Dict] = None) -> ProcessingResult:
        """
        å¤„ç†æ–‡æœ¬è¾“å…¥

        Args:
            text: è¾“å…¥æ–‡æœ¬
            input_type: è¾“å…¥ç±»å‹ ('text', 'transcript')
            options: å¤„ç†é€‰é¡¹

        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        options = options or {}

        try:
            # å¦‚æœæ˜¯è½¬å½•æ–‡æœ¬ä¸”éœ€è¦ä¼˜åŒ–
            if input_type == 'transcript' and options.get('enable_text_optimization', False):
                result = self.transcription_service.process_web_text(text, options)
            else:
                # ç›´æ¥è¿”å›æ–‡æœ¬ä½œä¸ºç»“æœ
                result = ProcessingResult(
                    content=text,
                    metadata={
                        'input_type': input_type,
                        'text_length': len(text),
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    },
                    source_type='text',
                    processing_time=0,
                    model_used='',
                    tokens_consumed={}
                )

            return result

        except Exception as e:
            return ProcessingResult(
                content=text,
                metadata={'error': str(e)},
                source_type='text',
                processing_time=0,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )

    def batch_process_files(self,
                            file_paths: List[Union[str, Path]],
                            options: Optional[Dict] = None) -> List[ProcessingResult]:
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶

        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            options: å¤„ç†é€‰é¡¹

        Returns:
            List[ProcessingResult]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        options = options or {}
        results = []
        progress_callback = options.get('progress_callback')

        total_files = len(file_paths)

        for i, file_path in enumerate(file_paths):
            if progress_callback:
                progress_callback(f"å¤„ç†æ–‡ä»¶ {i + 1}/{total_files}")

            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºç‹¬ç«‹çš„é€‰é¡¹
            file_options = options.copy()
            file_options['file_index'] = i
            file_options['total_files'] = total_files

            result = self.process_file(file_path, file_options)
            results.append(result)

        return results

    def get_file_info(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """
        è·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆä¸å¤„ç†æ–‡ä»¶ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            Dict: æ–‡ä»¶ä¿¡æ¯
        """
        file_path = Path(file_path)

        if not file_path.exists():
            return {'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}

        file_type = get_file_type(file_path)
        file_ext = get_file_extension(file_path)
        file_size = file_path.stat().st_size

        info = {
            'name': file_path.name,
            'path': str(file_path.absolute()),
            'type': file_type,
            'extension': file_ext,
            'size_bytes': file_size,
            'size_formatted': f"{file_size / (1024 * 1024):.2f} MB",
            'mime_type': mimetypes.guess_type(str(file_path))[0] or 'unknown',
            'created': datetime.fromtimestamp(file_path.stat().st_ctime).strftime('%Y-%m-%d %H:%M:%S'),
            'modified': datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
        }

        # éŸ³é¢‘æ–‡ä»¶ç‰¹æœ‰ä¿¡æ¯
        if file_type == 'audio':
            from utils.file_utils import get_audio_duration
            duration = get_audio_duration(file_path)
            if duration:
                info['duration_seconds'] = duration
                info['duration_formatted'] = f"{int(duration // 60)}:{int(duration % 60):02d}"

        return info

    def validate_file(self,
                      file_path: Union[str, Path],
                      file_type_required: Optional[str] = None) -> Tuple[bool, str]:
        """
        éªŒè¯æ–‡ä»¶æ˜¯å¦å¯ä»¥å¤„ç†

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            file_type_required: è¦æ±‚çš„æ–‡ä»¶ç±»å‹ ('audio', 'document', Noneè¡¨ç¤ºä»»æ„)

        Returns:
            (is_valid, message): éªŒè¯ç»“æœ
        """
        file_path = Path(file_path)

        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        if not file_path.exists():
            return False, "æ–‡ä»¶ä¸å­˜åœ¨"

        # æ£€æŸ¥æ–‡ä»¶ç±»å‹
        file_type = get_file_type(file_path)
        file_ext = get_file_extension(file_path)

        if file_type_required:
            if file_type != file_type_required:
                return False, f"æ–‡ä»¶ç±»å‹ä¸åŒ¹é…ï¼Œéœ€è¦ {file_type_required}ï¼Œå®é™…ä¸º {file_type}"

        # æ£€æŸ¥æ˜¯å¦æ”¯æŒè¯¥æ ¼å¼
        supported = False
        for ftype, extensions in self.supported_types.items():
            if file_ext in extensions:
                supported = True
                break

        if not supported:
            return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}"

        return True, f"æ–‡ä»¶æœ‰æ•ˆ: {file_type} ({file_ext})"

    def get_supported_formats(self) -> Dict[str, List[str]]:
        """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
        return self.supported_types.copy()

    def estimate_processing_time(self,
                                 file_path: Union[str, Path]) -> Optional[int]:
        """
        ä¼°ç®—å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            int: ä¼°ç®—çš„å¤„ç†æ—¶é—´ï¼ˆç§’ï¼‰
        """
        file_path = Path(file_path)
        if not file_path.exists():
            return None

        file_type = get_file_type(file_path)
        file_size_mb = file_path.stat().st_size / (1024 * 1024)

        # åŸºäºæ–‡ä»¶ç±»å‹å’Œå¤§å°çš„ç®€å•ä¼°ç®—
        if file_type == 'audio':
            # éŸ³é¢‘æ–‡ä»¶ï¼šè€ƒè™‘æ—¶é•¿
            from utils.file_utils import get_audio_duration
            duration = get_audio_duration(file_path)
            if duration:
                # å¤§çº¦æ¯åˆ†é’ŸéŸ³é¢‘éœ€è¦10ç§’å¤„ç†æ—¶é—´
                return int(duration / 60 * 10)
            else:
                # åŸºäºæ–‡ä»¶å¤§å°ä¼°ç®—
                return int(file_size_mb * 5)

        elif file_type == 'document':
            # æ–‡æ¡£æ–‡ä»¶ï¼šåŸºäºå¤§å°
            # å¤§çº¦æ¯MBéœ€è¦2ç§’å¤„ç†æ—¶é—´
            return int(file_size_mb * 2)

        else:
            # æœªçŸ¥ç±»å‹ï¼šä¿å®ˆä¼°ç®—
            return int(file_size_mb * 3)

--- File: core/model_interface.py ---
# ==============================================================================
# File: core/model_interface.py (ä¿®æ”¹å)
# ==============================================================================
# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/model_interface.py
åŠŸèƒ½è¯´æ˜: ç»Ÿä¸€çš„AIæ¨¡å‹æ¥å£ï¼Œé€šè¿‡è°ƒåº¦ä¸åŒçš„Providerï¼Œå°è£…å¤šæä¾›å•†ï¼ˆå¦‚Gemini, Qwenï¼‰çš„APIè°ƒç”¨ã€‚
          æ­¤ç±»ä½œä¸ºæ¨¡å‹è°ƒç”¨çš„ç»Ÿä¸€å…¥å£ï¼ˆFacade Patternï¼‰ã€‚
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-29
ç‰ˆæœ¬: 1.2.0
"""

import os
import sys
import time
import configparser
from typing import Dict, List, Optional, Tuple, Union, Any
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ã€ä¿®æ”¹ã€‘å¯¼å…¥æ–°çš„Providerç±»ï¼Œä¸å†ç›´æ¥å¯¼å…¥ä»»ä½•å…·ä½“SDK
from .llm_providers.base_provider import BaseProvider
from .llm_providers.gemini_provider import GeminiProvider
from .llm_providers.qwen_provider import QwenProvider


class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»ï¼ˆä¿æŒä¸å˜ï¼‰"""

    def __init__(self, provider: str, api_name: str, display_name: str,
                 input_price: float, output_price: float):
        self.provider = provider
        self.api_name = api_name
        self.display_name = display_name
        self.input_price_per_million = input_price
        self.output_price_per_million = output_price

    def calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """è®¡ç®—ä½¿ç”¨æˆæœ¬ï¼ˆç¾å…ƒï¼‰"""
        input_cost = (input_tokens / 1_000_000) * self.input_price_per_million
        output_cost = (output_tokens / 1_000_000) * self.output_price_per_million
        return input_cost + output_cost


class ModelInterface:
    """
    ç»Ÿä¸€çš„AIæ¨¡å‹æ¥å£

    ä¸»è¦åŠŸèƒ½:
    1. æ”¯æŒå¤šæ¨¡å‹æä¾›å•† (Gemini, Qwenç­‰)ã€‚
    2. ç»Ÿä¸€çš„æ¨¡å‹è°ƒç”¨æ¥å£ã€‚
    3. è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†ã€‚
    4. Tokenä½¿ç”¨é‡ç»Ÿè®¡å’Œè´¹ç”¨è®¡ç®—ã€‚
    5. æ¨¡å‹åŠ¨æ€é…ç½®å’Œåˆ‡æ¢ã€‚
    """

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹æ¥å£ã€‚
        """
        self.all_models: Dict[str, ModelConfig] = {}
        self.current_models: Dict[str, str] = {}
        self.api_key: Optional[str] = None
        self.provider: Optional[str] = None
        # ã€æ–°å¢ã€‘æŒæœ‰å…·ä½“çš„providerå®ä¾‹
        self.provider_client: Optional[BaseProvider] = None
        self.is_initialized = False

        self._load_config(config_path)
        self._load_model_config()

        if self.config.getboolean('API_SETTINGS', 'use_internal_api_key', fallback=False):
            api_key_file = self.config.get('API_SETTINGS', 'api_key_file', fallback='api_key.txt')
            project_root = Path(__file__).parent.parent
            api_key_path = project_root / api_key_file

            if api_key_path.exists():
                with open(api_key_path, 'r', encoding='utf-8') as f:
                    internal_api_key = f.read().strip()
                if internal_api_key:
                    default_provider = self.config.get('MODEL_PROVIDERS', 'default_provider', fallback='Gemini')
                    try:
                        self.initialize_model(internal_api_key, default_provider)
                    except Exception as e:
                        print(f"è­¦å‘Šï¼šä½¿ç”¨å†…éƒ¨å¯†é’¥åˆå§‹åŒ–å¤±è´¥: {e}")

    def initialize_model(self, api_key: str, provider: str):
        """
        ã€å·²é‡æ„ã€‘ä½¿ç”¨API Keyå’Œæä¾›å•†æ¥åˆå§‹åŒ–æ¨¡å‹ã€‚
        """
        if not api_key or not provider:
            self.is_initialized = False
            raise ValueError("API Keyå’Œæ¨¡å‹æä¾›å•†ä¸èƒ½ä¸ºç©º")

        self.api_key = api_key
        self.provider = provider

        try:
            # æ ¹æ®æä¾›å•†é€‰æ‹©ä¸åŒçš„åˆå§‹åŒ–é€»è¾‘ï¼ˆå·¥å‚æ¨¡å¼ï¼‰
            if self.provider == 'Gemini':
                self.provider_client = GeminiProvider(self.api_key)
            elif self.provider == 'Qwen':
                self.provider_client = QwenProvider(self.api_key)
            else:
                raise NotImplementedError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {self.provider}")

            # è°ƒç”¨å…·ä½“providerçš„åˆå§‹åŒ–æ–¹æ³•
            self.provider_client.initialize()
            self.is_initialized = True
            print(f"âœ… ModelInterface å·²ä½¿ç”¨ {self.provider} æä¾›å•†æˆåŠŸåˆå§‹åŒ–ã€‚")

        except Exception as e:
            self.is_initialized = False
            self.provider_client = None
            print(f"âŒ æ¨¡å‹æ¥å£åˆå§‹åŒ–å¤±è´¥: {e}")
            raise ConnectionError(f"æ— æ³•ä½¿ç”¨æä¾›çš„API Keyè¿æ¥åˆ° {self.provider}ã€‚è¯·æ£€æŸ¥Keyæ˜¯å¦æ­£ç¡®ä»¥åŠç½‘ç»œè¿æ¥ã€‚")

    def _load_config(self, config_path: Optional[str] = None):
        """åŠ è½½åº”ç”¨é…ç½®ï¼ˆä¿æŒä¸å˜ï¼‰"""
        if config_path is None:
            config_path = os.path.join(
                os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                'app_config.ini'
            )
        self.config = configparser.ConfigParser()
        self.config.read(config_path, encoding='utf-8')
        self.current_models = {
            'transcription': self.config.get('MODEL_SETTINGS', 'transcription_model', fallback=''),
            'analysis': self.config.get('MODEL_SETTINGS', 'analysis_model', fallback=''),
            'proposal': self.config.get('MODEL_SETTINGS', 'proposal_model', fallback=''),
            'optimization': self.config.get('MODEL_SETTINGS', 'optimization_model', fallback='')
        }

    def _load_model_config(self):
        """ä»models.confåŠ è½½æ‰€æœ‰æ¨¡å‹é…ç½®ï¼ˆä¿æŒä¸å˜ï¼‰"""
        models_conf_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
            'models.conf'
        )
        if not os.path.exists(models_conf_path):
            return
        with open(models_conf_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                parts = [part.strip() for part in line.split(',')]
                if len(parts) >= 5:
                    provider, api_name, display_name, input_price, output_price = parts[0], parts[1], parts[2], float(
                        parts[3]), float(parts[4])
                    self.all_models[api_name] = ModelConfig(provider, api_name, display_name, input_price, output_price)

    def get_model_name(self, model_type: str) -> str:
        """è·å–æŒ‡å®šç±»å‹çš„æ¨¡å‹åç§°ï¼ˆä¿æŒä¸å˜ï¼‰"""
        return self.current_models.get(model_type, '')

    def set_model(self, model_type: str, model_name: str) -> bool:
        """è®¾ç½®ç‰¹å®šç±»å‹ä½¿ç”¨çš„æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰"""
        if model_name in self.all_models:
            self.current_models[model_type] = model_name
            return True
        return False

    def get_available_models(self, provider: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨ï¼Œå¯æŒ‰æä¾›å•†è¿‡æ»¤ï¼ˆä¿æŒä¸å˜ï¼‰"""
        provider_to_check = provider or self.provider
        if not provider_to_check:
            return []
        available = []
        for model in self.all_models.values():
            if model.provider.lower() == provider_to_check.lower():
                available.append({'api_name': model.api_name, 'display_name': model.display_name})
        return available

    def generate_content(self,
                         prompt: Union[str, List],
                         model_type: str = 'analysis',
                         generation_config: Optional[Dict] = None,
                         safety_settings: Optional[List] = None,
                         request_options: Optional[Dict] = None) -> Tuple[str, Dict[str, Any]]:
        """
        ã€å·²é‡æ„ã€‘ç”Ÿæˆå†…å®¹çš„ç»Ÿä¸€æ¥å£ï¼Œå°†è°ƒç”¨å§”æ‰˜ç»™å…·ä½“çš„Providerã€‚
        """
        if not self.is_initialized or not self.provider_client:
            raise RuntimeError("ModelInterfaceæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·åœ¨ä¸»é¡µé¢è®¾ç½®APIå¯†é’¥ã€‚")

        model_name = self.get_model_name(model_type)
        if not model_name:
            raise ValueError(f"æœªç»™ä»»åŠ¡ç±»å‹ '{model_type}' é…ç½®æ¨¡å‹ã€‚è¯·åœ¨ä¾§è¾¹æ è®¾ç½®ã€‚")

        start_time = time.time()

        # å°†è°ƒç”¨å§”æ‰˜ç»™å…·ä½“çš„providerå®¢æˆ·ç«¯
        response_text, stats = self.provider_client.generate(
            prompt=prompt,
            model_name=model_name,
            generation_config=generation_config,
            safety_settings=safety_settings,
            request_options=request_options
        )

        end_time = time.time()
        cost = self.calculate_cost(stats.get('input_tokens', 0), stats.get('output_tokens', 0), model_type)

        # ç»„è£…æœ€ç»ˆçš„ã€ç»Ÿä¸€æ ¼å¼çš„ç»Ÿè®¡æ•°æ®
        final_stats = {
            'model_used': model_name,
            'input_tokens': stats.get('input_tokens', 0),
            'output_tokens': stats.get('output_tokens', 0),
            'total_tokens': stats.get('input_tokens', 0) + stats.get('output_tokens', 0),
            'estimated_cost': cost,
            'generation_time': end_time - start_time,
            'model_type': model_type
        }

        return response_text, final_stats

    def calculate_cost(self, input_tokens: int, output_tokens: int, model_type: str) -> float:
        """è®¡ç®—APIè°ƒç”¨æˆæœ¬ï¼ˆä¿æŒä¸å˜ï¼‰"""
        model_name = self.get_model_name(model_type)
        model_config = self.all_models.get(model_name)
        if model_config:
            return model_config.calculate_cost(input_tokens, output_tokens)
        return 0.0

    def count_tokens(self, text: str, model_type: str = 'analysis') -> int:
        """ã€å·²é‡æ„ã€‘ç²¾ç¡®è®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼Œå§”æ‰˜ç»™Providerã€‚"""
        if not self.is_initialized or not self.provider_client:
            return self._estimate_tokens(text)

        try:
            model_name = self.get_model_name(model_type)
            return self.provider_client.count_tokens(text, model_name)
        except Exception as e:
            print(f"Tokenè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—å€¼: {e}")
            return self._estimate_tokens(text)

    def _estimate_tokens(self, text: Union[str, Any]) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡ï¼ˆé€šç”¨åå¤‡æ–¹æ³•ï¼Œä¿æŒä¸å˜ï¼‰"""
        if not isinstance(text, str):
            text = str(text)
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        other_chars = len(text) - chinese_chars
        estimated_tokens = chinese_chars + (other_chars * 0.5)
        return int(estimated_tokens)

    def stream_generate_content(self,
                                prompt: Union[str, List],
                                model_type: str = 'analysis',
                                generation_config: Optional[Dict] = None,
                                callback=None) -> Tuple[str, Dict[str, Any]]:
        """ã€å·²é‡æ„ã€‘æµå¼ç”Ÿæˆå†…å®¹ï¼Œå§”æ‰˜ç»™Providerã€‚"""
        if not self.is_initialized or not self.provider_client:
            raise RuntimeError("ModelInterfaceæœªæ­£ç¡®åˆå§‹åŒ–")

        start_time = time.time()
        model_name = self.get_model_name(model_type)

        complete_response, stats = self.provider_client.stream_generate(
            prompt, model_name, generation_config, callback
        )

        end_time = time.time()
        cost = self.calculate_cost(stats.get('input_tokens', 0), stats.get('output_tokens', 0), model_type)

        final_stats = {
            'model_used': model_name,
            'input_tokens': stats.get('input_tokens', 0),
            'output_tokens': stats.get('output_tokens', 0),
            'total_tokens': stats.get('input_tokens', 0) + stats.get('output_tokens', 0),
            'estimated_cost': cost,
            'generation_time': end_time - start_time,
            'model_type': model_type,
            'stream_mode': True
        }

        return complete_response, final_stats

    def get_model_info(self, model_type: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šç±»å‹æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä¿æŒä¸å˜ï¼‰"""
        model_name = self.get_model_name(model_type)
        model_config = self.all_models.get(model_name)
        if model_config:
            return {
                'api_name': model_config.api_name, 'display_name': model_config.display_name,
                'input_price_per_million': model_config.input_price_per_million,
                'output_price_per_million': model_config.output_price_per_million,
                'model_type': model_type, 'is_active': True
            }
        return {
            'api_name': model_name, 'display_name': model_name, 'model_type': model_type,
            'is_active': False, 'error': 'Model configuration not found'
        }

    def health_check(self) -> Dict[str, Any]:
        """ã€å·²é‡æ„ã€‘å¥åº·æ£€æŸ¥ï¼Œå§”æ‰˜ç»™Providerã€‚"""
        health_status = {
            'status': 'unhealthy', 'api_key_configured': bool(self.api_key),
            'provider': self.provider, 'models_loaded': len(self.all_models),
            'is_initialized': self.is_initialized, 'errors': []
        }

        if self.is_initialized and self.provider_client:
            try:
                provider_health = self.provider_client.health_check()
                health_status.update(provider_health)
                if provider_health.get('status') == 'healthy':
                    health_status['status'] = 'healthy'
                else:
                    health_status['errors'].append(provider_health.get('reason', 'Provider health check failed.'))
            except Exception as e:
                health_status['status'] = 'unhealthy'
                health_status['errors'].append(f"Provider health check raised an exception: {e}")
        else:
            health_status['errors'].append('Not initialized or no provider client.')

        return health_status

--- File: core/prompt_manager.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/prompt_manager.py
åŠŸèƒ½è¯´æ˜: Promptæ¨¡æ¿ç®¡ç†å™¨ï¼Œè´Ÿè´£æ¨¡æ¿çš„åŠ è½½ã€ç¼“å­˜å’Œç®¡ç†
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import json
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime
import re

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


class PromptTemplate:
    """Promptæ¨¡æ¿ç±»"""
    
    def __init__(self, template_id: str, content: str, 
                 category: str, metadata: Optional[Dict] = None):
        self.template_id = template_id
        self.content = content
        self.category = category
        self.metadata = metadata or {}
        self.load_time = datetime.now()
        self.version = self.metadata.get('version', '1.0.0')
        
        # è§£ææ¨¡æ¿ä¸­çš„å˜é‡
        self.variables = self._extract_variables()
    
    def _extract_variables(self) -> List[str]:
        """æå–æ¨¡æ¿ä¸­çš„å˜é‡å ä½ç¬¦"""
        # åŒ¹é… {variable_name} æ ¼å¼çš„å ä½ç¬¦
        pattern = r'\{([^}]+)\}'
        variables = re.findall(pattern, self.content)
        return list(set(variables))  # å»é‡
    
    def render(self, variables: Optional[Dict[str, Any]] = None) -> str:
        """
        æ¸²æŸ“æ¨¡æ¿ï¼Œæ›¿æ¢å˜é‡
        
        Args:
            variables: å˜é‡å­—å…¸
        
        Returns:
            str: æ¸²æŸ“åçš„å†…å®¹
        """
        if not variables:
            return self.content
        
        rendered = self.content
        for var_name, var_value in variables.items():
            placeholder = f"{{{var_name}}}"
            rendered = rendered.replace(placeholder, str(var_value))
        
        return rendered
    
    def validate_variables(self, provided_variables: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        éªŒè¯æä¾›çš„å˜é‡æ˜¯å¦æ»¡è¶³æ¨¡æ¿è¦æ±‚
        
        Returns:
            (is_valid, missing_variables)
        """
        provided_keys = set(provided_variables.keys())
        required_keys = set(self.variables)
        
        missing = list(required_keys - provided_keys)
        is_valid = len(missing) == 0
        
        return is_valid, missing
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡æ¿ä¿¡æ¯"""
        return {
            'template_id': self.template_id,
            'category': self.category,
            'version': self.version,
            'variables': self.variables,
            'metadata': self.metadata,
            'load_time': self.load_time.isoformat()
        }


class PromptManager:
    """
    Promptæ¨¡æ¿ç®¡ç†å™¨
    
    ä¸»è¦åŠŸèƒ½:
    1. ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½å†…ç½®æ¨¡æ¿
    2. æ”¯æŒè¿è¡Œæ—¶åŠ è½½è‡ªå®šä¹‰æ¨¡æ¿
    3. æ¨¡æ¿å‚æ•°åŒ–å’Œå˜é‡æ›¿æ¢
    4. æ¨¡æ¿ç¼“å­˜ç®¡ç†
    5. æ¨¡æ¿ç‰ˆæœ¬æ§åˆ¶
    
    ä½¿ç”¨ç¤ºä¾‹:
        pm = PromptManager()
        template = pm.get_template('analysis', 'customer_interview', variables={'transcript': text})
    """
    
    # é»˜è®¤æ¨¡æ¿ï¼ˆå½“æ–‡ä»¶ç³»ç»Ÿæ¨¡æ¿ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
    DEFAULT_TEMPLATES = {
        'transcription': {
            'multi_speaker': """è¯·å‡†ç¡®è½¬å½•è¿™æ®µéŸ³é¢‘å†…å®¹ã€‚

è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«ä¸åŒè¯´è¯äººï¼Œä½¿ç”¨"è¯´è¯äººA:"ã€"è¯´è¯äººB:"ç­‰æ ¼å¼æ ‡è®°
2. ä¿ç•™æ‰€æœ‰å¯¹è¯å†…å®¹ï¼ŒåŒ…æ‹¬è¯­æ°”è¯
3. é€‚å½“æ·»åŠ æ ‡ç‚¹ç¬¦å·ï¼Œæé«˜å¯è¯»æ€§
4. å¦‚æœ‰èƒŒæ™¯å™ªéŸ³æˆ–ä¸æ¸…æ™°éƒ¨åˆ†ï¼Œç”¨[å¬ä¸æ¸…]æ ‡è®°

è¯·ç›´æ¥è¾“å‡ºè½¬å½•ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚""",
            
            'single_speaker': """è¯·å‡†ç¡®è½¬å½•è¿™æ®µéŸ³é¢‘å†…å®¹ã€‚

è¦æ±‚ï¼š
1. å®Œæ•´ä¿ç•™æ‰€æœ‰å†…å®¹
2. é€‚å½“æ·»åŠ æ ‡ç‚¹ç¬¦å·
3. ä¿æŒåŸå§‹è¯­è¨€é£æ ¼
4. ä¸æ¸…æ™°éƒ¨åˆ†ç”¨[å¬ä¸æ¸…]æ ‡è®°

è¯·ç›´æ¥è¾“å‡ºè½¬å½•ç»“æœã€‚""",
            
            'optimization': """# è½¬å½•æ–‡æœ¬ä¼˜åŒ–ä»»åŠ¡

## ç¬¬ä¸€éƒ¨åˆ†ï¼šé”™è¯¯è¯†åˆ«ä¸ä¿®æ­£å»ºè®®

è¯·ä»”ç»†åˆ†æä»¥ä¸‹è½¬å½•æ–‡æœ¬ï¼Œè¯†åˆ«å¯èƒ½çš„é”™è¯¯å¹¶æä¾›ä¿®æ­£å»ºè®®ï¼š

{transcript}

è¯·åˆ—å‡ºï¼š
1. æ˜æ˜¾çš„æ‹¼å†™æˆ–ç”¨è¯é”™è¯¯
2. è¯­æ³•é—®é¢˜
3. æ ‡ç‚¹ç¬¦å·ä½¿ç”¨ä¸å½“
4. ä¸Šä¸‹æ–‡é€»è¾‘ä¸é€šçš„åœ°æ–¹

## ç¬¬äºŒéƒ¨åˆ†ï¼šä¼˜åŒ–åè½¬å½•æ–‡æœ¬

åŸºäºä¸Šè¿°åˆ†æï¼Œè¯·æä¾›ä¼˜åŒ–åçš„å®Œæ•´è½¬å½•æ–‡æœ¬ã€‚ä¿æŒåŸæ„çš„åŒæ—¶ï¼š
- ä¿®æ­£é”™è¯¯
- æ”¹å–„è¯­è¨€æµç•…æ€§
- ç¡®ä¿ä¸“ä¸šæœ¯è¯­å‡†ç¡®
- ä¿ç•™è¯´è¯äººæ ‡è®°"""
        },
        
        'analysis': {
            'customer_interview': """# å®¢æˆ·è®¿è°ˆæ·±åº¦åˆ†æ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰15å¹´ç»éªŒçš„èµ„æ·±å•†ä¸šåˆ†æå¸ˆå’Œå®¢æˆ·æ´å¯Ÿä¸“å®¶ï¼Œä¸“ç²¾äºä»å®¢æˆ·è®¿è°ˆä¸­æå–å…³é”®ä¿¡æ¯å¹¶åˆ¶å®šå•†ä¸šç­–ç•¥ã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å®¢æˆ·è®¿è°ˆè®°å½•è¿›è¡Œæ·±åº¦åˆ†æï¼Œé‡ç‚¹å…³æ³¨ï¼š
- å®¢æˆ·çš„æ ¸å¿ƒéœ€æ±‚å’Œç—›ç‚¹
- å†³ç­–è¿‡ç¨‹å’Œå…³é”®å½±å“å› ç´ 
- é¢„ç®—èŒƒå›´å’Œæ—¶é—´çº¿
- æ½œåœ¨çš„å•†ä¸šæœºä¼š

### è®¿è°ˆå†…å®¹ï¼š
{transcript}

## ä¸‰ã€åˆ†ææ¡†æ¶

### 3.1 æ‰§è¡Œæ‘˜è¦ï¼ˆ200å­—ä»¥å†…ï¼‰
ç®€è¦æ¦‚æ‹¬è®¿è°ˆçš„æ ¸å¿ƒå‘ç°å’Œå…³é”®æ´å¯Ÿã€‚

### 3.2 å®¢æˆ·ç”»åƒ
- **åŸºæœ¬ä¿¡æ¯**ï¼šè¡Œä¸šã€è§„æ¨¡ã€è§’è‰²
- **ä¸šåŠ¡ç°çŠ¶**ï¼šå½“å‰æŒ‘æˆ˜å’Œæœºé‡
- **å†³ç­–ç‰¹å¾**ï¼šå†³ç­–æµç¨‹ã€å…³é”®äººç‰©

### 3.3 éœ€æ±‚åˆ†æ
- **æ˜¾æ€§éœ€æ±‚**ï¼šå®¢æˆ·æ˜ç¡®è¡¨è¾¾çš„éœ€æ±‚
- **éšæ€§éœ€æ±‚**ï¼šä»å¯¹è¯ä¸­æ¨æ–­çš„æ½œåœ¨éœ€æ±‚
- **éœ€æ±‚ä¼˜å…ˆçº§**ï¼šåŸºäºç´§è¿«æ€§å’Œé‡è¦æ€§æ’åº

### 3.4 å•†æœºè¯„ä¼°
- **é¡¹ç›®è§„æ¨¡**ï¼šé¢„ä¼°çš„é¡¹ç›®ä»·å€¼
- **æˆåŠŸæ¦‚ç‡**ï¼šåŸºäºå®¢æˆ·æ€åº¦å’ŒåŒ¹é…åº¦
- **é£é™©å› ç´ **ï¼šå¯èƒ½å½±å“åˆä½œçš„å› ç´ 

### 3.5 è¡ŒåŠ¨å»ºè®®
æä¾›3-5æ¡å…·ä½“ã€å¯æ‰§è¡Œçš„åç»­è¡ŒåŠ¨å»ºè®®ã€‚

## å››ã€è¾“å‡ºè¦æ±‚
1. åˆ†æåŸºäºäº‹å®ï¼Œé¿å…è¿‡åº¦æ¨æµ‹
2. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„å•†ä¸šè¯­è¨€
3. çªå‡ºå…³é”®ä¿¡æ¯ï¼Œä¾¿äºå¿«é€Ÿå†³ç­–""",
            
            'business_negotiation': """# å•†åŠ¡è°ˆåˆ¤è¦ç‚¹åˆ†æ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å•†åŠ¡è°ˆåˆ¤ä¸“å®¶ï¼Œæ“…é•¿åˆ†æè°ˆåˆ¤åŠ¨æ€ã€è¯†åˆ«å„æ–¹ç«‹åœºå¹¶åˆ¶å®šè°ˆåˆ¤ç­–ç•¥ã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å•†åŠ¡è°ˆåˆ¤è®°å½•è¿›è¡Œæ·±åº¦åˆ†æï¼š

{transcript}

## ä¸‰ã€åˆ†æç»´åº¦

### 3.1 è°ˆåˆ¤æ¦‚å†µ
- å‚ä¸æ–¹åŠå…¶è§’è‰²
- è°ˆåˆ¤ä¸»é¢˜å’Œç›®æ ‡
- å½“å‰è°ˆåˆ¤é˜¶æ®µ

### 3.2 å„æ–¹ç«‹åœºåˆ†æ
- **æˆ‘æ–¹ç«‹åœº**ï¼šæ ¸å¿ƒè¯‰æ±‚ã€åº•çº¿ã€ç­¹ç 
- **å¯¹æ–¹ç«‹åœº**ï¼šä¸»è¦å…³æ³¨ç‚¹ã€è®©æ­¥ç©ºé—´
- **åˆ†æ­§ç„¦ç‚¹**ï¼šä¸»è¦äº‰è®®å’Œéšœç¢

### 3.3 è°ˆåˆ¤åŠ¨æ€
- è°ˆåˆ¤æ°›å›´å’Œè¿›å±•
- å…³é”®è½¬æŠ˜ç‚¹
- åŒæ–¹ç­–ç•¥å˜åŒ–

### 3.4 æ¡æ¬¾è¦ç‚¹
- å·²è¾¾æˆå…±è¯†çš„æ¡æ¬¾
- å¾…å•†è®®çš„æ¡æ¬¾
- æ½œåœ¨é£é™©æ¡æ¬¾

### 3.5 ç­–ç•¥å»ºè®®
- ä¸‹ä¸€æ­¥è°ˆåˆ¤ç­–ç•¥
- å¯èƒ½çš„è®©æ­¥æ–¹æ¡ˆ
- é£é™©é˜²èŒƒæªæ–½""",
            
            'internal_meeting': """# å†…éƒ¨ä¼šè®®å†³ç­–åˆ†æ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç®¡ç†é¡¾é—®ï¼Œä¸“æ³¨äºä¼šè®®æ•ˆç‡æå‡å’Œå†³ç­–è´¨é‡ä¼˜åŒ–ã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å†…éƒ¨ä¼šè®®è®°å½•è¿›è¡Œåˆ†æï¼š

{transcript}

## ä¸‰ã€åˆ†æè¦ç‚¹

### 3.1 ä¼šè®®æ¦‚è¿°
- ä¼šè®®ä¸»é¢˜å’Œç›®æ ‡
- å‚ä¼šäººå‘˜å’Œè§’è‰²
- ä¼šè®®ç±»å‹ï¼ˆå†³ç­–/è®¨è®º/æ±‡æŠ¥ï¼‰

### 3.2 å…³é”®è®®é¢˜
åˆ—å‡ºè®¨è®ºçš„ä¸»è¦è®®é¢˜åŠå…¶é‡è¦æ€§ã€‚

### 3.3 å†³ç­–äº‹é¡¹
- **å·²å†³ç­–äº‹é¡¹**ï¼šæ˜ç¡®çš„å†³å®šå’Œç»“è®º
- **å¾…å†³ç­–äº‹é¡¹**ï¼šéœ€è¦è¿›ä¸€æ­¥è®¨è®ºçš„é—®é¢˜
- **å†³ç­–ä¾æ®**ï¼šæ”¯æ’‘å†³ç­–çš„å…³é”®ä¿¡æ¯

### 3.4 è¡ŒåŠ¨è®¡åˆ’
- å…·ä½“è¡ŒåŠ¨é¡¹
- è´£ä»»äººåˆ†é…
- å®Œæˆæ—¶é™
- æ‰€éœ€èµ„æº

### 3.5 åç»­è·Ÿè¿›
- éœ€è¦è·Ÿè¿›çš„äº‹é¡¹
- ä¸‹æ¬¡ä¼šè®®å®‰æ’
- é£é™©å’Œæ³¨æ„äº‹é¡¹"""
        },
        
        'proposal': {
            'project_proposal': """# é¡¹ç›®å»ºè®®ä¹¦ç”Ÿæˆ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å•†åŠ¡æ–¹æ¡ˆä¸“å®¶ï¼Œæ“…é•¿æ’°å†™ä¸“ä¸šã€æœ‰è¯´æœåŠ›çš„é¡¹ç›®å»ºè®®ä¹¦ã€‚

## äºŒã€ç”Ÿæˆä»»åŠ¡
åŸºäºä»¥ä¸‹åˆ†ææŠ¥å‘Š{analysis_report}ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„é¡¹ç›®å»ºè®®ä¹¦ã€‚

{capability_docs}

## ä¸‰ã€å»ºè®®ä¹¦ç»“æ„

### 1. æ‰§è¡Œæ‘˜è¦
- é¡¹ç›®èƒŒæ™¯å’Œæœºé‡
- æ ¸å¿ƒä»·å€¼ä¸»å¼ 
- é¢„æœŸæˆæœ

### 2. å®¢æˆ·éœ€æ±‚ç†è§£
- ä¸šåŠ¡æŒ‘æˆ˜åˆ†æ
- éœ€æ±‚è§£è¯»
- æˆåŠŸæ ‡å‡†å®šä¹‰

### 3. è§£å†³æ–¹æ¡ˆ
- æ•´ä½“æ–¹æ¡ˆæ¶æ„
- æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
- æŠ€æœ¯è·¯çº¿
- åˆ›æ–°äº®ç‚¹

### 4. å®æ–½è®¡åˆ’
- é¡¹ç›®é˜¶æ®µåˆ’åˆ†
- æ—¶é—´çº¿å’Œé‡Œç¨‹ç¢‘
- èµ„æºé…ç½®
- é£é™©ç®¡ç†

### 5. ä»·å€¼æ”¶ç›Š
- ç›´æ¥æ”¶ç›Š
- é—´æ¥æ”¶ç›Š
- ROIåˆ†æ

### 6. ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬
- æ ¸å¿ƒä¼˜åŠ¿
- æˆåŠŸæ¡ˆä¾‹
- å›¢é˜Ÿå®åŠ›

### 7. å•†åŠ¡æ¡æ¬¾
- æŠ¥ä»·æ–¹æ¡ˆ
- ä»˜æ¬¾æ–¹å¼
- æœåŠ¡æ‰¿è¯º

## å››ã€å†™ä½œè¦æ±‚
1. ä¸“ä¸šä¸¥è°¨ï¼Œé€»è¾‘æ¸…æ™°
2. çªå‡ºä»·å€¼ï¼Œæ‰“åŠ¨å®¢æˆ·
3. æ–¹æ¡ˆå…·ä½“ï¼Œå¯æ“ä½œæ€§å¼º
4. ç¯‡å¹…é€‚ä¸­ï¼Œé‡ç‚¹çªå‡º""",
            
            'quotation_proposal': """# å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆç”Ÿæˆ

## ä¸€ã€ä»»åŠ¡è¯´æ˜
åŸºäºå®¢æˆ·éœ€æ±‚åˆ†æ{analysis_report}ï¼Œç”Ÿæˆä¸“ä¸šçš„å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆã€‚

{capability_docs}

## äºŒã€æŠ¥ä»·æ–¹æ¡ˆç»“æ„

### 1. æ–¹æ¡ˆæ¦‚è¿°
- é¡¹ç›®èƒŒæ™¯
- æœåŠ¡èŒƒå›´
- äº¤ä»˜æˆæœ

### 2. è¯¦ç»†æŠ¥ä»·
- æœåŠ¡é¡¹ç›®æ˜ç»†
- å•ä»·å’Œæ•°é‡
- ä¼˜æƒ æ”¿ç­–
- æ€»ä»·

### 3. æœåŠ¡è¯´æ˜
- å„é¡¹æœåŠ¡è¯¦ç»†è¯´æ˜
- æœåŠ¡æ ‡å‡†
- è´¨é‡ä¿è¯

### 4. ä»˜æ¬¾æ–¹å¼
- ä»˜æ¬¾èŠ‚ç‚¹
- ä»˜æ¬¾æ¯”ä¾‹
- ä»˜æ¬¾æ¡ä»¶

### 5. å…¶ä»–æ¡æ¬¾
- æœ‰æ•ˆæœŸ
- å”®åæœåŠ¡
- ç‰¹åˆ«è¯´æ˜""",
            
            'solution_brief': """# è§£å†³æ–¹æ¡ˆç®€æŠ¥

## ä¸€ã€ä»»åŠ¡è¯´æ˜
åŸºäºåˆ†æç»“æœ{analysis_report}ï¼Œç”Ÿæˆç®€æ´çš„è§£å†³æ–¹æ¡ˆç®€æŠ¥ã€‚

## äºŒã€ç®€æŠ¥ç»“æ„

### 1. é—®é¢˜é™ˆè¿°
ç®€æ˜æ‰¼è¦åœ°æè¿°å®¢æˆ·é¢ä¸´çš„æ ¸å¿ƒé—®é¢˜ã€‚

### 2. è§£å†³æ–¹æ¡ˆ
- æ–¹æ¡ˆæ¦‚è¿°
- å…³é”®ç‰¹æ€§
- å®æ–½æ­¥éª¤

### 3. é¢„æœŸæ•ˆæœ
- çŸ­æœŸæ”¶ç›Š
- é•¿æœŸä»·å€¼

### 4. ä¸‹ä¸€æ­¥è¡ŒåŠ¨
æ˜ç¡®çš„è¡ŒåŠ¨å»ºè®®å’Œæ—¶é—´å®‰æ’ã€‚"""
        }
    }
    
    def __init__(self, template_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–Promptç®¡ç†å™¨
        
        Args:
            template_dir: æ¨¡æ¿ç›®å½•è·¯å¾„
        """
        if template_dir is None:
            # é»˜è®¤æ¨¡æ¿ç›®å½•
            template_dir = os.path.join(
                os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                'prompts'
            )
        
        self.template_dir = Path(template_dir)
        self.templates: Dict[str, Dict[str, PromptTemplate]] = {}
        self.custom_templates: Dict[str, PromptTemplate] = {}
        self.cache_enabled = True
        
        # åŠ è½½æ‰€æœ‰æ¨¡æ¿
        self._load_all_templates()

    def _load_all_templates(self):
        """åŠ è½½æ‰€æœ‰æ¨¡æ¿æ–‡ä»¶"""
        # å…ˆåŠ è½½é»˜è®¤æ¨¡æ¿
        self._load_default_templates()

        if not self.template_dir.exists():
            print(f"è­¦å‘Šï¼šæ¨¡æ¿ç›®å½• {self.template_dir} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
            return

        # éå†æ¨¡æ¿ç›®å½•
        for category_dir in self.template_dir.iterdir():
            if category_dir.is_dir() and not category_dir.name.startswith('_'):
                category = category_dir.name

                # å¦‚æœè¯¥ç±»åˆ«è¿˜æ²¡æœ‰æ¨¡æ¿ï¼Œåˆå§‹åŒ–ç©ºå­—å…¸
                if category not in self.templates:
                    self.templates[category] = {}

                # åŠ è½½è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰æ¨¡æ¿
                for template_file in category_dir.glob('*.md'):
                    template_id = template_file.stem
                    try:
                        content = self._load_template_file(template_file)
                        metadata = self._extract_metadata(content)

                        template = PromptTemplate(
                            template_id=template_id,
                            content=content,
                            category=category,
                            metadata=metadata
                        )

                        self.templates[category][template_id] = template

                    except Exception as e:
                        print(f"åŠ è½½æ¨¡æ¿ {template_file} å¤±è´¥: {e}")

        print(f"æˆåŠŸåŠ è½½ {sum(len(cat) for cat in self.templates.values())} ä¸ªæ¨¡æ¿")
    
    def _load_default_templates(self):
        """åŠ è½½é»˜è®¤æ¨¡æ¿"""
        for category, templates in self.DEFAULT_TEMPLATES.items():
            self.templates[category] = {}
            for template_id, content in templates.items():
                template = PromptTemplate(
                    template_id=template_id,
                    content=content,
                    category=category,
                    metadata={'source': 'default', 'version': '1.0.0'}
                )
                self.templates[category][template_id] = template
    
    def _load_template_file(self, file_path: Path) -> str:
        """åŠ è½½å•ä¸ªæ¨¡æ¿æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def _extract_metadata(self, content: str) -> Dict[str, Any]:
        """ä»æ¨¡æ¿å†…å®¹ä¸­æå–å…ƒæ•°æ®"""
        metadata = {}
        
        # å°è¯•ä»å†…å®¹å¼€å¤´æå–YAMLæ ¼å¼çš„å…ƒæ•°æ®
        if content.startswith('---'):
            try:
                end_index = content.find('---', 3)
                if end_index > 0:
                    yaml_content = content[3:end_index].strip()
                    # ç®€å•çš„YAMLè§£æï¼ˆå¯ä»¥ä½¿ç”¨yamlåº“è¿›è¡Œæ›´å¤æ‚çš„è§£æï¼‰
                    for line in yaml_content.split('\n'):
                        if ':' in line:
                            key, value = line.split(':', 1)
                            metadata[key.strip()] = value.strip()
            except:
                pass
        
        return metadata

    def get_template(self,
                     category: str,
                     template_id: str,
                     variables: Optional[Dict[str, Any]] = None) -> str:
        """
        è·å–å¹¶æ¸²æŸ“æ¨¡æ¿

        Args:
            category: æ¨¡æ¿ç±»åˆ«
            template_id: æ¨¡æ¿ID
            variables: å˜é‡å­—å…¸

        Returns:
            str: æ¸²æŸ“åçš„æ¨¡æ¿å†…å®¹
        """
        # å…ˆæ£€æŸ¥è‡ªå®šä¹‰æ¨¡æ¿
        custom_key = f"{category}/{template_id}"
        if custom_key in self.custom_templates:
            template = self.custom_templates[custom_key]
            return template.render(variables)

        # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿæ¨¡æ¿
        if category in self.templates and template_id in self.templates[category]:
            template = self.templates[category][template_id]
            return template.render(variables)

        # å°è¯•ä»é»˜è®¤æ¨¡æ¿è·å–
        if category in self.DEFAULT_TEMPLATES and template_id in self.DEFAULT_TEMPLATES[category]:
            default_content = self.DEFAULT_TEMPLATES[category][template_id]
            template = PromptTemplate(
                template_id=template_id,
                content=default_content,
                category=category,
                metadata={'source': 'default_fallback'}
            )
            # ç¼“å­˜åˆ°æ¨¡æ¿ä¸­ä»¥é¿å…é‡å¤åˆ›å»º
            if category not in self.templates:
                self.templates[category] = {}
            self.templates[category][template_id] = template
            return template.render(variables)

        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼ŒæŠ›å‡ºå¼‚å¸¸
        raise ValueError(f"æ¨¡æ¿ {category}/{template_id} ä¸å­˜åœ¨")
    
    def register_custom_template(self,
                                category: str,
                                template_id: str,
                                content: str,
                                metadata: Optional[Dict] = None) -> bool:
        """
        æ³¨å†Œè‡ªå®šä¹‰æ¨¡æ¿
        
        Args:
            category: æ¨¡æ¿ç±»åˆ«
            template_id: æ¨¡æ¿ID
            content: æ¨¡æ¿å†…å®¹
            metadata: æ¨¡æ¿å…ƒæ•°æ®
        
        Returns:
            bool: æ˜¯å¦æ³¨å†ŒæˆåŠŸ
        """
        try:
            template = PromptTemplate(
                template_id=template_id,
                content=content,
                category=category,
                metadata=metadata or {}
            )
            
            custom_key = f"{category}/{template_id}"
            self.custom_templates[custom_key] = template
            
            return True
            
        except Exception as e:
            print(f"æ³¨å†Œè‡ªå®šä¹‰æ¨¡æ¿å¤±è´¥: {e}")
            return False
    
    def list_templates(self, category: Optional[str] = None) -> List[str]:
        """
        åˆ—å‡ºå¯ç”¨çš„æ¨¡æ¿
        
        Args:
            category: æ¨¡æ¿ç±»åˆ«ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ—å‡ºæ‰€æœ‰æ¨¡æ¿
        
        Returns:
            List[str]: æ¨¡æ¿IDåˆ—è¡¨
        """
        templates = []
        
        # æ–‡ä»¶ç³»ç»Ÿæ¨¡æ¿
        if category:
            if category in self.templates:
                templates.extend(self.templates[category].keys())
        else:
            for cat, temps in self.templates.items():
                templates.extend([f"{cat}/{tid}" for tid in temps.keys()])
        
        # è‡ªå®šä¹‰æ¨¡æ¿
        for custom_key in self.custom_templates.keys():
            if category:
                if custom_key.startswith(f"{category}/"):
                    templates.append(custom_key.split('/', 1)[1])
            else:
                templates.append(custom_key)
        
        return sorted(list(set(templates)))
    
    def get_template_info(self, category: str, template_id: str) -> Dict[str, Any]:
        """
        è·å–æ¨¡æ¿è¯¦ç»†ä¿¡æ¯
        
        Args:
            category: æ¨¡æ¿ç±»åˆ«
            template_id: æ¨¡æ¿ID
        
        Returns:
            Dict: æ¨¡æ¿ä¿¡æ¯
        """
        # æ£€æŸ¥è‡ªå®šä¹‰æ¨¡æ¿
        custom_key = f"{category}/{template_id}"
        if custom_key in self.custom_templates:
            return self.custom_templates[custom_key].get_info()
        
        # æ£€æŸ¥æ–‡ä»¶ç³»ç»Ÿæ¨¡æ¿
        if category in self.templates and template_id in self.templates[category]:
            return self.templates[category][template_id].get_info()
        
        raise ValueError(f"æ¨¡æ¿ {category}/{template_id} ä¸å­˜åœ¨")
    
    def validate_template(self,
                         category: str,
                         template_id: str,
                         variables: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        éªŒè¯æ¨¡æ¿å˜é‡
        
        Args:
            category: æ¨¡æ¿ç±»åˆ«
            template_id: æ¨¡æ¿ID
            variables: æä¾›çš„å˜é‡
        
        Returns:
            (is_valid, missing_variables)
        """
        # è·å–æ¨¡æ¿
        custom_key = f"{category}/{template_id}"
        if custom_key in self.custom_templates:
            template = self.custom_templates[custom_key]
        elif category in self.templates and template_id in self.templates[category]:
            template = self.templates[category][template_id]
        else:
            return False, [f"æ¨¡æ¿ {category}/{template_id} ä¸å­˜åœ¨"]
        
        return template.validate_variables(variables)
    
    def reload_templates(self):
        """é‡æ–°åŠ è½½æ‰€æœ‰æ¨¡æ¿"""
        self.templates.clear()
        self._load_all_templates()
        print("æ¨¡æ¿é‡æ–°åŠ è½½å®Œæˆ")
    
    def export_template(self, 
                       category: str,
                       template_id: str,
                       output_path: str) -> bool:
        """
        å¯¼å‡ºæ¨¡æ¿åˆ°æ–‡ä»¶
        
        Args:
            category: æ¨¡æ¿ç±»åˆ«
            template_id: æ¨¡æ¿ID
            output_path: è¾“å‡ºè·¯å¾„
        
        Returns:
            bool: æ˜¯å¦å¯¼å‡ºæˆåŠŸ
        """
        try:
            content = self.get_template(category, template_id)
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return True
            
        except Exception as e:
            print(f"å¯¼å‡ºæ¨¡æ¿å¤±è´¥: {e}")
            return False
    
    def get_categories(self) -> List[str]:
        """è·å–æ‰€æœ‰æ¨¡æ¿ç±»åˆ«"""
        categories = set(self.templates.keys())
        
        # æ·»åŠ è‡ªå®šä¹‰æ¨¡æ¿çš„ç±»åˆ«
        for custom_key in self.custom_templates.keys():
            category = custom_key.split('/')[0]
            categories.add(category)
        
        return sorted(list(categories))
    
    def clear_cache(self):
        """æ¸…é™¤æ¨¡æ¿ç¼“å­˜ï¼ˆæœªæ¥æ‰©å±•ç”¨ï¼‰"""
        # å½“å‰å®ç°ä¸­æ¨¡æ¿æ˜¯ç«‹å³åŠ è½½çš„ï¼Œè¿™é‡Œé¢„ç•™ç¼“å­˜æ¸…ç†æ¥å£
        pass
    
    def get_template_stats(self) -> Dict[str, Any]:
        """è·å–æ¨¡æ¿ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_templates': 0,
            'categories': {},
            'custom_templates': len(self.custom_templates),
            'load_time': datetime.now().isoformat()
        }
        
        for category, templates in self.templates.items():
            stats['categories'][category] = len(templates)
            stats['total_templates'] += len(templates)
        
        stats['total_templates'] += len(self.custom_templates)
        
        return stats

--- File: core/session_manager.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/session_manager.py
åŠŸèƒ½è¯´æ˜: ä¼šè¯çŠ¶æ€ç®¡ç†å™¨ï¼Œç®¡ç†è·¨é¡µé¢çš„æ•°æ®æµè½¬
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import json
import pickle
import shutil
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timedelta
from pathlib import Path
import hashlib
import tempfile

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.base_service import ProcessingResult
from utils.file_utils import ensure_directory_exists, cleanup_directory


class SessionData:
    """ä¼šè¯æ•°æ®ç±»ï¼Œå­˜å‚¨å•ä¸ªå¤„ç†ä¼šè¯çš„æ‰€æœ‰ä¿¡æ¯"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.created_at = datetime.now()
        self.updated_at = datetime.now()
        self.workflow_type = None  # å·¥ä½œæµç±»å‹
        self.current_step = None   # å½“å‰æ­¥éª¤
        self.data = {}            # å„æ­¥éª¤çš„æ•°æ®
        self.files = {}           # å…³è”çš„æ–‡ä»¶è·¯å¾„
        self.metadata = {}        # å…ƒæ•°æ®
        self.status = "active"    # çŠ¶æ€ï¼šactive, completed, error
        
    def update(self, key: str, value: Any):
        """æ›´æ–°æ•°æ®"""
        self.data[key] = value
        self.updated_at = datetime.now()
    
    def get(self, key: str, default: Any = None) -> Any:
        """è·å–æ•°æ®"""
        return self.data.get(key, default)
    
    def add_file(self, file_type: str, file_path: str):
        """æ·»åŠ æ–‡ä»¶å¼•ç”¨"""
        self.files[file_type] = file_path
        self.updated_at = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'session_id': self.session_id,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'workflow_type': self.workflow_type,
            'current_step': self.current_step,
            'data': self.data,
            'files': self.files,
            'metadata': self.metadata,
            'status': self.status
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SessionData':
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        session = cls(data['session_id'])
        session.created_at = datetime.fromisoformat(data['created_at'])
        session.updated_at = datetime.fromisoformat(data['updated_at'])
        session.workflow_type = data.get('workflow_type')
        session.current_step = data.get('current_step')
        session.data = data.get('data', {})
        session.files = data.get('files', {})
        session.metadata = data.get('metadata', {})
        session.status = data.get('status', 'active')
        return session


class SessionManager:
    """
    ä¼šè¯çŠ¶æ€ç®¡ç†å™¨
    
    ä¸»è¦åŠŸèƒ½:
    1. ç®¡ç†Streamlit session state
    2. æ•°æ®åœ¨å„ç¯èŠ‚é—´çš„ä¼ é€’
    3. ä¸´æ—¶æ–‡ä»¶ç®¡ç†
    4. ç»“æœç¼“å­˜
    
    ä½¿ç”¨ç¤ºä¾‹:
        sm = SessionManager()
        sm.save_result('transcription', result)
        result = sm.get_result('transcription')
    """
    
    def __init__(self, temp_dir: Optional[str] = None, max_sessions: int = 100):
        """
        åˆå§‹åŒ–ä¼šè¯ç®¡ç†å™¨
        
        Args:
            temp_dir: ä¸´æ—¶æ–‡ä»¶ç›®å½•
            max_sessions: æœ€å¤§ä¼šè¯æ•°é‡
        """
        if temp_dir is None:
            temp_dir = os.path.join(tempfile.gettempdir(), 'smartproposal_sessions')
        
        self.temp_dir = Path(temp_dir)
        self.max_sessions = max_sessions
        self.sessions: Dict[str, SessionData] = {}
        self.current_session_id: Optional[str] = None
        
        # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
        ensure_directory_exists(self.temp_dir)
        
        # åŠ è½½å·²æœ‰ä¼šè¯ï¼ˆå¦‚æœéœ€è¦æŒä¹…åŒ–ï¼‰
        self._load_sessions()
    
    def create_session(self, workflow_type: str = 'default') -> str:
        """
        åˆ›å»ºæ–°ä¼šè¯
        
        Args:
            workflow_type: å·¥ä½œæµç±»å‹
        
        Returns:
            str: ä¼šè¯ID
        """
        # ç”Ÿæˆå”¯ä¸€ä¼šè¯ID
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        random_suffix = hashlib.md5(os.urandom(16)).hexdigest()[:8]
        session_id = f"{workflow_type}_{timestamp}_{random_suffix}"
        
        # åˆ›å»ºä¼šè¯æ•°æ®
        session = SessionData(session_id)
        session.workflow_type = workflow_type
        
        # åˆ›å»ºä¼šè¯ç›®å½•
        session_dir = self.temp_dir / session_id
        ensure_directory_exists(session_dir)
        
        # ä¿å­˜ä¼šè¯
        self.sessions[session_id] = session
        self.current_session_id = session_id
        
        # æ¸…ç†è¿‡æœŸä¼šè¯
        self._cleanup_old_sessions()
        
        return session_id
    
    def get_current_session(self) -> Optional[SessionData]:
        """è·å–å½“å‰ä¼šè¯"""
        if self.current_session_id and self.current_session_id in self.sessions:
            return self.sessions[self.current_session_id]
        return None
    
    def set_current_session(self, session_id: str) -> bool:
        """
        è®¾ç½®å½“å‰ä¼šè¯
        
        Args:
            session_id: ä¼šè¯ID
        
        Returns:
            bool: æ˜¯å¦è®¾ç½®æˆåŠŸ
        """
        if session_id in self.sessions:
            self.current_session_id = session_id
            return True
        return False
    
    def save_result(self, 
                   step_name: str, 
                   result: Union[ProcessingResult, Dict, str],
                   session_id: Optional[str] = None) -> bool:
        """
        ä¿å­˜å¤„ç†ç»“æœ
        
        Args:
            step_name: æ­¥éª¤åç§°ï¼ˆå¦‚ 'transcription', 'analysis', 'proposal'ï¼‰
            result: å¤„ç†ç»“æœ
            session_id: ä¼šè¯IDï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰ä¼šè¯ï¼‰
        
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return False
        
        session = self.sessions[session_id]
        
        # è½¬æ¢ProcessingResultä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        if isinstance(result, ProcessingResult):
            result_data = result.to_dict()
        else:
            result_data = result
        
        # ä¿å­˜åˆ°ä¼šè¯æ•°æ®
        session.update(f"{step_name}_result", result_data)
        session.current_step = step_name
        
        # å¦‚æœç»“æœåŒ…å«æ–‡ä»¶å†…å®¹ï¼Œè€ƒè™‘ä¿å­˜åˆ°æ–‡ä»¶
        if isinstance(result, ProcessingResult) and len(result.content) > 10000:
            # å¤§å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶
            file_path = self._save_content_to_file(
                session_id, 
                step_name, 
                result.content
            )
            session.add_file(f"{step_name}_content", str(file_path))
        
        return True
    
    def get_result(self, 
                  step_name: str,
                  session_id: Optional[str] = None) -> Optional[ProcessingResult]:
        """
        è·å–å¤„ç†ç»“æœ
        
        Args:
            step_name: æ­¥éª¤åç§°
            session_id: ä¼šè¯ID
        
        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return None
        
        session = self.sessions[session_id]
        result_data = session.get(f"{step_name}_result")
        
        if not result_data:
            return None
        
        # å¦‚æœå†…å®¹ä¿å­˜åœ¨æ–‡ä»¶ä¸­ï¼Œè¯»å–æ–‡ä»¶
        content_file = session.files.get(f"{step_name}_content")
        if content_file and os.path.exists(content_file):
            with open(content_file, 'r', encoding='utf-8') as f:
                result_data['content'] = f.read()
        
        # è½¬æ¢å›ProcessingResultå¯¹è±¡
        if isinstance(result_data, dict) and 'content' in result_data:
            return ProcessingResult.from_dict(result_data)
        
        return result_data
    
    def save_file(self,
                 file_type: str,
                 file_path: str,
                 session_id: Optional[str] = None) -> bool:
        """
        ä¿å­˜æ–‡ä»¶å¼•ç”¨
        
        Args:
            file_type: æ–‡ä»¶ç±»å‹
            file_path: æ–‡ä»¶è·¯å¾„
            session_id: ä¼šè¯ID
        
        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return False
        
        session = self.sessions[session_id]
        session.add_file(file_type, file_path)
        return True
    
    def get_file(self,
                file_type: str,
                session_id: Optional[str] = None) -> Optional[str]:
        """
        è·å–æ–‡ä»¶è·¯å¾„
        
        Args:
            file_type: æ–‡ä»¶ç±»å‹
            session_id: ä¼šè¯ID
        
        Returns:
            str: æ–‡ä»¶è·¯å¾„
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return None
        
        session = self.sessions[session_id]
        return session.files.get(file_type)
    
    def transfer_between_steps(self,
                             from_step: str,
                             to_step: str,
                             transform_func: Optional[callable] = None) -> bool:
        """
        åœ¨æ­¥éª¤é—´ä¼ é€’æ•°æ®
        
        Args:
            from_step: æºæ­¥éª¤
            to_step: ç›®æ ‡æ­¥éª¤
            transform_func: æ•°æ®è½¬æ¢å‡½æ•°ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            bool: æ˜¯å¦ä¼ é€’æˆåŠŸ
        """
        # è·å–æºæ•°æ®
        source_result = self.get_result(from_step)
        if not source_result:
            return False
        
        # åº”ç”¨è½¬æ¢å‡½æ•°ï¼ˆå¦‚æœæä¾›ï¼‰
        if transform_func:
            try:
                transformed_data = transform_func(source_result)
            except Exception as e:
                print(f"æ•°æ®è½¬æ¢å¤±è´¥: {e}")
                return False
        else:
            transformed_data = source_result
        
        # ä¿å­˜åˆ°ç›®æ ‡æ­¥éª¤
        return self.save_result(to_step, transformed_data)
    
    def get_workflow_status(self, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–å·¥ä½œæµçŠ¶æ€
        
        Returns:
            Dict: å·¥ä½œæµçŠ¶æ€ä¿¡æ¯
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return {'status': 'no_session'}
        
        session = self.sessions[session_id]
        
        # æ£€æŸ¥å„æ­¥éª¤å®Œæˆæƒ…å†µ
        steps_status = {
            'transcription': bool(session.get('transcription_result')),
            'analysis': bool(session.get('analysis_result')),
            'proposal': bool(session.get('proposal_result'))
        }
        
        return {
            'session_id': session_id,
            'workflow_type': session.workflow_type,
            'current_step': session.current_step,
            'steps_completed': steps_status,
            'status': session.status,
            'created_at': session.created_at,
            'updated_at': session.updated_at
        }
    
    def export_all_results(self, 
                          session_id: Optional[str] = None,
                          output_dir: Optional[str] = None) -> Dict[str, str]:
        """
        å¯¼å‡ºæ‰€æœ‰ç»“æœ
        
        Args:
            session_id: ä¼šè¯ID
            output_dir: è¾“å‡ºç›®å½•
        
        Returns:
            Dict[str, str]: å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„æ˜ å°„
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return {}
        
        session = self.sessions[session_id]
        
        if output_dir is None:
            output_dir = os.path.join('output', session_id)
        
        ensure_directory_exists(output_dir)
        
        exported_files = {}
        
        # å¯¼å‡ºå„æ­¥éª¤ç»“æœ
        for step in ['transcription', 'analysis', 'proposal']:
            result = self.get_result(step, session_id)
            if result and isinstance(result, ProcessingResult):
                # å¯¼å‡ºå†…å®¹
                file_name = f"{step}_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                file_path = os.path.join(output_dir, file_name)
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    # å†™å…¥å…ƒæ•°æ®
                    f.write(f"# {step.capitalize()} Result\n\n")
                    f.write(f"**Generated at**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"**Model**: {result.model_used}\n")
                    f.write(f"**Processing Time**: {result.processing_time:.2f}s\n\n")
                    f.write("---\n\n")
                    
                    # å†™å…¥å†…å®¹
                    f.write(result.content)
                
                exported_files[step] = file_path
        
        # å¯¼å‡ºä¼šè¯ä¿¡æ¯
        session_info_path = os.path.join(output_dir, 'session_info.json')
        with open(session_info_path, 'w', encoding='utf-8') as f:
            json.dump(session.to_dict(), f, ensure_ascii=False, indent=2)
        
        exported_files['session_info'] = session_info_path
        
        return exported_files
    
    def clear_session(self, session_id: Optional[str] = None) -> bool:
        """
        æ¸…ç†ä¼šè¯æ•°æ®
        
        Args:
            session_id: ä¼šè¯ID
        
        Returns:
            bool: æ˜¯å¦æ¸…ç†æˆåŠŸ
        """
        session_id = session_id or self.current_session_id
        if not session_id or session_id not in self.sessions:
            return False
        
        # æ¸…ç†ä¼šè¯ç›®å½•
        session_dir = self.temp_dir / session_id
        if session_dir.exists():
            cleanup_directory(session_dir, safe_mode=False)
        
        # åˆ é™¤ä¼šè¯æ•°æ®
        del self.sessions[session_id]
        
        # å¦‚æœæ˜¯å½“å‰ä¼šè¯ï¼Œæ¸…ç©ºå½“å‰ä¼šè¯ID
        if session_id == self.current_session_id:
            self.current_session_id = None
        
        return True
    
    def list_sessions(self, 
                     active_only: bool = True,
                     limit: int = 10) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºä¼šè¯
        
        Args:
            active_only: æ˜¯å¦åªåˆ—å‡ºæ´»åŠ¨ä¼šè¯
            limit: é™åˆ¶æ•°é‡
        
        Returns:
            List[Dict]: ä¼šè¯åˆ—è¡¨
        """
        sessions_list = []
        
        for session_id, session in self.sessions.items():
            if active_only and session.status != 'active':
                continue
            
            sessions_list.append({
                'session_id': session_id,
                'workflow_type': session.workflow_type,
                'current_step': session.current_step,
                'status': session.status,
                'created_at': session.created_at,
                'updated_at': session.updated_at
            })
        
        # æŒ‰æ›´æ–°æ—¶é—´æ’åº
        sessions_list.sort(key=lambda x: x['updated_at'], reverse=True)
        
        return sessions_list[:limit]
    
    def _save_content_to_file(self, 
                            session_id: str,
                            step_name: str,
                            content: str) -> Path:
        """ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶"""
        session_dir = self.temp_dir / session_id
        ensure_directory_exists(session_dir)
        
        file_name = f"{step_name}_content.txt"
        file_path = session_dir / file_name
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return file_path
    
    def _cleanup_old_sessions(self):
        """æ¸…ç†è¿‡æœŸä¼šè¯"""
        if len(self.sessions) <= self.max_sessions:
            return
        
        # æŒ‰æ›´æ–°æ—¶é—´æ’åº
        sorted_sessions = sorted(
            self.sessions.items(),
            key=lambda x: x[1].updated_at
        )
        
        # åˆ é™¤æœ€æ—§çš„ä¼šè¯
        to_remove = len(self.sessions) - self.max_sessions
        for session_id, _ in sorted_sessions[:to_remove]:
            self.clear_session(session_id)
    
    def _load_sessions(self):
        """åŠ è½½å·²ä¿å­˜çš„ä¼šè¯ï¼ˆå¦‚æœéœ€è¦æŒä¹…åŒ–ï¼‰"""
        # MVPç‰ˆæœ¬æš‚ä¸å®ç°æŒä¹…åŒ–
        pass
    
    def _save_sessions(self):
        """ä¿å­˜ä¼šè¯ï¼ˆå¦‚æœéœ€è¦æŒä¹…åŒ–ï¼‰"""
        # MVPç‰ˆæœ¬æš‚ä¸å®ç°æŒä¹…åŒ–
        pass
    
    def cleanup_all_temp_files(self):
        """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶"""
        try:
            if self.temp_dir.exists():
                for session_dir in self.temp_dir.iterdir():
                    if session_dir.is_dir():
                        cleanup_directory(session_dir, safe_mode=False)
            return True
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def get_session_size(self, session_id: Optional[str] = None) -> int:
        """
        è·å–ä¼šè¯å ç”¨çš„ç£ç›˜ç©ºé—´
        
        Returns:
            int: å­—èŠ‚æ•°
        """
        session_id = session_id or self.current_session_id
        if not session_id:
            return 0
        
        session_dir = self.temp_dir / session_id
        if not session_dir.exists():
            return 0
        
        total_size = 0
        for file_path in session_dir.rglob('*'):
            if file_path.is_file():
                total_size += file_path.stat().st_size
        
        return total_size
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_sessions = len(self.sessions)
        active_sessions = sum(1 for s in self.sessions.values() if s.status == 'active')
        completed_sessions = sum(1 for s in self.sessions.values() if s.status == 'completed')
        
        # è®¡ç®—æ€»ç£ç›˜ä½¿ç”¨
        total_disk_usage = 0
        for session_id in self.sessions:
            total_disk_usage += self.get_session_size(session_id)
        
        return {
            'total_sessions': total_sessions,
            'active_sessions': active_sessions,
            'completed_sessions': completed_sessions,
            'total_disk_usage_mb': total_disk_usage / (1024 * 1024),
            'current_session_id': self.current_session_id
        }

--- File: env_example_file.sh ---
# SmartProposal Engine Environment Variables
# Copy this file to .env and update with your actual values

# ===================================
# API Keys and Authentication
# ===================================

# Google Gemini API Key (Required)
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Alternative: Use internal API key file (set in app_config.ini)
# If using internal key file, leave GOOGLE_API_KEY empty

# ===================================
# Application Settings
# ===================================

# Environment (development, staging, production)
ENVIRONMENT=development

# Debug mode (true/false)
DEBUG=false

# Application port (default: 8501 for Streamlit)
PORT=8501

# ===================================
# File Storage Settings
# ===================================

# Temporary files directory (default: temp/)
TEMP_DIR=temp/

# Output files directory (default: output/)
OUTPUT_DIR=output/

# Maximum file size in MB (default: 200)
MAX_FILE_SIZE_MB=200

# Auto cleanup temporary files (true/false)
AUTO_CLEANUP_TEMP_FILES=true

# ===================================
# Model Configuration
# ===================================

# Default models for different tasks
# Available models: gemini-2.5-pro, gemini-2.5-flash, gemini-1.5-pro, gemini-1.5-flash
DEFAULT_TRANSCRIPTION_MODEL=models/gemini-2.5-flash
DEFAULT_ANALYSIS_MODEL=models/gemini-2.5-pro
DEFAULT_PROPOSAL_MODEL=models/gemini-2.5-pro

# Model temperature settings (0.0 - 1.0)
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.95

# Maximum tokens per request
MAX_OUTPUT_TOKENS=16384

# ===================================
# Feature Flags
# ===================================

# Enable/disable features
ENABLE_TEXT_OPTIMIZATION=true
ENABLE_SPEAKER_DIARIZATION=true
ENABLE_CUSTOM_PROMPTS=true
ENABLE_BATCH_PROCESSING=true
ENABLE_CAPABILITY_DOCS=true

# ===================================
# Performance Settings
# ===================================

# Request timeout in seconds
REQUEST_TIMEOUT=900

# Maximum concurrent requests
MAX_CONCURRENT_REQUESTS=3

# Retry configuration
MAX_RETRIES=3
RETRY_DELAY_SECONDS=2

# Cache settings
ENABLE_CACHE=true
CACHE_TTL_HOURS=24

# ===================================
# Security Settings
# ===================================

# Session secret key (generate a random string)
SESSION_SECRET_KEY=your_secret_key_here_change_in_production

# Enable HTTPS redirect (for production)
FORCE_HTTPS=false

# Allowed file extensions (comma-separated)
ALLOWED_AUDIO_EXTENSIONS=.m4a,.mp3,.wav,.aac,.ogg,.flac,.mp4
ALLOWED_DOCUMENT_EXTENSIONS=.docx,.pdf,.txt,.doc,.rtf,.odt

# ===================================
# Logging Configuration
# ===================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path
LOG_FILE=logs/app.log

# Enable console logging
CONSOLE_LOGGING=true

# ===================================
# External Services (Future Extensions)
# ===================================

# Database URL (for future persistence features)
# DATABASE_URL=postgresql://user:password@localhost:5432/smartproposal

# Redis URL (for future caching/queuing)
# REDIS_URL=redis://localhost:6379

# Email settings (for future notifications)
# SMTP_HOST=smtp.gmail.com
# SMTP_PORT=587
# SMTP_USER=your_email@gmail.com
# SMTP_PASSWORD=your_app_password

# Cloud storage (for future cloud integration)
# AWS_ACCESS_KEY_ID=your_aws_key
# AWS_SECRET_ACCESS_KEY=your_aws_secret
# AWS_S3_BUCKET=smartproposal-uploads

# ===================================
# Analytics and Monitoring (Optional)
# ===================================

# Google Analytics
# GA_TRACKING_ID=UA-XXXXXXXXX-X

# Sentry error tracking
# SENTRY_DSN=https://your_sentry_dsn@sentry.io/project_id

# ===================================
# Development Settings
# ===================================

# Enable hot reload (for development)
HOT_RELOAD=true

# Show detailed error messages (disable in production)
SHOW_ERROR_DETAILS=true

# Enable profiling (for performance debugging)
ENABLE_PROFILING=false

# ===================================
# Notes
# ===================================
# 1. Never commit the actual .env file to version control
# 2. Keep your API keys secure and rotate them regularly
# 3. Use different API keys for different environments
# 4. Set appropriate values for production deployment
# 5. Some settings can also be configured in app_config.ini

--- File: llm_providers/__init__.py ---
# ==============================================================================
# File: core/llm_providers/__init__.py (æ–°å¢æ–‡ä»¶)
# ==============================================================================
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/llm_providers/__init__.py
åŠŸèƒ½è¯´æ˜: åˆå§‹åŒ–llm_providersåŒ…ï¼Œä½¿å…¶å¯ä»¥è¢«Pythonè§£é‡Šå™¨è¯†åˆ«å’Œå¯¼å…¥ã€‚
          åŒæ—¶ï¼Œä¸ºäº†æ–¹ä¾¿å¤–éƒ¨è°ƒç”¨ï¼Œè¿™é‡Œç›´æ¥å¯¼å‡ºäº†åŒ…å†…çš„æ ¸å¿ƒProviderç±»ã€‚
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-29
ç‰ˆæœ¬: 1.0.0
"""

# å¯¼å…¥åŸºç±»ï¼Œä½¿å…¶å¯ä»¥åœ¨åŒ…çº§åˆ«è®¿é—®
from .base_provider import BaseProvider

# å¯¼å…¥å…·ä½“çš„æä¾›å•†å®ç°ç±»
from .gemini_provider import GeminiProvider
from .qwen_provider import QwenProvider

# å®šä¹‰ __all__ï¼Œæ˜ç¡®æŒ‡å®šä»è¯¥åŒ…ä¸­ "from core.llm_providers import *" æ—¶ä¼šå¯¼å…¥å“ªäº›æ¨¡å—ã€‚
# è¿™æ˜¯ä¸€ç§è‰¯å¥½çš„ç¼–ç¨‹ä¹ æƒ¯ï¼Œå¯ä»¥æ§åˆ¶åŒ…çš„å…¬å…±APIã€‚
__all__ = [
    'BaseProvider',
    'GeminiProvider',
    'QwenProvider'
]

--- File: llm_providers/base_provider.py ---
# ==============================================================================
# File: core/llm_providers/base_provider.py (æ–°å¢æ–‡ä»¶)
# ==============================================================================
# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/llm_providers/base_provider.py
åŠŸèƒ½è¯´æ˜: å®šä¹‰æ‰€æœ‰LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰æä¾›å•†çš„æŠ½è±¡åŸºç±» (ABC)ã€‚
          è¿™ä¸ªåŸºç±»ä½œä¸ºä¸€ä¸ªæ¥å£ï¼Œç¡®ä¿æ‰€æœ‰å…·ä½“çš„æä¾›å•†å®ç°ï¼ˆå¦‚Gemini, Qwenç­‰ï¼‰
          éƒ½éµå¾ªç»Ÿä¸€çš„æ–¹æ³•ç­¾åå’Œè¡Œä¸ºè§„èŒƒï¼Œä»è€Œä½¿å¾—ModelInterfaceå¯ä»¥æ— ç¼åˆ‡æ¢å’Œè°ƒåº¦ã€‚
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-29
ç‰ˆæœ¬: 1.0.0
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Tuple, Union, Any, Generator


class BaseProvider(ABC):
    """
    LLMæä¾›å•†çš„æŠ½è±¡åŸºç±»ã€‚
    æ‰€æœ‰å…·ä½“çš„æ¨¡å‹æä¾›å•†éƒ½åº”ç»§æ‰¿æ­¤ç±»å¹¶å®ç°å…¶æ‰€æœ‰æŠ½è±¡æ–¹æ³•ã€‚
    """

    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–åŸºç¡€æä¾›å•†ã€‚

        Args:
            api_key (str): è¯¥æä¾›å•†çš„APIå¯†é’¥ã€‚

        Raises:
            ValueError: å¦‚æœAPI Keyä¸ºç©ºã€‚
        """
        if not api_key:
            raise ValueError("API Key ä¸èƒ½ä¸ºç©º")
        self.api_key = api_key
        self.is_initialized = False

    @abstractmethod
    def initialize(self) -> None:
        """
        åˆå§‹åŒ–æä¾›å•†çš„å®¢æˆ·ç«¯æˆ–SDKã€‚
        åœ¨å­ç±»ä¸­å®ç°ï¼Œä¾‹å¦‚é…ç½®APIå¯†é’¥ã€è®¾ç½®ä¼šè¯ç­‰ã€‚
        æ­¤æ–¹æ³•åº”åœ¨æˆåŠŸåˆå§‹åŒ–åè®¾ç½® self.is_initialized = Trueã€‚
        """
        pass

    @abstractmethod
    def generate(self,
                 prompt: Union[str, List[Any]],
                 model_name: str,
                 generation_config: Optional[Dict[str, Any]] = None,
                 safety_settings: Optional[List[Dict[str, Any]]] = None,
                 request_options: Optional[Dict[str, Any]] = None
                 ) -> Tuple[str, Dict[str, Any]]:
        """
        ç”Ÿæˆå†…å®¹ï¼ˆéæµå¼ï¼‰ã€‚

        Args:
            prompt (Union[str, List[Any]]): å‘é€ç»™æ¨¡å‹çš„æç¤ºï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å†…å®¹åˆ—è¡¨ã€‚
            model_name (str): è¦ä½¿ç”¨çš„å…·ä½“æ¨¡å‹åç§°ã€‚
            generation_config (Optional[Dict[str, Any]]): ç”Ÿæˆå‚æ•°é…ç½®ã€‚
            safety_settings (Optional[List[Dict[str, Any]]]): å®‰å…¨è®¾ç½®ã€‚
            request_options (Optional[Dict[str, Any]]): è¯·æ±‚é€‰é¡¹ï¼Œå¦‚è¶…æ—¶ã€‚

        Returns:
            Tuple[str, Dict[str, Any]]:
            - ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹ã€‚
            - ç¬¬äºŒä¸ªå…ƒç´ æ˜¯åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼Œè‡³å°‘åº”åŒ…å« 'input_tokens' å’Œ 'output_tokens'ã€‚
        """
        pass

    @abstractmethod
    def stream_generate(self,
                        prompt: Union[str, List[Any]],
                        model_name: str,
                        generation_config: Optional[Dict[str, Any]] = None,
                        callback: Optional[callable] = None
                        ) -> Tuple[str, Dict[str, Any]]:
        """
        æµå¼ç”Ÿæˆå†…å®¹ã€‚

        Args:
            prompt (Union[str, List[Any]]): å‘é€ç»™æ¨¡å‹çš„æç¤ºã€‚
            model_name (str): è¦ä½¿ç”¨çš„å…·ä½“æ¨¡å‹åç§°ã€‚
            generation_config (Optional[Dict[str, Any]]): ç”Ÿæˆå‚æ•°é…ç½®ã€‚
            callback (Optional[callable]): ç”¨äºå®æ—¶å¤„ç†ç”Ÿæˆå—çš„å›è°ƒå‡½æ•°ã€‚
                                          å›è°ƒå‡½æ•°åº”æ¥æ”¶ä¸€ä¸ªå‚æ•°ï¼š(chunk_text: str)ã€‚

        Returns:
            Tuple[str, Dict[str, Any]]:
            - ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æœ€ç»ˆç”Ÿæˆçš„å®Œæ•´æ–‡æœ¬ã€‚
            - ç¬¬äºŒä¸ªå…ƒç´ æ˜¯åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸ï¼Œè‡³å°‘åº”åŒ…å« 'input_tokens' å’Œ 'output_tokens'ã€‚
        """
        pass

    @abstractmethod
    def count_tokens(self, text: str, model_name: str) -> int:
        """
        è®¡ç®—ç»™å®šæ–‡æœ¬çš„tokenæ•°é‡ã€‚

        Args:
            text (str): éœ€è¦è®¡ç®—tokençš„æ–‡æœ¬ã€‚
            model_name (str): ç”¨äºè®¡ç®—tokençš„æ¨¡å‹åç§°ï¼ˆä¸åŒæ¨¡å‹åˆ†è¯æ–¹å¼å¯èƒ½ä¸åŒï¼‰ã€‚

        Returns:
            int: tokençš„æ€»æ•°ã€‚
        """
        pass

    def health_check(self) -> Dict[str, Any]:
        """
        å¯¹æä¾›å•†æœåŠ¡è¿›è¡Œå¥åº·æ£€æŸ¥ã€‚
        å­ç±»å¯ä»¥é‡å†™æ­¤æ–¹æ³•ä»¥æä¾›æ›´è¯¦ç»†çš„æ£€æŸ¥ã€‚
        """
        if not self.is_initialized:
            return {
                'status': 'unhealthy',
                'reason': 'Provider not initialized.'
            }

        # é»˜è®¤çš„å¥åº·æ£€æŸ¥é€»è¾‘ï¼ˆå­ç±»å¯ä»¥æ‰©å±•ï¼‰
        # å°è¯•ä½¿ç”¨ä¸€ä¸ªéå¸¸ç®€çŸ­çš„ã€ä½æˆæœ¬çš„è°ƒç”¨æ¥éªŒè¯API Keyå’Œè¿æ¥æ€§
        try:
            # è¿™é‡Œå¯ä»¥æ”¾ä¸€ä¸ªç®€å•çš„æµ‹è¯•è°ƒç”¨ï¼Œä½†ä¸ºäº†é¿å…ä¸å¿…è¦çš„å¼€é”€ï¼Œ
            # åŸºç¡€å®ç°ä»…æ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€ã€‚
            # å…·ä½“çš„APIè°ƒç”¨æµ‹è¯•å¯ä»¥åœ¨å­ç±»ä¸­å®ç°ã€‚
            return {
                'status': 'healthy',
                'reason': 'Provider is initialized.'
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'reason': f'Health check failed: {str(e)}'
            }


# è¿™ä¸ªæ–‡ä»¶å®šä¹‰çš„æ˜¯æŠ½è±¡ç±»ï¼Œä¸åº”è¯¥è¢«ç›´æ¥è¿è¡Œã€‚
# if __name__ == "__main__" å—ç”¨äºè¯´æ˜æ­¤æ–‡ä»¶çš„ç”¨é€”ã€‚
if __name__ == "__main__":
    print("è¿™æ˜¯ä¸€ä¸ªæŠ½è±¡åŸºç±»æ–‡ä»¶ï¼Œä¸åº”ç›´æ¥è¿è¡Œã€‚")
    print("è¯·åˆ›å»ºå…·ä½“çš„æä¾›å•†ç±»ï¼ˆå¦‚ GeminiProvider, QwenProviderï¼‰å¹¶ç»§æ‰¿è‡ª BaseProviderã€‚")

--- File: llm_providers/gemini_provider.py ---
# ==============================================================================
# File: core/llm_providers/gemini_provider.py (æ–°å¢æ–‡ä»¶)
# ==============================================================================
# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/llm_providers/gemini_provider.py
åŠŸèƒ½è¯´æ˜: å®ç°äº†é’ˆå¯¹Google Geminiæ¨¡å‹çš„å…·ä½“Providerã€‚
          è¯¥ç±»å°è£…äº†æ‰€æœ‰ä¸Gemini APIäº¤äº’çš„ç»†èŠ‚ï¼ŒåŒ…æ‹¬åˆå§‹åŒ–ã€å†…å®¹ç”Ÿæˆã€
          æµå¼å¤„ç†ã€Tokenè®¡ç®—ä»¥åŠé”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘ã€‚
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-29
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import time
from typing import Dict, List, Optional, Tuple, Union, Any

# åŠ¨æ€æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import google.generativeai as genai
except ImportError:
    # å‹å¥½æç¤ºï¼Œé¿å…åœ¨æœªå®‰è£…ä¾èµ–æ—¶ç¨‹åºå´©æºƒ
    raise ImportError(
        "Google Geminiçš„ä¾èµ–åº“ 'google-generativeai' æœªå®‰è£…ã€‚"
        "è¯·è¿è¡Œ 'pip install google-generativeai' è¿›è¡Œå®‰è£…ã€‚"
    )

from .base_provider import BaseProvider


class GeminiProvider(BaseProvider):
    """
    é’ˆå¯¹Google Geminiæ¨¡å‹çš„LLM Providerå®ç°ã€‚
    """

    def __init__(self, api_key: str, max_retries: int = 3):
        """
        åˆå§‹åŒ–GeminiProviderã€‚

        Args:
            api_key (str): Google AI Studioçš„APIå¯†é’¥ã€‚
            max_retries (int): APIè¯·æ±‚å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚
        """
        super().__init__(api_key)
        self.max_retries = max_retries

    def initialize(self) -> None:
        """
        é…ç½®Gemini APIå¯†é’¥å¹¶éªŒè¯ã€‚
        """
        try:
            genai.configure(api_key=self.api_key)
            # å¯é€‰ï¼šè¿›è¡Œä¸€æ¬¡è½»é‡çº§çš„å¥åº·æ£€æŸ¥æ¥ç¡®è®¤API Keyçš„æœ‰æ•ˆæ€§
            # ä¾‹å¦‚ï¼Œåˆ—å‡ºæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªä½æˆæœ¬çš„æ“ä½œ
            models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            if not models:
                raise ConnectionError("API Keyæœ‰æ•ˆï¼Œä½†æœªæ‰¾åˆ°å¯ç”¨çš„ç”Ÿæˆæ¨¡å‹ã€‚")
            self.is_initialized = True
            print("âœ… Gemini Provider åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            self.is_initialized = False
            print(f"âŒ Gemini Provider åˆå§‹åŒ–å¤±è´¥: {e}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œä»¥ä¾¿ä¸Šå±‚å¯ä»¥æ•è·
            raise ConnectionError(f"æ— æ³•é…ç½®Gemini APIï¼Œè¯·æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®ã€‚é”™è¯¯: {e}")

    def generate(self,
                 prompt: Union[str, List[Any]],
                 model_name: str,
                 generation_config: Optional[Dict[str, Any]] = None,
                 safety_settings: Optional[List[Dict[str, Any]]] = None,
                 request_options: Optional[Dict[str, Any]] = None
                 ) -> Tuple[str, Dict[str, Any]]:
        """
        ä½¿ç”¨Geminiæ¨¡å‹ç”Ÿæˆå†…å®¹ï¼ˆéæµå¼ï¼‰ã€‚
        """
        if not self.is_initialized:
            raise RuntimeError("Gemini Providerå°šæœªåˆå§‹åŒ–ã€‚")

        return self._generate_with_retry(
            prompt, model_name, generation_config,
            safety_settings, request_options, retry_count=0
        )

    def _generate_with_retry(self,
                             prompt: Union[str, List[Any]],
                             model_name: str,
                             generation_config: Optional[Dict[str, Any]],
                             safety_settings: Optional[List[Dict[str, Any]]],
                             request_options: Optional[Dict[str, Any]],
                             retry_count: int) -> Tuple[str, Dict[str, Any]]:
        """å†…éƒ¨æ–¹æ³•ï¼ŒåŒ…å«é‡è¯•é€»è¾‘çš„ç”Ÿæˆå®ç°ã€‚"""
        try:
            model = genai.GenerativeModel(model_name)

            # è®¾ç½®é»˜è®¤é…ç½®
            final_gen_config = {
                'temperature': 0.7, 'top_p': 0.95,
                'max_output_tokens': 16384, 'response_mime_type': 'text/plain'
            }
            if generation_config:
                final_gen_config.update(generation_config)

            final_safety_settings = safety_settings or [
                {"category": c, "threshold": "BLOCK_MEDIUM_AND_ABOVE"} for c in
                ["HARM_CATEGORY_HARASSMENT", "HARM_CATEGORY_HATE_SPEECH",
                 "HARM_CATEGORY_SEXUALLY_EXPLICIT", "HARM_CATEGORY_DANGEROUS_CONTENT"]
            ]

            final_request_options = {"timeout": 900}
            if request_options:
                final_request_options.update(request_options)

            # è°ƒç”¨API
            response = model.generate_content(
                prompt,
                generation_config=final_gen_config,
                safety_settings=final_safety_settings,
                request_options=final_request_options
            )

            response_text = response.text

            # ä¼˜å…ˆä»APIè¿”å›çš„å…ƒæ•°æ®ä¸­è·å–ç²¾ç¡®çš„tokenæ•°
            if hasattr(response, 'usage_metadata'):
                input_tokens = response.usage_metadata.prompt_token_count
                output_tokens = response.usage_metadata.candidates_token_count
            else:
                # å¦‚æœAPIæœªè¿”å›ï¼Œåˆ™è¿›è¡Œä¼°ç®—
                input_tokens = self._estimate_tokens(str(prompt))
                output_tokens = self._estimate_tokens(response_text)

            stats = {
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
            }

            return response_text, stats

        except Exception as e:
            error_msg = str(e)
            if retry_count < self.max_retries and self._should_retry(error_msg):
                wait_time = 2 ** retry_count
                print(f"Geminiè¯·æ±‚å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... (å°è¯• {retry_count + 1}/{self.max_retries})")
                time.sleep(wait_time)
                return self._generate_with_retry(
                    prompt, model_name, generation_config, safety_settings,
                    request_options, retry_count + 1
                )
            # é‡è¯•æ¬¡æ•°ç”¨å°½æˆ–é‡åˆ°ä¸å¯é‡è¯•é”™è¯¯ï¼Œåˆ™ç›´æ¥æŠ›å‡º
            raise Exception(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {error_msg}")

    def stream_generate(self,
                        prompt: Union[str, List[Any]],
                        model_name: str,
                        generation_config: Optional[Dict[str, Any]] = None,
                        callback: Optional[callable] = None
                        ) -> Tuple[str, Dict[str, Any]]:
        """
        ä½¿ç”¨Geminiæ¨¡å‹æµå¼ç”Ÿæˆå†…å®¹ã€‚
        """
        if not self.is_initialized:
            raise RuntimeError("Gemini Providerå°šæœªåˆå§‹åŒ–ã€‚")

        try:
            model = genai.GenerativeModel(model_name)
            final_gen_config = {'temperature': 0.7, 'top_p': 0.95, 'max_output_tokens': 16384}
            if generation_config:
                final_gen_config.update(generation_config)

            response_stream = model.generate_content(
                prompt, generation_config=final_gen_config, stream=True
            )

            complete_response = ""
            for chunk in response_stream:
                if chunk.text:
                    complete_response += chunk.text
                    if callback:
                        try:
                            callback(chunk.text)
                        except Exception as cb_e:
                            print(f"æµå¼å›è°ƒå‡½æ•°æ‰§è¡Œå‡ºé”™: {cb_e}")

            # æµå¼ä¼ è¾“å®Œæˆåï¼Œä»å“åº”å¯¹è±¡è·å–tokenä½¿ç”¨é‡
            if hasattr(response_stream, 'usage_metadata'):
                input_tokens = response_stream.usage_metadata.prompt_token_count
                output_tokens = response_stream.usage_metadata.candidates_token_count
            else:
                input_tokens = self._estimate_tokens(str(prompt))
                output_tokens = self._estimate_tokens(complete_response)

            stats = {
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
            }

            return complete_response, stats
        except Exception as e:
            raise Exception(f"æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}")

    def count_tokens(self, text: str, model_name: str) -> int:
        """
        ä½¿ç”¨Gemini APIè®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡ã€‚
        """
        if not self.is_initialized:
            print("è­¦å‘Š: Gemini Provideræœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ä¼°ç®—æ–¹æ³•è®¡ç®—tokenã€‚")
            return self._estimate_tokens(text)

        try:
            model = genai.GenerativeModel(model_name)
            result = model.count_tokens(text)
            return result.total_tokens
        except Exception as e:
            print(f"è°ƒç”¨Gemini APIè®¡ç®—Tokenå¤±è´¥ï¼Œä½¿ç”¨ä¼°ç®—å€¼: {e}")
            return self._estimate_tokens(text)

    def _should_retry(self, error_msg: str) -> bool:
        """åˆ¤æ–­é”™è¯¯æ˜¯å¦åº”è¯¥é‡è¯•"""
        retry_keywords = [
            'rate limit', 'quota exceeded', 'timeout', 'temporary', 'unavailable',
            '503 service unavailable', 'resource has been exhausted',
            '429', '500', '503', '504'
        ]
        error_lower = error_msg.lower()
        return any(keyword in error_lower for keyword in retry_keywords)

    def _estimate_tokens(self, text: Union[str, Any]) -> int:
        """åå¤‡æ–¹æ³•ï¼šä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        if not isinstance(text, str):
            text = str(text)

        # ä¸€ä¸ªæ›´é€šç”¨çš„ä¼°ç®—æ–¹æ³•ï¼šå¹³å‡æ¯ä¸ªå­—ç¬¦çº¦0.3ä¸ªtoken
        return int(len(text) * 0.3) + 1


# æ¨¡å—ç‹¬ç«‹æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("è¿™æ˜¯ä¸€ä¸ªå…·ä½“çš„Providerå®ç°æ–‡ä»¶ï¼Œä¸åº”ç›´æ¥è¿è¡Œã€‚")
    print("è¯·é€šè¿‡ ModelInterface æ¥è°ƒç”¨ã€‚")

--- File: llm_providers/qwen_provider.py ---
# ==============================================================================
# File: core/llm_providers/qwen_provider.py (æ–°å¢æ–‡ä»¶)
# ==============================================================================
# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/core/llm_providers/qwen_provider.py
åŠŸèƒ½è¯´æ˜: å®ç°äº†é’ˆå¯¹é˜¿é‡Œé€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ¨¡å‹çš„å…·ä½“Providerã€‚
          è¯¥ç±»ä½¿ç”¨dashscope SDKï¼Œå°è£…äº†ä¸Qwenæ¨¡å‹äº¤äº’çš„æ‰€æœ‰ç»†èŠ‚ï¼Œ
          åŒ…æ‹¬åˆå§‹åŒ–ã€å†…å®¹ç”Ÿæˆã€æµå¼å¤„ç†ã€Tokenè®¡ç®—ä»¥åŠé”™è¯¯å¤„ç†ã€‚
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-29
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import time
from http import HTTPStatus
from typing import Dict, List, Optional, Tuple, Union, Any

# åŠ¨æ€æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import dashscope
except ImportError:
    # å‹å¥½æç¤ºï¼Œé¿å…åœ¨æœªå®‰è£…ä¾èµ–æ—¶ç¨‹åºå´©æºƒ
    raise ImportError(
        "é€šä¹‰åƒé—®çš„ä¾èµ–åº“ 'dashscope' æœªå®‰è£…ã€‚"
        "è¯·è¿è¡Œ 'pip install \"dashscope>=1.16.1\"' è¿›è¡Œå®‰è£…ã€‚"
    )

from .base_provider import BaseProvider


class QwenProvider(BaseProvider):
    """
    é’ˆå¯¹é˜¿é‡Œé€šä¹‰åƒé—®ï¼ˆQwenï¼‰æ¨¡å‹çš„LLM Providerå®ç°ã€‚
    """

    def __init__(self, api_key: str, max_retries: int = 3):
        """
        åˆå§‹åŒ–QwenProviderã€‚

        Args:
            api_key (str): DashScopeçš„APIå¯†é’¥ã€‚
            max_retries (int): APIè¯·æ±‚å¤±è´¥æ—¶çš„æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚
        """
        super().__init__(api_key)
        self.max_retries = max_retries

    def initialize(self) -> None:
        """
        é…ç½®DashScope APIå¯†é’¥å¹¶éªŒè¯ã€‚
        """
        try:
            dashscope.api_key = self.api_key
            # é€šè¿‡åˆ—å‡ºæ¨¡å‹æ¥éªŒè¯API Keyçš„æœ‰æ•ˆæ€§
            models = dashscope.Model.list()
            if not models or models.get('data') is None:
                raise ConnectionError("API Keyå¯èƒ½æ— æ•ˆï¼Œæ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ã€‚")
            self.is_initialized = True
            print("âœ… Qwen Provider (DashScope) åˆå§‹åŒ–æˆåŠŸã€‚")
        except Exception as e:
            self.is_initialized = False
            print(f"âŒ Qwen Provider åˆå§‹åŒ–å¤±è´¥: {e}")
            raise ConnectionError(f"æ— æ³•é…ç½®DashScope APIï¼Œè¯·æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®ã€‚é”™è¯¯: {e}")

    def generate(self,
                 prompt: Union[str, List[Any]],
                 model_name: str,
                 generation_config: Optional[Dict[str, Any]] = None,
                 safety_settings: Optional[List[Dict[str, Any]]] = None,  # Qwenæš‚ä¸ç›´æ¥ä½¿ç”¨æ­¤æ ¼å¼çš„safety_settings
                 request_options: Optional[Dict[str, Any]] = None
                 ) -> Tuple[str, Dict[str, Any]]:
        """
        ä½¿ç”¨Qwenæ¨¡å‹ç”Ÿæˆå†…å®¹ï¼ˆéæµå¼ï¼‰ã€‚
        """
        if not self.is_initialized:
            raise RuntimeError("Qwen Providerå°šæœªåˆå§‹åŒ–ã€‚")

        # Qwen APIé€šå¸¸éœ€è¦ä¸€ä¸ªå­—ç¬¦ä¸²promptï¼Œæˆ‘ä»¬å°†åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(prompt, list):
            prompt = "\n".join(str(p) for p in prompt)

        return self._generate_with_retry(
            prompt, model_name, generation_config, request_options, retry_count=0
        )

    def _generate_with_retry(self,
                             prompt: str,
                             model_name: str,
                             generation_config: Optional[Dict[str, Any]],
                             request_options: Optional[Dict[str, Any]],
                             retry_count: int) -> Tuple[str, Dict[str, Any]]:
        """å†…éƒ¨æ–¹æ³•ï¼ŒåŒ…å«é‡è¯•é€»è¾‘çš„ç”Ÿæˆå®ç°ã€‚"""
        try:
            # åˆå¹¶å’Œå‡†å¤‡å‚æ•°
            final_gen_config = generation_config or {}
            timeout = request_options.get('timeout', 600) if request_options else 600

            response = dashscope.Generation.call(
                model=model_name,
                prompt=prompt,
                stream=False,
                timeout=timeout,
                **final_gen_config
            )

            if response.status_code == HTTPStatus.OK:
                response_text = response.output.text
                stats = {
                    'input_tokens': response.usage.input_tokens,
                    'output_tokens': response.usage.output_tokens
                }
                return response_text, stats
            else:
                # APIè¿”å›é200çŠ¶æ€ç 
                raise Exception(f"API Error: {response.code} - {response.message}")

        except Exception as e:
            error_msg = str(e)
            if retry_count < self.max_retries and self._should_retry(error_msg):
                wait_time = 2 ** retry_count
                print(f"Qwenè¯·æ±‚å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... (å°è¯• {retry_count + 1}/{self.max_retries})")
                time.sleep(wait_time)
                return self._generate_with_retry(
                    prompt, model_name, generation_config, request_options, retry_count + 1
                )
            # é‡è¯•æ¬¡æ•°ç”¨å°½æˆ–é‡åˆ°ä¸å¯é‡è¯•é”™è¯¯
            raise Exception(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {error_msg}")

    def stream_generate(self,
                        prompt: Union[str, List[Any]],
                        model_name: str,
                        generation_config: Optional[Dict[str, Any]] = None,
                        callback: Optional[callable] = None
                        ) -> Tuple[str, Dict[str, Any]]:
        """
        ä½¿ç”¨Qwenæ¨¡å‹æµå¼ç”Ÿæˆå†…å®¹ã€‚
        """
        if not self.is_initialized:
            raise RuntimeError("Qwen Providerå°šæœªåˆå§‹åŒ–ã€‚")

        if isinstance(prompt, list):
            prompt = "\n".join(str(p) for p in prompt)

        try:
            final_gen_config = generation_config or {}
            response_stream = dashscope.Generation.call(
                model=model_name,
                prompt=prompt,
                stream=True,
                **final_gen_config
            )

            complete_response = ""
            last_chunk = None
            for chunk in response_stream:
                if chunk.status_code == HTTPStatus.OK:
                    partial_text = chunk.output.text
                    # dashscopeæµå¼è¿”å›çš„æ˜¯ç´¯ç§¯æ–‡æœ¬ï¼Œéœ€è¦å–å¢é‡éƒ¨åˆ†
                    new_text = partial_text[len(complete_response):]
                    complete_response = partial_text

                    if callback and new_text:
                        try:
                            callback(new_text)
                        except Exception as cb_e:
                            print(f"æµå¼å›è°ƒå‡½æ•°æ‰§è¡Œå‡ºé”™: {cb_e}")
                    last_chunk = chunk
                else:
                    raise Exception(f"æµå¼APIé”™è¯¯: {chunk.code} - {chunk.message}")

            if last_chunk:
                stats = {
                    'input_tokens': last_chunk.usage.input_tokens,
                    'output_tokens': last_chunk.usage.output_tokens
                }
            else:
                # å¦‚æœæµä¸ºç©ºï¼Œåˆ™ä¼°ç®—
                stats = {
                    'input_tokens': self._estimate_tokens(prompt),
                    'output_tokens': 0
                }

            return complete_response, stats

        except Exception as e:
            raise Exception(f"æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}")

    def count_tokens(self, text: str, model_name: str) -> int:
        """
        ä½¿ç”¨DashScope APIè®¡ç®—æ–‡æœ¬çš„tokenæ•°é‡ã€‚
        """
        if not self.is_initialized:
            print("è­¦å‘Š: Qwen Provideræœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ä¼°ç®—æ–¹æ³•è®¡ç®—tokenã€‚")
            return self._estimate_tokens(text)

        try:
            response = dashscope.Tokenization.call(
                model=model_name,
                prompt=text
            )
            if response.status_code == HTTPStatus.OK:
                return response.usage.prompt_tokens
            else:
                print(f"è°ƒç”¨DashScope APIè®¡ç®—Tokenå¤±è´¥: {response.message}ï¼Œä½¿ç”¨ä¼°ç®—å€¼ã€‚")
                return self._estimate_tokens(text)
        except Exception as e:
            print(f"è°ƒç”¨DashScope APIè®¡ç®—Tokenæ—¶å‘ç”Ÿå¼‚å¸¸: {e}ï¼Œä½¿ç”¨ä¼°ç®—å€¼ã€‚")
            return self._estimate_tokens(text)

    def _should_retry(self, error_msg: str) -> bool:
        """åˆ¤æ–­é”™è¯¯æ˜¯å¦åº”è¯¥é‡è¯•"""
        # DashScope å¸¸è§çš„å¯é‡è¯•é”™è¯¯ç æˆ–ä¿¡æ¯
        retry_keywords = [
            'throttling', 'qps rate-limit', 'service is unavailable', 'timeout',
            'serviceunavailable', 'systemerror', 'internalservererror',
            '503', '504'
        ]
        error_lower = error_msg.lower()
        return any(keyword in error_lower for keyword in retry_keywords)

    def _estimate_tokens(self, text: Union[str, Any]) -> int:
        """åå¤‡æ–¹æ³•ï¼šä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        if not isinstance(text, str):
            text = str(text)

        # Qwençš„åˆ†è¯å¯¹ä¸­æ–‡æ›´å‹å¥½ï¼Œç®€å•ä¼°ç®—å¯ä»¥è®¤ä¸º1ä¸ªæ±‰å­—çº¦ç­‰äº1ä¸ªtoken
        chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
        other_chars = len(text) - chinese_chars
        # å…¶ä»–å­—ç¬¦ï¼ˆè‹±æ–‡ã€æ•°å­—ã€ç¬¦å·ï¼‰å¤§è‡´æŒ‰æ¯4ä¸ªå­—ç¬¦1ä¸ªtokenä¼°ç®—
        estimated_tokens = chinese_chars + (other_chars // 4)
        return int(estimated_tokens) + 1


# æ¨¡å—ç‹¬ç«‹æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("è¿™æ˜¯ä¸€ä¸ªå…·ä½“çš„Providerå®ç°æ–‡ä»¶ï¼Œä¸åº”ç›´æ¥è¿è¡Œã€‚")
    print("è¯·é€šè¿‡ ModelInterface æ¥è°ƒç”¨ã€‚")

--- File: models.conf ---
# ==============================================================================
# File: models.conf (ä¿®æ”¹å)
# ==============================================================================
# SmartProposal Engine æ¨¡å‹é…ç½®æ–‡ä»¶
#
# æ­¤æ–‡ä»¶å®šä¹‰äº†æ‰€æœ‰å¯ä¾›åº”ç”¨é€‰æ‹©çš„AIæ¨¡å‹åŠå…¶ç›¸å…³å±æ€§ã€‚
# æ ¼å¼: provider,model_api_name,display_name,input_price_per_million_tokens,output_price_per_million_tokens
#
# - provider: æ¨¡å‹æä¾›å•†çš„æ ‡è¯†ç¬¦ (ä¾‹å¦‚: Gemini, Qwen)ï¼Œå¿…é¡»ä¸ ModelInterface ä¸­çš„é€»è¾‘å¯¹åº”ã€‚
# - model_api_name: è°ƒç”¨æœåŠ¡æä¾›å•†APIæ—¶ä½¿ç”¨çš„ç¡®åˆ‡æ¨¡å‹åç§°ã€‚
# - display_name: åœ¨åº”ç”¨UIä¸‹æ‹‰èœå•ä¸­æ˜¾ç¤ºç»™ç”¨æˆ·çš„åç§°ï¼Œå¯ä»¥åŒ…å«ç®€è¦è¯´æ˜ã€‚
# - input_price_per_million_tokens: æ¯ç™¾ä¸‡è¾“å…¥tokençš„ç¾å…ƒä»·æ ¼ã€‚
# - output_price_per_million_tokens: æ¯ç™¾ä¸‡è¾“å‡ºtokençš„ç¾å…ƒä»·æ ¼ã€‚
#
# ä»·æ ¼ä¿¡æ¯ç”¨äºæˆæœ¬ä¼°ç®—ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µæ›´æ–°ã€‚

# --- Gemini æ¨¡å‹é…ç½® (æ ¹æ® 2024-06-17 å®˜æ–¹ä»·æ ¼æ›´æ–°) ---

# --- Gemini 2.5 ç³»åˆ— (æœ€æ–°) ---
Gemini,models/gemini-2.5-pro,Gemini 2.5 Pro (æœ€å¼ºæ¨è),1.25,10.00
Gemini,models/gemini-2.5-flash,Gemini 2.5 Flash (éŸ³é¢‘ä¼˜åŒ–),1.00,2.50
Gemini,models/gemini-2.5-flash-lite-preview,Gemini 2.5 Flash-Lite (æœ€å¿«éŸ³é¢‘),0.50,0.40

# --- Gemini 1.5 ç³»åˆ— (ç¨³å®š) ---
Gemini,models/gemini-1.5-pro-latest,Gemini 1.5 Pro (ç»å…¸æ——èˆ°),1.25,5.00
Gemini,models/gemini-1.5-flash-latest,Gemini 1.5 Flash (é«˜æ€§ä»·æ¯”),0.075,0.30
Gemini,models/gemini-1.5-flash-8b,Gemini 1.5 Flash-8B (æœ€ç»æµ),0.0375,0.15

# --- Qwen (é€šä¹‰åƒé—®) æ¨¡å‹ç¤ºä¾‹ (ä»·æ ¼ä¸ºå‡è®¾ï¼Œè¯·æ ¹æ®å®˜æ–¹å®šä»·ä¿®æ”¹) ---
# ã€æ–°å¢ã€‘ä»¥ä¸‹æ˜¯æ–°å¢çš„Qwenæ¨¡å‹é…ç½®
# model_api_name åº”ä¸ºdashscope SDKæ”¯æŒçš„æ¨¡å‹ID
Qwen,qwen-long,Qwen Long (é•¿æ–‡æœ¬),0.0007,0.0014
Qwen,qwen-max,Qwen Max (æ——èˆ°),0.0167,0.0167
Qwen,qwen-plus,Qwen Plus (å¢å¼º),0.0028,0.0028
Qwen,qwen-turbo,Qwen Turbo (é«˜é€Ÿ),0.0011,0.0011

--- File: pages/0_ğŸ”‘_Configuration.py ---
# pages/0_ğŸ”‘_Configuration.py

import streamlit as st
import configparser
from pathlib import Path
import sys
import os

# ç¡®ä¿èƒ½æ‰¾åˆ°æ ¸å¿ƒæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.model_interface import ModelInterface

st.set_page_config(page_title="åˆå§‹åŒ–é…ç½®", page_icon="ğŸ”‘", layout="centered")

st.title("ğŸ”‘ ç³»ç»Ÿåˆå§‹åŒ–é…ç½®")
st.markdown("åœ¨ä½¿ç”¨å‰ï¼Œè¯·å…ˆå®ŒæˆAPI Keyå’Œæ¨¡å‹çš„é…ç½®ã€‚")

# --- Session State åˆå§‹åŒ– ---
if 'app_settings' not in st.session_state:
    st.session_state.app_settings = {
        "api_key": "",
        "model_provider": "Gemini", # é»˜è®¤æä¾›å•†
        "transcription_model": "",
        "analysis_model": "",
        "proposal_model": "",
        "config_completed": False
    }

# --- åŠ è½½æ¨¡å‹é…ç½® ---
# (æ­¤å¤„çš„æ¨¡å‹åŠ è½½é€»è¾‘å°†åœ¨ç¬¬äºŒé˜¶æ®µé‡æ„ ModelInterface åå˜å¾—æ›´ä¼˜é›…)
# æš‚æ—¶ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹å¼æ¥æ¼”ç¤º
def load_available_models():
    # åœ¨ç¬¬äºŒé˜¶æ®µï¼Œè¿™é‡Œä¼šä» ModelInterface è·å–
    # å‡è®¾ models.conf å·²ç»æŒ‰æ–°æ ¼å¼ä¿®æ”¹
    return {
        "Gemini": ["models/gemini-2.5-flash", "models/gemini-2.5-pro", "models/gemini-1.5-pro-latest"],
        "Qwen": ["qwen-turbo", "qwen-long"],
        # ... å…¶ä»–æ¨¡å‹æä¾›å•†
    }

available_models = load_available_models()
model_providers = list(available_models.keys())

# --- ç•Œé¢è¡¨å• ---
with st.form("config_form"):
    st.subheader("1. API é…ç½®")
    api_key = st.text_input(
        "API Key",
        type="password",
        placeholder="è¯·è¾“å…¥æ‚¨çš„API Key",
        help="æ‚¨çš„API Keyå°†ä»…åœ¨æœ¬æ¬¡ä¼šè¯ä¸­ä¿å­˜ï¼Œä¸ä¼šè¢«å­˜å‚¨åˆ°æœåŠ¡å™¨ã€‚",
        value=st.session_state.app_settings.get("api_key", "")
    )

    st.subheader("2. æ¨¡å‹é€‰æ‹©")
    model_provider = st.selectbox(
        "é€‰æ‹©æ¨¡å‹æä¾›å•†",
        options=model_providers,
        index=model_providers.index(st.session_state.app_settings.get("model_provider", "Gemini"))
    )

    # æ ¹æ®é€‰æ‹©çš„æä¾›å•†ï¼ŒåŠ¨æ€æ›´æ–°å­æ¨¡å‹åˆ—è¡¨
    sub_models = available_models.get(model_provider, [])

    transcription_model = st.selectbox(
        "è½¬å½•æ¨¡å‹ (ç”¨äºéŸ³é¢‘å¤„ç†)",
        options=sub_models,
        help="æ¨èä½¿ç”¨é’ˆå¯¹éŸ³é¢‘ä¼˜åŒ–çš„æ¨¡å‹ï¼Œå¦‚ gemini-2.5-flash"
    )

    analysis_model = st.selectbox(
        "åˆ†ææ¨¡å‹ (ç”¨äºæ·±åº¦åˆ†æ)",
        options=sub_models,
        help="æ¨èä½¿ç”¨èƒ½åŠ›æ›´å¼ºçš„æ¨¡å‹ï¼Œå¦‚ gemini-2.5-pro"
    )

    proposal_model = st.selectbox(
        "æ–¹æ¡ˆç”Ÿæˆæ¨¡å‹ (ç”¨äºæœ€ç»ˆè¾“å‡º)",
        options=sub_models,
        help="æ¨èä½¿ç”¨èƒ½åŠ›æœ€å¼ºçš„æ¨¡å‹ï¼Œå¦‚ gemini-2.5-pro"
    )

    submitted = st.form_submit_button("âœ… ä¿å­˜é…ç½®", use_container_width=True, type="primary")

# --- è¡¨å•æäº¤é€»è¾‘ ---
if submitted:
    if not api_key:
        st.error("API Key ä¸èƒ½ä¸ºç©ºï¼")
    else:
        # ä¿å­˜é…ç½®åˆ° session_state
        st.session_state.app_settings["api_key"] = api_key
        st.session_state.app_settings["model_provider"] = model_provider
        st.session_state.app_settings["transcription_model"] = transcription_model
        st.session_state.app_settings["analysis_model"] = analysis_model
        st.session_state.app_settings["proposal_model"] = proposal_model
        st.session_state.app_settings["config_completed"] = True

        # çœŸæ­£çš„åˆå§‹åŒ–åœ¨è¿™é‡Œå‘ç”Ÿ
        if 'model_interface' in st.session_state:
            try:
                # ä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„Keyå’Œæ¨¡å‹é€‰æ‹©æ¥é…ç½® ModelInterface
                model_interface = st.session_state.model_interface
                model_interface.set_api_key(api_key) # éœ€è¦åœ¨ModelInterfaceä¸­æ–°å¢æ­¤æ–¹æ³•
                model_interface.set_model('transcription', transcription_model)
                model_interface.set_model('analysis', analysis_model)
                model_interface.set_model('proposal', proposal_model)
                model_interface.initialize_genai() # éœ€è¦åœ¨ModelInterfaceä¸­æ–°å¢æ­¤æ–¹æ³•
                st.session_state.model_initialized = True
                st.success("é…ç½®æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨å…¶ä»–åŠŸèƒ½äº†ã€‚")
            except Exception as e:
                st.session_state.model_initialized = False
                st.error(f"é…ç½®å¤±è´¥ï¼Œè¯·æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®: {e}")
        else:
            st.error("æ ¸å¿ƒæ¨¡å‹æ¥å£æœªåŠ è½½ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚")

--- File: pages/1_ğŸ“„_Input_Processing.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/pages/1_ğŸ“„_Input_Processing.py
åŠŸèƒ½è¯´æ˜: å†…å®¹è¾“å…¥å¤„ç†é¡µé¢
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-29
ç‰ˆæœ¬: 1.1.0
"""

import os
import sys
import streamlit as st
from pathlib import Path
from datetime import datetime
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.document_processor import DocumentProcessor
from core.session_manager import SessionManager
from utils.file_utils import (
    save_uploaded_file,
    get_file_metadata,
    format_file_size,
    prepare_download_file
)
from utils.format_utils import (
    format_metadata_display,
    format_duration,
    truncate_text
)
from utils.validation_utils import validate_text_input
from utils.ui_utils import check_api_key_setup  # å¼•å…¥æ£€æŸ¥å‡½æ•°

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="å†…å®¹è¾“å…¥å¤„ç† - SmartProposal Engine",
    page_icon="ğŸ“„",
    layout="wide"
)


def initialize_page_state():
    """åˆå§‹åŒ–é¡µé¢çŠ¶æ€"""
    if 'input_processing' not in st.session_state:
        st.session_state.input_processing = {
            'current_tab': 'file_upload',
            'processing_result': None,
            'processing_history': [],
            'temp_file_path': None,
            'current_progress': 0  # æ·»åŠ è¿›åº¦è·Ÿè¸ª
        }

    # ç¡®ä¿SessionManagerå­˜åœ¨
    if 'session_manager' not in st.session_state:
        st.session_state.session_manager = SessionManager()

    # åˆ›å»ºæˆ–è·å–å½“å‰ä¼šè¯
    if not st.session_state.session_manager.current_session_id:
        st.session_state.session_manager.create_session('input_processing')


def show_file_upload_tab():
    """æ˜¾ç¤ºæ–‡ä»¶ä¸Šä¼ æ ‡ç­¾é¡µ"""
    st.markdown("### ğŸ“ æ–‡ä»¶ä¸Šä¼ ")

    # æ”¯æŒçš„æ ¼å¼è¯´æ˜
    col1, col2 = st.columns(2)

    with col1:
        st.info("""
        **æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼š**
        - M4A, MP3, WAV, AAC, OGG, FLAC
        - æœ€å¤§æ–‡ä»¶å¤§å°ï¼š200 MB
        - æ”¯æŒè¶…é•¿éŸ³é¢‘è‡ªåŠ¨åˆ†å‰²
        """)

    with col2:
        st.info("""
        **æ”¯æŒçš„æ–‡æ¡£æ ¼å¼ï¼š**
        - DOCX, PDF, TXT, DOC, RTF
        - æœ€å¤§æ–‡ä»¶å¤§å°ï¼š50 MB
        - è‡ªåŠ¨æå–æ–‡æ¡£å†…å®¹å’Œå…ƒæ•°æ®
        """)

    # æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    uploaded_file = st.file_uploader(
        "é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶",
        type=['m4a', 'mp3', 'wav', 'aac', 'ogg', 'flac', 'mp4',
              'docx', 'pdf', 'txt', 'doc', 'rtf', 'odt'],
        help="æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„æˆ–ç‚¹å‡»æµè§ˆ"
    )

    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_details = {
            "æ–‡ä»¶å": uploaded_file.name,
            "æ–‡ä»¶ç±»å‹": uploaded_file.type,
            "æ–‡ä»¶å¤§å°": format_file_size(uploaded_file.size)
        }

        st.markdown("#### â„¹ï¸ æ–‡ä»¶ä¿¡æ¯")
        for key, value in file_details.items():
            st.text(f"{key}: {value}")

        # å¤„ç†é€‰é¡¹
        st.markdown("#### âš™ï¸ å¤„ç†é€‰é¡¹")

        # æ ¹æ®æ–‡ä»¶ç±»å‹æ˜¾ç¤ºä¸åŒé€‰é¡¹
        file_ext = Path(uploaded_file.name).suffix.lower()

        options = {}

        if file_ext in ['.m4a', '.mp3', '.wav', '.aac', '.ogg', '.flac', '.mp4']:
            # éŸ³é¢‘æ–‡ä»¶é€‰é¡¹
            col1, col2 = st.columns(2)

            with col1:
                options['enable_speaker_diarization'] = st.checkbox(
                    "å¯ç”¨è¯´è¯äººè¯†åˆ«",
                    value=True,
                    key="file_upload_speaker_diarization",
                    help="è¯†åˆ«å¹¶åŒºåˆ†ä¸åŒçš„è¯´è¯äºº"
                )

                if options['enable_speaker_diarization']:
                    options['maintain_speaker_consistency'] = st.checkbox(
                        "ä¿æŒè¯´è¯äººä¸€è‡´æ€§",
                        value=True,
                        key="file_upload_speaker_consistency",
                        help="åœ¨é•¿éŸ³é¢‘ä¸­ä¿æŒè¯´è¯äººæ ‡è¯†çš„ä¸€è‡´æ€§"
                    )

            with col2:
                options['enable_text_optimization'] = st.checkbox(
                    "å¯ç”¨æ–‡æœ¬ä¼˜åŒ–",
                    value=False,
                    key="file_upload_text_optimization",
                    help="ä½¿ç”¨AIä¼˜åŒ–è½¬å½•æ–‡æœ¬è´¨é‡"
                )

                options['max_segment_duration_minutes'] = st.slider(
                    "æœ€å¤§ç‰‡æ®µæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰",
                    min_value=10,
                    max_value=30,
                    value=20,
                    key="file_upload_segment_duration",
                    help="è¶…é•¿éŸ³é¢‘å°†è¢«åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ"
                )

        else:
            # æ–‡æ¡£æ–‡ä»¶é€‰é¡¹
            col1, col2 = st.columns(2)

            with col1:
                options['extract_metadata'] = st.checkbox(
                    "æå–å…ƒæ•°æ®",
                    value=True,
                    key="file_upload_extract_metadata",
                    help="æå–æ–‡æ¡£çš„ä½œè€…ã€åˆ›å»ºæ—¶é—´ç­‰ä¿¡æ¯"
                )

            with col2:
                options['clean_output'] = st.checkbox(
                    "æ¸…ç†è¾“å‡ºæ–‡æœ¬",
                    value=True,
                    key="file_upload_clean_output",
                    help="ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç©ºè¡Œ"
                )

        # å¤„ç†æŒ‰é’®
        if st.button("â–¶ï¸ å¼€å§‹å¤„ç†", type="primary", use_container_width=True, key="file_upload_process"):
            process_uploaded_file(uploaded_file, options)


def show_text_input_tab():
    """æ˜¾ç¤ºæ–‡æœ¬è¾“å…¥æ ‡ç­¾é¡µ"""
    st.markdown("### âœï¸ æ–‡æœ¬è¾“å…¥")

    st.info("""
    ç›´æ¥ç²˜è´´æˆ–è¾“å…¥æ–‡æœ¬å†…å®¹ï¼Œé€‚ç”¨äºï¼š
    - å·²æœ‰çš„è½¬å½•æ–‡æœ¬
    - ä¼šè®®è®°å½•
    - å…¶ä»–æ–‡æœ¬å†…å®¹
    """)

    # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
    text_input = st.text_area(
        "è¯·è¾“å…¥æ–‡æœ¬å†…å®¹",
        height=400,
        placeholder="åœ¨æ­¤ç²˜è´´æˆ–è¾“å…¥æ–‡æœ¬å†…å®¹...",
        key="text_input_area",
        help="æ”¯æŒä¸­è‹±æ–‡ï¼Œå»ºè®®é•¿åº¦åœ¨50-50000å­—ç¬¦ä¹‹é—´"
    )

    # æ˜¾ç¤ºå­—æ•°ç»Ÿè®¡
    if text_input:
        char_count = len(text_input)
        word_count = len(text_input.split())
        st.caption(f"å­—ç¬¦æ•°: {char_count:,} | è¯æ•°: {word_count:,}")

    # è¾“å…¥é€‰é¡¹
    st.markdown("#### âš™ï¸ å¤„ç†é€‰é¡¹")

    col1, col2 = st.columns(2)

    with col1:
        input_type = st.selectbox(
            "æ–‡æœ¬ç±»å‹",
            options=['transcript', 'document', 'general'],
            format_func=lambda x: {
                'transcript': 'è½¬å½•æ–‡æœ¬',
                'document': 'æ–‡æ¡£å†…å®¹',
                'general': 'é€šç”¨æ–‡æœ¬'
            }.get(x, x),
            key="text_input_type",
            help="é€‰æ‹©æ–‡æœ¬çš„ç±»å‹ä»¥è·å¾—æœ€ä½³å¤„ç†æ•ˆæœ"
        )

    with col2:
        if input_type == 'transcript':
            enable_optimization = st.checkbox(
                "å¯ç”¨æ–‡æœ¬ä¼˜åŒ–",
                value=False,
                key="text_input_optimization",
                help="ä½¿ç”¨AIä¼˜åŒ–è½¬å½•æ–‡æœ¬è´¨é‡"
            )
        else:
            enable_optimization = False

    # å¤„ç†æŒ‰é’®
    if st.button("â–¶ï¸ å¤„ç†æ–‡æœ¬", type="primary", use_container_width=True, key="text_input_process"):
        if text_input.strip():
            # éªŒè¯æ–‡æœ¬
            is_valid, message = validate_text_input(
                text_input,
                min_length=50,
                max_length=100000
            )

            if is_valid:
                process_text_input(text_input, input_type, enable_optimization)
            else:
                st.error(message)
        else:
            st.warning("è¯·è¾“å…¥æ–‡æœ¬å†…å®¹")


def process_uploaded_file(uploaded_file, options):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
    session_manager = st.session_state.session_manager

    # åˆ›å»ºè¿›åº¦å®¹å™¨
    progress_container = st.container()

    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        st.session_state.input_processing['current_progress'] = 0

        try:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            status_text.text("æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
            progress_bar.progress(10)
            st.session_state.input_processing['current_progress'] = 10

            save_dir = Path("temp") / datetime.now().strftime("%Y%m%d_%H%M%S")
            success, file_path, message = save_uploaded_file(
                uploaded_file,
                save_dir
            )

            if not success:
                st.error(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {message}")
                return

            st.session_state.input_processing['temp_file_path'] = file_path

            # åˆå§‹åŒ–å¤„ç†å™¨
            status_text.text("æ­£åœ¨åˆå§‹åŒ–å¤„ç†å™¨...")
            progress_bar.progress(20)
            st.session_state.input_processing['current_progress'] = 20

            processor = DocumentProcessor()

            # å®šä¹‰è¿›åº¦å›è°ƒ
            def progress_callback(msg):
                status_text.text(msg)
                # åŠ¨æ€æ›´æ–°è¿›åº¦æ¡
                current = st.session_state.input_processing['current_progress']
                if current < 90:
                    new_progress = min(current + 10, 90)
                    progress_bar.progress(new_progress)
                    st.session_state.input_processing['current_progress'] = new_progress

            options['progress_callback'] = progress_callback

            # å¤„ç†æ–‡ä»¶
            status_text.text("æ­£åœ¨å¤„ç†æ–‡ä»¶...")
            progress_bar.progress(30)
            st.session_state.input_processing['current_progress'] = 30

            start_time = time.time()
            result = processor.process_file(file_path, options)
            processing_time = time.time() - start_time

            progress_bar.progress(100)
            st.session_state.input_processing['current_progress'] = 100

            if result.is_success:
                status_text.text("âœ… å¤„ç†å®Œæˆï¼")

                # ä¿å­˜ç»“æœåˆ°ä¼šè¯
                session_manager.save_result('input_processing', result)
                st.session_state.input_processing['processing_result'] = result

                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.input_processing['processing_history'].append({
                    'filename': uploaded_file.name,
                    'timestamp': datetime.now(),
                    'processing_time': processing_time,
                    'result': result
                })

                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                st.success(f"""
                æ–‡ä»¶å¤„ç†æˆåŠŸï¼
                - å¤„ç†æ—¶é—´: {processing_time:.1f} ç§’
                - å†…å®¹é•¿åº¦: {len(result.content):,} å­—ç¬¦
                """)

                # è‡ªåŠ¨å±•ç¤ºç»“æœ
                time.sleep(1)
                st.rerun()

            else:
                status_text.text("âŒ å¤„ç†å¤±è´¥")
                st.error(f"å¤„ç†å¤±è´¥: {result.error}")

        except Exception as e:
            status_text.text("âŒ å‘ç”Ÿé”™è¯¯")
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

        finally:
            # æ¸…ç†è¿›åº¦æ˜¾ç¤º
            time.sleep(2)
            progress_container.empty()
            # é‡ç½®è¿›åº¦
            st.session_state.input_processing['current_progress'] = 0


def process_text_input(text_input, input_type, enable_optimization):
    """å¤„ç†æ–‡æœ¬è¾“å…¥"""
    session_manager = st.session_state.session_manager

    with st.spinner("æ­£åœ¨å¤„ç†æ–‡æœ¬..."):
        try:
            processor = DocumentProcessor()

            options = {
                'enable_text_optimization': enable_optimization
            }

            start_time = time.time()
            result = processor.process_text_input(
                text_input,
                input_type,
                options
            )
            processing_time = time.time() - start_time

            if result.is_success:
                # ä¿å­˜ç»“æœ
                session_manager.save_result('input_processing', result)
                st.session_state.input_processing['processing_result'] = result

                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.input_processing['processing_history'].append({
                    'filename': f"æ–‡æœ¬è¾“å…¥_{datetime.now().strftime('%H%M%S')}",
                    'timestamp': datetime.now(),
                    'processing_time': processing_time,
                    'result': result
                })

                st.success(f"æ–‡æœ¬å¤„ç†æˆåŠŸï¼å¤„ç†æ—¶é—´: {processing_time:.1f} ç§’")

                # è‡ªåŠ¨å±•ç¤ºç»“æœ
                time.sleep(1)
                st.rerun()

            else:
                st.error(f"å¤„ç†å¤±è´¥: {result.error}")

        except Exception as e:
            st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def show_processing_result():
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    result = st.session_state.input_processing.get('processing_result')

    if not result:
        return

    st.markdown("---")
    st.markdown("### ğŸ“Š å¤„ç†ç»“æœ")

    # ç»“æœæ‘˜è¦
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("å†…å®¹é•¿åº¦", f"{len(result.content):,} å­—ç¬¦")

    with col2:
        st.metric("å¤„ç†æ—¶é—´", f"{result.processing_time:.1f} ç§’")

    with col3:
        if result.tokens_consumed:
            st.metric("Tokenä½¿ç”¨", f"{result.total_tokens:,}")

    # å…ƒæ•°æ®æ˜¾ç¤º
    if result.metadata:
        with st.expander("â„¹ï¸ è¯¦ç»†ä¿¡æ¯", expanded=False):
            # æ ¼å¼åŒ–æ˜¾ç¤ºå…ƒæ•°æ®
            for key, value in result.metadata.items():
                if key not in ['error', 'original_text']:
                    st.text(f"{key}: {value}")

    # å†…å®¹é¢„è§ˆ
    st.markdown("#### ğŸ“‹ å†…å®¹é¢„è§ˆ")

    # é¢„è§ˆé€‰é¡¹
    col1, col2 = st.columns([3, 1])
    with col1:
        preview_length = st.slider(
            "é¢„è§ˆé•¿åº¦",
            min_value=500,
            max_value=5000,
            value=1500,
            step=500,
            key="result_preview_length"
        )

    with col2:
        show_full = st.checkbox("æ˜¾ç¤ºå…¨æ–‡", value=False, key="result_show_full")

    # æ˜¾ç¤ºå†…å®¹
    if show_full:
        st.text_area(
            "å¤„ç†åçš„å†…å®¹",
            value=result.content,
            height=600,
            disabled=True,
            key="result_full_content"
        )
    else:
        preview_text = truncate_text(result.content, preview_length)
        st.text_area(
            "å¤„ç†åçš„å†…å®¹ï¼ˆé¢„è§ˆï¼‰",
            value=preview_text,
            height=400,
            disabled=True,
            key="result_preview_content"
        )

    # æ“ä½œæŒ‰é’®
    st.markdown("#### â¯ï¸ ä¿å­˜å’Œä¸‹ä¸€æ­¥")

    col1, col2, col3 = st.columns(3)

    with col1:
        # ä¸‹è½½æŒ‰é’®
        download_content = result.content
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"processed_content_{timestamp}.txt"

        st.download_button(
            label="ğŸ’¾ ä¸‹è½½ç»“æœ",
            data=download_content,
            file_name=filename,
            mime="text/plain",
            use_container_width=True,
            key="result_download"
        )

    with col2:
        # å‘é€åˆ°åˆ†æ
        if st.button("â¡ï¸ å‘é€åˆ°æ·±åº¦åˆ†æ", type="primary", use_container_width=True, key="send_to_analysis"):
            # ä¿å­˜åˆ°ä¼šè¯ä¾›ä¸‹ä¸€æ­¥ä½¿ç”¨
            session_manager = st.session_state.session_manager
            session_manager.save_result('transcription', result)
            st.success("å·²ä¿å­˜ï¼è¯·å‰å¾€ **æ·±åº¦åˆ†æ** é¡µé¢ç»§ç»­")
            # å¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸€ä¸ªçŸ­æš‚çš„å»¶è¿Ÿç„¶ååˆ·æ–°é¡µé¢ï¼Œè®©ç”¨æˆ·çœ‹åˆ°æ¶ˆæ¯
            time.sleep(2)
            st.rerun()

    with col3:
        # æ¸…é™¤ç»“æœ
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç»“æœ", use_container_width=True, key="clear_result"):
            st.session_state.input_processing['processing_result'] = None
            st.rerun()


def show_processing_history():
    """æ˜¾ç¤ºå¤„ç†å†å²"""
    history = st.session_state.input_processing.get('processing_history', [])

    if not history:
        return

    st.markdown("---")
    st.markdown("### ğŸ“œ å¤„ç†å†å²")

    # æŒ‰æ—¶é—´å€’åºæ˜¾ç¤º
    for idx, item in enumerate(reversed(history[-5:])):  # åªæ˜¾ç¤ºæœ€è¿‘5æ¡
        with st.expander(
                f"{item['filename']} - {item['timestamp'].strftime('%H:%M:%S')}",
                expanded=False
        ):
            st.text(f"å¤„ç†æ—¶é—´: {item['processing_time']:.1f} ç§’")
            st.text(f"å†…å®¹é•¿åº¦: {len(item['result'].content):,} å­—ç¬¦")

            if st.button(f"ä½¿ç”¨æ­¤ç»“æœ", key=f"use_history_{idx}_{item['timestamp']}"):
                st.session_state.input_processing['processing_result'] = item['result']
                st.rerun()


def main():
    """ä¸»å‡½æ•°"""
    # åœ¨é¡µé¢é¡¶éƒ¨æ£€æŸ¥API Keyè®¾ç½®
    check_api_key_setup()

    # åˆå§‹åŒ–é¡µé¢çŠ¶æ€
    initialize_page_state()

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“„ å†…å®¹è¾“å…¥å¤„ç†")
    st.markdown("ä¸Šä¼ éŸ³é¢‘æˆ–æ–‡æ¡£æ–‡ä»¶ï¼Œæˆ–ç›´æ¥è¾“å…¥æ–‡æœ¬å†…å®¹è¿›è¡Œå¤„ç†")

    # é€‰æ‹©è¾“å…¥æ–¹å¼
    tab1, tab2 = st.tabs(["ğŸ“ æ–‡ä»¶ä¸Šä¼ ", "âœï¸ æ–‡æœ¬è¾“å…¥"])

    with tab1:
        show_file_upload_tab()

    with tab2:
        show_text_input_tab()

    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    if st.session_state.input_processing.get('processing_result'):
        show_processing_result()

    # æ˜¾ç¤ºå¤„ç†å†å²
    show_processing_history()

    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
        st.info("""
**æ–‡ä»¶ä¸Šä¼ **ï¼š
- æ”¯æŒéŸ³é¢‘å’Œæ–‡æ¡£æ–‡ä»¶
- éŸ³é¢‘ä¼šè‡ªåŠ¨è½¬å½•ä¸ºæ–‡æœ¬
- æ–‡æ¡£ä¼šæå–æ–‡æœ¬å†…å®¹

**æ–‡æœ¬è¾“å…¥**ï¼š
- å¯ç›´æ¥ç²˜è´´å·²æœ‰æ–‡æœ¬
- æ”¯æŒä¼˜åŒ–è½¬å½•æ–‡æœ¬

**ä¸‹ä¸€æ­¥**ï¼š
- å¤„ç†å®Œæˆåå¯å‘é€åˆ°æ·±åº¦åˆ†æ
- æˆ–ä¸‹è½½ç»“æœä¿å­˜
""")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if st.button("ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶", key="sidebar_cleanup"):
            session_manager = st.session_state.session_manager
            if session_manager.cleanup_all_temp_files():
                st.success("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            else:
                st.error("æ¸…ç†å¤±è´¥")


if __name__ == "__main__":
    main()

--- File: pages/2_ğŸ”_Deep_Analysis.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/pages/2_ğŸ”_Deep_Analysis.py
åŠŸèƒ½è¯´æ˜: æ·±åº¦åˆ†æé¡µé¢ï¼Œå¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œå•†ä¸šæ´å¯Ÿåˆ†æ
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-29
ç‰ˆæœ¬: 1.1.0
"""

import os
import sys
import streamlit as st
from pathlib import Path
from datetime import datetime
import time
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.analysis_service import DeepAnalysisService
from core.session_manager import SessionManager
from core.prompt_manager import PromptManager
from utils.file_utils import (
    save_uploaded_file,
    get_file_metadata,
    format_file_size,
    prepare_download_file
)
from utils.format_utils import (
    format_metadata_display,
    format_duration,
    truncate_text,
    markdown_to_text
)
from utils.validation_utils import validate_text_input
from utils.ui_utils import check_api_key_setup  # å¼•å…¥æ£€æŸ¥å‡½æ•°

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ·±åº¦åˆ†æ - SmartProposal Engine",
    page_icon="ğŸ”",
    layout="wide"
)


def initialize_page_state():
    """åˆå§‹åŒ–é¡µé¢çŠ¶æ€"""
    if 'deep_analysis' not in st.session_state:
        st.session_state.deep_analysis = {
            'analysis_result': None,
            'analysis_history': [],
            'current_template': 'customer_interview',
            'custom_prompt': '',
            'processing': False,
            'current_progress': 0  # æ·»åŠ è¿›åº¦è·Ÿè¸ª
        }

    # ç¡®ä¿SessionManagerå­˜åœ¨
    if 'session_manager' not in st.session_state:
        st.session_state.session_manager = SessionManager()

    # åˆ›å»ºæˆ–è·å–å½“å‰ä¼šè¯
    if not st.session_state.session_manager.current_session_id:
        st.session_state.session_manager.create_session('deep_analysis')


def load_previous_result():
    """åŠ è½½ä¸Šä¸€æ­¥çš„ç»“æœ"""
    session_manager = st.session_state.session_manager

    # å°è¯•è·å–è½¬å½•ç»“æœ
    transcription_result = session_manager.get_result('transcription')
    if transcription_result:
        return transcription_result

    # å°è¯•è·å–è¾“å…¥å¤„ç†ç»“æœ
    input_result = session_manager.get_result('input_processing')
    if input_result:
        return input_result

    return None


def show_data_source_section():
    """æ˜¾ç¤ºæ•°æ®æºé€‰æ‹©éƒ¨åˆ†"""
    st.markdown("### ğŸ“Š é€‰æ‹©æ•°æ®æº")

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¸€æ­¥çš„ç»“æœ
    previous_result = load_previous_result()

    col1, col2 = st.columns(2)

    with col1:
        use_previous = st.checkbox(
            "ä½¿ç”¨ä¸Šä¸€æ­¥å¤„ç†ç»“æœ",
            value=bool(previous_result),
            disabled=not bool(previous_result),
            help="ä½¿ç”¨å†…å®¹è¾“å…¥é¡µé¢çš„å¤„ç†ç»“æœ" if previous_result else "æ²¡æœ‰æ‰¾åˆ°ä¸Šä¸€æ­¥çš„å¤„ç†ç»“æœ"
        )

    if use_previous and previous_result:
        with col2:
            st.success(f"âœ… å·²åŠ è½½ä¸Šä¸€æ­¥ç»“æœ")
            st.caption(f"å†…å®¹é•¿åº¦: {len(previous_result.content):,} å­—ç¬¦")

        # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
        with st.expander("æŸ¥çœ‹å†…å®¹é¢„è§ˆ", expanded=False):
            st.text_area(
                "å†…å®¹é¢„è§ˆ",
                value=truncate_text(previous_result.content, 1000),
                height=200,
                disabled=True
            )

        return previous_result.content, previous_result.metadata

    else:
        # æ–‡ä»¶ä¸Šä¼ æˆ–æ–‡æœ¬è¾“å…¥
        tab1, tab2 = st.tabs(["ğŸ“¤ ä¸Šä¼ æ–‡ä»¶", "âœï¸ æ–‡æœ¬è¾“å…¥"])

        with tab1:
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ è½¬å½•æ–‡æœ¬æˆ–æ–‡æ¡£",
                type=['txt', 'docx', 'pdf', 'json'],
                help="æ”¯æŒTXTã€DOCXã€PDFæˆ–ä¹‹å‰å¯¼å‡ºçš„JSONæ–‡ä»¶"
            )

            if uploaded_file:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                save_dir = Path("temp") / datetime.now().strftime("%Y%m%d_%H%M%S")
                success, file_path, message = save_uploaded_file(uploaded_file, save_dir)

                if success:
                    st.success(message)

                    # è¯»å–æ–‡ä»¶å†…å®¹
                    if uploaded_file.type == 'application/json':
                        # JSONæ–‡ä»¶ç‰¹æ®Šå¤„ç†
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            content = data.get('content', '')
                            metadata = data.get('metadata', {})
                    else:
                        # å…¶ä»–æ–‡ä»¶ä½œä¸ºçº¯æ–‡æœ¬å¤„ç†
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        metadata = get_file_metadata(file_path)

                    return content, metadata
                else:
                    st.error(message)
                    return None, None

        with tab2:
            text_input = st.text_area(
                "ç²˜è´´æˆ–è¾“å…¥æ–‡æœ¬å†…å®¹",
                height=300,
                placeholder="åœ¨æ­¤è¾“å…¥éœ€è¦åˆ†æçš„æ–‡æœ¬å†…å®¹...",
                help="å»ºè®®æ–‡æœ¬é•¿åº¦åœ¨100-50000å­—ç¬¦ä¹‹é—´"
            )

            if text_input:
                # æ˜¾ç¤ºå­—æ•°ç»Ÿè®¡
                char_count = len(text_input)
                word_count = len(text_input.split())
                st.caption(f"å­—ç¬¦æ•°: {char_count:,} | è¯æ•°: {word_count:,}")

                # éªŒè¯è¾“å…¥
                is_valid, message = validate_text_input(
                    text_input,
                    min_length=100,
                    max_length=100000
                )

                if is_valid:
                    metadata = {
                        'source': 'text_input',
                        'char_count': char_count,
                        'word_count': word_count,
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    }
                    return text_input, metadata
                else:
                    st.warning(message)
                    return None, None

    return None, None


def show_analysis_configuration():
    """æ˜¾ç¤ºåˆ†æé…ç½®éƒ¨åˆ†"""
    st.markdown("### âš™ï¸ åˆ†æé…ç½®")

    # åˆå§‹åŒ–åˆ†ææœåŠ¡ä»¥è·å–å¯ç”¨æ¨¡æ¿
    analysis_service = DeepAnalysisService()

    col1, col2 = st.columns([2, 1])

    with col1:
        # åˆ†æåœºæ™¯é€‰æ‹©
        scenarios = analysis_service.ANALYSIS_SCENARIOS
        template_options = list(scenarios.keys())
        template_names = [scenarios[key]['name'] for key in template_options]

        selected_index = st.selectbox(
            "é€‰æ‹©åˆ†æåœºæ™¯",
            range(len(template_options)),
            format_func=lambda x: template_names[x],
            index=template_options.index(st.session_state.deep_analysis['current_template']),
            help="é€‰æ‹©é€‚åˆæ‚¨ä¸šåŠ¡åœºæ™¯çš„åˆ†ææ¨¡æ¿"
        )

        selected_template = template_options[selected_index]
        st.session_state.deep_analysis['current_template'] = selected_template

        # æ˜¾ç¤ºåœºæ™¯è¯´æ˜
        scenario_info = scenarios[selected_template]
        st.info(f"**åœºæ™¯è¯´æ˜**: {scenario_info['description']}")

        # æ˜¾ç¤ºé‡ç‚¹åˆ†æé¢†åŸŸ
        st.markdown("**é‡ç‚¹åˆ†æé¢†åŸŸ:**")
        focus_areas_text = " | ".join(scenario_info['focus_areas'])
        st.caption(focus_areas_text)

    with col2:
        # é«˜çº§é€‰é¡¹
        st.markdown("**é«˜çº§é€‰é¡¹**")

        include_recommendations = st.checkbox(
            "åŒ…å«è¡ŒåŠ¨å»ºè®®",
            value=True,
            help="åœ¨åˆ†ææŠ¥å‘Šä¸­åŒ…å«å…·ä½“çš„è¡ŒåŠ¨å»ºè®®"
        )

        extract_action_items = st.checkbox(
            "æå–è¡ŒåŠ¨é¡¹",
            value=True,
            help="è‡ªåŠ¨æå–å¹¶åˆ—å‡ºéœ€è¦æ‰§è¡Œçš„è¡ŒåŠ¨é¡¹"
        )

        output_format = st.selectbox(
            "è¾“å‡ºæ ¼å¼",
            options=['markdown', 'text'],
            format_func=lambda x: {'markdown': 'Markdownæ ¼å¼', 'text': 'çº¯æ–‡æœ¬'}.get(x, x),
            help="é€‰æ‹©åˆ†ææŠ¥å‘Šçš„è¾“å‡ºæ ¼å¼"
        )

    # è‡ªå®šä¹‰Promptéƒ¨åˆ†
    with st.expander("ğŸ› ï¸ è‡ªå®šä¹‰åˆ†ææ¨¡æ¿ï¼ˆé«˜çº§ï¼‰", expanded=False):
        st.markdown("""
        æ‚¨å¯ä»¥æä¾›è‡ªå®šä¹‰çš„åˆ†ææ¨¡æ¿æ¥æ›¿ä»£é¢„è®¾æ¨¡æ¿ã€‚æ¨¡æ¿ä¸­å¯ä½¿ç”¨ä»¥ä¸‹å˜é‡ï¼š
        - `{transcript}`: å¾…åˆ†æçš„æ–‡æœ¬å†…å®¹
        - `{additional_context}`: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """)

        custom_prompt = st.text_area(
            "è‡ªå®šä¹‰åˆ†ææ¨¡æ¿",
            value=st.session_state.deep_analysis.get('custom_prompt', ''),
            height=300,
            placeholder="è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰åˆ†ææ¨¡æ¿...",
            help="ç•™ç©ºåˆ™ä½¿ç”¨é€‰å®šçš„é¢„è®¾æ¨¡æ¿"
        )

        if custom_prompt:
            st.session_state.deep_analysis['custom_prompt'] = custom_prompt

        # é¢å¤–ä¸Šä¸‹æ–‡
        additional_context = st.text_area(
            "é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰",
            height=100,
            placeholder="æä¾›é¢å¤–çš„èƒŒæ™¯ä¿¡æ¯æˆ–ç‰¹æ®Šè¦æ±‚...",
            help="è¿™äº›ä¿¡æ¯å°†å¸®åŠ©AIæ›´å¥½åœ°ç†è§£åˆ†æéœ€æ±‚"
        )

    # è¿”å›é…ç½®é€‰é¡¹
    options = {
        'template': selected_template,
        'include_recommendations': include_recommendations,
        'extract_action_items': extract_action_items,
        'output_format': output_format,
        'custom_prompt': custom_prompt if custom_prompt else None,
        'additional_context': additional_context if additional_context else None
    }

    return options


def perform_analysis(content: str, metadata: dict, options: dict):
    """æ‰§è¡Œæ·±åº¦åˆ†æ"""
    session_manager = st.session_state.session_manager

    # åˆ›å»ºè¿›åº¦å®¹å™¨
    progress_container = st.container()

    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        st.session_state.deep_analysis['current_progress'] = 0

        try:
            # åˆå§‹åŒ–åˆ†ææœåŠ¡
            status_text.text("æ­£åœ¨åˆå§‹åŒ–åˆ†ææœåŠ¡...")
            progress_bar.progress(10)
            st.session_state.deep_analysis['current_progress'] = 10

            analysis_service = DeepAnalysisService()

            # å®šä¹‰è¿›åº¦å›è°ƒ
            def progress_callback(msg):
                status_text.text(msg)
                current = st.session_state.deep_analysis['current_progress']
                if current < 90:
                    new_progress = min(current + 20, 90)
                    progress_bar.progress(new_progress)
                    st.session_state.deep_analysis['current_progress'] = new_progress

            options['progress_callback'] = progress_callback

            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                'transcript': content,
                'metadata': metadata
            }

            # æ‰§è¡Œåˆ†æ
            status_text.text("æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ...")
            progress_bar.progress(30)
            st.session_state.deep_analysis['current_progress'] = 30

            start_time = time.time()
            result = analysis_service.process(
                input_data,
                template=options['template'],
                options=options
            )

            progress_bar.progress(100)
            st.session_state.deep_analysis['current_progress'] = 100

            if result.is_success:
                status_text.text("âœ… åˆ†æå®Œæˆï¼")

                # ä¿å­˜ç»“æœåˆ°ä¼šè¯
                session_manager.save_result('analysis', result)
                st.session_state.deep_analysis['analysis_result'] = result

                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.deep_analysis['analysis_history'].append({
                    'timestamp': datetime.now(),
                    'template': options['template'],
                    'processing_time': result.processing_time,
                    'result': result
                })

                # å¦‚æœéœ€è¦æå–è¡ŒåŠ¨é¡¹
                if options.get('extract_action_items'):
                    action_items = analysis_service.extract_action_items(result)
                    result.metadata['action_items'] = action_items

                # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
                executive_summary = analysis_service.generate_executive_summary(result)
                result.metadata['executive_summary'] = executive_summary

                st.success(f"""
                æ·±åº¦åˆ†ææˆåŠŸå®Œæˆï¼
                - å¤„ç†æ—¶é—´: {result.processing_time:.1f} ç§’
                - ä½¿ç”¨æ¨¡å‹: {result.model_used}
                - Tokenä½¿ç”¨: {result.total_tokens:,}
                """)

                # è‡ªåŠ¨åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç»“æœ
                time.sleep(1)
                st.rerun()

            else:
                status_text.text("âŒ åˆ†æå¤±è´¥")
                st.error(f"åˆ†æå¤±è´¥: {result.error}")

        except Exception as e:
            status_text.text("âŒ å‘ç”Ÿé”™è¯¯")
            st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

        finally:
            # æ¸…ç†è¿›åº¦æ˜¾ç¤º
            time.sleep(2)
            progress_container.empty()
            # é‡ç½®è¿›åº¦
            st.session_state.deep_analysis['current_progress'] = 0


def show_analysis_result():
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    result = st.session_state.deep_analysis.get('analysis_result')

    if not result:
        return

    st.markdown("---")
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")

    # æ˜¾ç¤ºæ‰§è¡Œæ‘˜è¦
    if 'executive_summary' in result.metadata:
        st.markdown("#### ğŸ“„ æ‰§è¡Œæ‘˜è¦")
        st.info(result.metadata['executive_summary'])

    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("åˆ†æç”¨æ—¶", f"{result.processing_time:.1f} ç§’")

    with col2:
        st.metric("Tokenä½¿ç”¨", f"{result.total_tokens:,}")

    with col3:
        if 'estimated_cost' in result.metadata:
            st.metric("é¢„ä¼°è´¹ç”¨", f"${result.metadata['estimated_cost']:.4f}")

    with col4:
        st.metric("åˆ†ææ¨¡æ¿", result.metadata.get('analysis_scenario', 'æœªçŸ¥'))

    # æ˜¾ç¤ºå®Œæ•´åˆ†ææŠ¥å‘Š
    st.markdown("#### ğŸ“‘ å®Œæ•´åˆ†ææŠ¥å‘Š")

    # æŠ¥å‘Šæ˜¾ç¤ºé€‰é¡¹
    col1, col2 = st.columns([3, 1])
    with col1:
        show_full_report = st.checkbox("æ˜¾ç¤ºå®Œæ•´æŠ¥å‘Š", value=True)
    with col2:
        if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿"):
            st.write(result.content)  # Streamlitä¼šè‡ªåŠ¨æ·»åŠ å¤åˆ¶åŠŸèƒ½
            st.success("å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼")

    # æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
    if show_full_report:
        # ä½¿ç”¨å®¹å™¨æ˜¾ç¤ºæ ¼å¼åŒ–çš„Markdownå†…å®¹
        report_container = st.container()
        with report_container:
            st.markdown(result.content)
    else:
        # æ˜¾ç¤ºæ‘˜è¦
        preview_length = 2000
        preview_text = truncate_text(result.content, preview_length)
        st.text_area(
            "æŠ¥å‘Šé¢„è§ˆ",
            value=preview_text,
            height=400,
            disabled=True
        )

    # æ˜¾ç¤ºè¡ŒåŠ¨é¡¹ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'action_items' in result.metadata and result.metadata['action_items']:
        st.markdown("#### ğŸ¯ æå–çš„è¡ŒåŠ¨é¡¹")

        action_items = result.metadata['action_items']
        for i, item in enumerate(action_items, 1):
            col1, col2 = st.columns([5, 1])
            with col1:
                st.write(f"{i}. {item['description']}")
            with col2:
                st.caption(f"ä¼˜å…ˆçº§: {item.get('priority', 'ä¸­')}")

    # æ“ä½œæŒ‰é’®
    st.markdown("#### â¯ï¸ ä¿å­˜å’Œä¸‹ä¸€æ­¥")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        # ä¸‹è½½Markdownæ ¼å¼
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename_md = f"analysis_report_{timestamp}.md"

        st.download_button(
            label="ğŸ’¾ ä¸‹è½½æŠ¥å‘Š(MD)",
            data=result.content,
            file_name=filename_md,
            mime="text/markdown",
            use_container_width=True
        )

    with col2:
        # ä¸‹è½½JSONæ ¼å¼ï¼ˆåŒ…å«å®Œæ•´æ•°æ®ï¼‰
        export_data = {
            'content': result.content,
            'metadata': result.metadata,
            'processing_info': {
                'processing_time': result.processing_time,
                'model_used': result.model_used,
                'tokens_consumed': result.tokens_consumed,
                'timestamp': datetime.now().isoformat()
            }
        }

        filename_json = f"analysis_report_{timestamp}.json"
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)

        st.download_button(
            label="ğŸ’¾ ä¸‹è½½æŠ¥å‘Š(JSON)",
            data=json_str,
            file_name=filename_json,
            mime="application/json",
            use_container_width=True
        )

    with col3:
        # å‘é€åˆ°æ–¹æ¡ˆç”Ÿæˆ
        if st.button("â¡ï¸ å‘é€åˆ°æ–¹æ¡ˆç”Ÿæˆ", type="primary", use_container_width=True):
            session_manager = st.session_state.session_manager
            session_manager.save_result('analysis', result)
            st.success("å·²ä¿å­˜ï¼è¯·å‰å¾€ **æ–¹æ¡ˆç”Ÿæˆ** é¡µé¢ç»§ç»­")
            time.sleep(2)
            st.rerun()

    with col4:
        # é‡æ–°åˆ†æ
        if st.button("ğŸ”„ é‡æ–°åˆ†æ", use_container_width=True):
            st.session_state.deep_analysis['analysis_result'] = None
            st.rerun()


def show_analysis_history():
    """æ˜¾ç¤ºåˆ†æå†å²"""
    history = st.session_state.deep_analysis.get('analysis_history', [])

    if not history:
        return

    st.markdown("---")
    st.markdown("### ğŸ“œ åˆ†æå†å²")

    # æŒ‰æ—¶é—´å€’åºæ˜¾ç¤ºæœ€è¿‘çš„åˆ†æ
    for item in reversed(history[-5:]):  # åªæ˜¾ç¤ºæœ€è¿‘5æ¡
        template_name = DeepAnalysisService.ANALYSIS_SCENARIOS.get(
            item['template'], {}
        ).get('name', item['template'])

        with st.expander(
                f"{template_name} - {item['timestamp'].strftime('%H:%M:%S')}",
                expanded=False
        ):
            st.text(f"å¤„ç†æ—¶é—´: {item['processing_time']:.1f} ç§’")
            st.text(f"å†…å®¹é•¿åº¦: {len(item['result'].content):,} å­—ç¬¦")

            if st.button(f"ä½¿ç”¨æ­¤ç»“æœ", key=f"use_{item['timestamp']}"):
                st.session_state.deep_analysis['analysis_result'] = item['result']
                st.rerun()


def main():
    """ä¸»å‡½æ•°"""
    # åœ¨é¡µé¢é¡¶éƒ¨æ£€æŸ¥API Keyè®¾ç½®
    check_api_key_setup()

    # åˆå§‹åŒ–é¡µé¢çŠ¶æ€
    initialize_page_state()

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ” æ·±åº¦åˆ†æ")
    st.markdown("å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œå•†ä¸šæ´å¯Ÿåˆ†æï¼Œæå–å…³é”®ä¿¡æ¯å’Œè¡ŒåŠ¨å»ºè®®")

    # æ˜¾ç¤ºåˆ†æç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    if st.session_state.deep_analysis.get('analysis_result'):
        show_analysis_result()
        show_analysis_history()
    else:
        # è·å–æ•°æ®æº
        content, metadata = show_data_source_section()

        if content:
            st.markdown("---")

            # æ˜¾ç¤ºåˆ†æé…ç½®
            options = show_analysis_configuration()

            st.markdown("---")

            # æ‰§è¡Œåˆ†ææŒ‰é’®
            col1, col2, col3 = st.columns([2, 1, 2])
            with col2:
                if st.button(
                        "â–¶ï¸ å¼€å§‹åˆ†æ",
                        type="primary",
                        use_container_width=True,
                        disabled=st.session_state.deep_analysis.get('processing', False)
                ):
                    st.session_state.deep_analysis['processing'] = True
                    perform_analysis(content, metadata, options)
                    st.session_state.deep_analysis['processing'] = False

        # æ˜¾ç¤ºå†å²è®°å½•
        show_analysis_history()

    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
        st.info("""
**åˆ†æåœºæ™¯é€‰æ‹©**ï¼š
- å®¢æˆ·è®¿è°ˆï¼šé€‚åˆéœ€æ±‚æŒ–æ˜
- å•†åŠ¡è°ˆåˆ¤ï¼šé€‚åˆæ¡æ¬¾åˆ†æ
- å†…éƒ¨ä¼šè®®ï¼šé€‚åˆå†³ç­–æå–

**è‡ªå®šä¹‰æ¨¡æ¿**ï¼š
- æ”¯æŒå®Œå…¨è‡ªå®šä¹‰åˆ†æé€»è¾‘
- ä½¿ç”¨ {transcript} å¼•ç”¨æ–‡æœ¬

**ä¸‹ä¸€æ­¥**ï¼š
- åˆ†æå®Œæˆåå¯ç”Ÿæˆæ–¹æ¡ˆ
- æ”¯æŒå¤šæ¬¡åˆ†æå¯¹æ¯”
""")

        # æ¨¡æ¿å¸®åŠ©
        if st.button("ğŸ“– æŸ¥çœ‹æ¨¡æ¿ç¤ºä¾‹"):
            st.markdown("""
**è‡ªå®šä¹‰æ¨¡æ¿ç¤ºä¾‹**ï¼š
```
è¯·åˆ†æä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œé‡ç‚¹å…³æ³¨ï¼š
1. å®¢æˆ·çš„æ ¸å¿ƒéœ€æ±‚
2. é¢„ç®—èŒƒå›´
3. å†³ç­–æ—¶é—´çº¿

å¯¹è¯å†…å®¹ï¼š
{transcript}

è¯·æä¾›ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚
```
""")


if __name__ == "__main__":
    main()

--- File: pages/3_ğŸ“‹_Proposal_Generation.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/pages/3_ğŸ“‹_Proposal_Generation.py
åŠŸèƒ½è¯´æ˜: æ–¹æ¡ˆç”Ÿæˆé¡µé¢ï¼ŒåŸºäºåˆ†æç»“æœç”Ÿæˆå„ç±»å•†ä¸šæ–‡æ¡£
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-29
ç‰ˆæœ¬: 1.1.0
"""

import os
import sys
import streamlit as st
from pathlib import Path
from datetime import datetime
import time
import json
from typing import List, Optional, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.proposal_service import ProposalService
from services.document_service import DocumentService
from core.session_manager import SessionManager
from utils.file_utils import (
    save_uploaded_file,
    get_file_metadata,
    format_file_size,
    create_unique_filename,
    ensure_directory_exists
)
from utils.format_utils import (
    format_metadata_display,
    truncate_text,
    format_table_text,
    markdown_to_text
)
from utils.validation_utils import validate_text_input, validate_file_type
from utils.ui_utils import check_api_key_setup # å¼•å…¥æ£€æŸ¥å‡½æ•°

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ–¹æ¡ˆç”Ÿæˆ - SmartProposal Engine",
    page_icon="ğŸ“‹",
    layout="wide"
)


def initialize_page_state():
    """åˆå§‹åŒ–é¡µé¢çŠ¶æ€"""
    if 'proposal_generation' not in st.session_state:
        st.session_state.proposal_generation = {
            'proposal_result': None,
            'generation_history': [],
            'current_template': 'project_proposal',
            'capability_docs': [],
            'custom_prompt': '',
            'client_info': {},
            'processing': False,
            'current_progress': 0  # æ·»åŠ è¿›åº¦è·Ÿè¸ª
        }

    # ç¡®ä¿SessionManagerå­˜åœ¨
    if 'session_manager' not in st.session_state:
        st.session_state.session_manager = SessionManager()

    # åˆ›å»ºæˆ–è·å–å½“å‰ä¼šè¯
    if not st.session_state.session_manager.current_session_id:
        st.session_state.session_manager.create_session('proposal_generation')


def load_analysis_result():
    """åŠ è½½åˆ†æç»“æœ"""
    session_manager = st.session_state.session_manager

    # å°è¯•è·å–åˆ†æç»“æœ
    analysis_result = session_manager.get_result('analysis')
    if analysis_result:
        return analysis_result

    return None


def show_analysis_source_section():
    """æ˜¾ç¤ºåˆ†ææŠ¥å‘Šæºé€‰æ‹©éƒ¨åˆ†"""
    st.markdown("### ğŸ“Š é€‰æ‹©åˆ†ææŠ¥å‘Š")

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šä¸€æ­¥çš„ç»“æœ
    previous_result = load_analysis_result()

    col1, col2 = st.columns(2)

    with col1:
        use_previous = st.checkbox(
            "ä½¿ç”¨æ·±åº¦åˆ†æç»“æœ",
            value=bool(previous_result),
            disabled=not bool(previous_result),
            help="ä½¿ç”¨æ·±åº¦åˆ†æé¡µé¢çš„åˆ†æç»“æœ" if previous_result else "æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœ"
        )

    if use_previous and previous_result:
        with col2:
            st.success("âœ… å·²åŠ è½½åˆ†æç»“æœ")

            # æ˜¾ç¤ºåˆ†æä¿¡æ¯
            analysis_template = previous_result.metadata.get('analysis_scenario', 'æœªçŸ¥')
            st.caption(f"åˆ†æç±»å‹: {analysis_template}")

        # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
        with st.expander("æŸ¥çœ‹åˆ†ææŠ¥å‘Šé¢„è§ˆ", expanded=False):
            # æ˜¾ç¤ºæ‰§è¡Œæ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'executive_summary' in previous_result.metadata:
                st.markdown("**æ‰§è¡Œæ‘˜è¦:**")
                st.info(previous_result.metadata['executive_summary'])
                st.markdown("---")

            # æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
            st.text_area(
                "æŠ¥å‘Šå†…å®¹é¢„è§ˆ",
                value=truncate_text(previous_result.content, 1500),
                height=300,
                disabled=True
            )

        return previous_result.content, previous_result.metadata

    else:
        # æ–‡ä»¶ä¸Šä¼ 
        st.markdown("#### ğŸ“¤ ä¸Šä¼ åˆ†ææŠ¥å‘Š")

        uploaded_file = st.file_uploader(
            "ä¸Šä¼ åˆ†ææŠ¥å‘Šæ–‡ä»¶",
            type=['txt', 'md', 'json'],
            help="æ”¯æŒæ–‡æœ¬ã€Markdownæˆ–JSONæ ¼å¼çš„åˆ†ææŠ¥å‘Š"
        )

        if uploaded_file:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            save_dir = Path("temp") / datetime.now().strftime("%Y%m%d_%H%M%S")
            success, file_path, message = save_uploaded_file(uploaded_file, save_dir)

            if success:
                st.success(message)

                # è¯»å–æ–‡ä»¶å†…å®¹
                if uploaded_file.type == 'application/json':
                    # JSONæ–‡ä»¶ç‰¹æ®Šå¤„ç†
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        content = data.get('content', '')
                        metadata = data.get('metadata', {})
                else:
                    # å…¶ä»–æ–‡ä»¶ä½œä¸ºçº¯æ–‡æœ¬å¤„ç†
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    metadata = get_file_metadata(file_path)

                # éªŒè¯å†…å®¹
                is_valid, msg = validate_text_input(content, min_length=200)
                if is_valid:
                    return content, metadata
                else:
                    st.error(f"åˆ†ææŠ¥å‘Šå†…å®¹ä¸ç¬¦åˆè¦æ±‚: {msg}")
                    return None, None
            else:
                st.error(message)
                return None, None

    return None, None


def show_capability_docs_section():
    """æ˜¾ç¤ºä¼ä¸šèƒ½åŠ›æ–‡æ¡£ä¸Šä¼ éƒ¨åˆ†"""
    st.markdown("### ğŸ¢ ä¼ä¸šèƒ½åŠ›æ–‡æ¡£ï¼ˆå¯é€‰ï¼‰")

    st.info("""
    ä¸Šä¼ ä¼ä¸šä»‹ç»ã€æ¡ˆä¾‹å±•ç¤ºã€èµ„è´¨è¯æ˜ç­‰æ–‡æ¡£ï¼Œç³»ç»Ÿå°†åœ¨ç”Ÿæˆæ–¹æ¡ˆæ—¶å‚è€ƒè¿™äº›ä¿¡æ¯ï¼Œ
    å¢å¼ºæ–¹æ¡ˆçš„é’ˆå¯¹æ€§å’Œè¯´æœåŠ›ã€‚
    """)

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "é€‰æ‹©èƒ½åŠ›æ–‡æ¡£",
        type=['docx', 'pdf', 'txt', 'md'],
        accept_multiple_files=True,
        help="å¯ä»¥ä¸Šä¼ å¤šä¸ªæ–‡æ¡£ï¼Œæ”¯æŒDOCXã€PDFã€TXTã€Markdownæ ¼å¼"
    )

    capability_doc_paths = []

    if uploaded_files:
        # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡ä»¶
        st.markdown("#### å·²ä¸Šä¼ çš„æ–‡æ¡£:")

        for i, uploaded_file in enumerate(uploaded_files):
            col1, col2, col3 = st.columns([3, 1, 1])

            with col1:
                st.text(f"ğŸ“„ {uploaded_file.name}")

            with col2:
                st.caption(format_file_size(uploaded_file.size))

            with col3:
                # ä¿å­˜æ–‡ä»¶
                save_dir = Path("temp") / "capability_docs" / datetime.now().strftime("%Y%m%d_%H%M%S")
                success, file_path, _ = save_uploaded_file(uploaded_file, save_dir)

                if success:
                    capability_doc_paths.append(file_path)
                    st.success("âœ“")
                else:
                    st.error("âœ—")

        # ä¿å­˜åˆ°session state
        st.session_state.proposal_generation['capability_docs'] = capability_doc_paths

        # æ˜¾ç¤ºæ–‡æ¡£é¢„è§ˆé€‰é¡¹
        if st.checkbox("é¢„è§ˆæ–‡æ¡£å†…å®¹", value=False):
            document_service = DocumentService()

            for doc_path in capability_doc_paths[:3]:  # æœ€å¤šé¢„è§ˆ3ä¸ª
                with st.expander(f"é¢„è§ˆ: {Path(doc_path).name}", expanded=False):
                    result = document_service.process(doc_path)
                    if result.is_success:
                        st.text_area(
                            "å†…å®¹é¢„è§ˆ",
                            value=truncate_text(result.content, 1000),
                            height=200,
                            disabled=True
                        )
                    else:
                        st.error("æ— æ³•è¯»å–æ–‡æ¡£å†…å®¹")

    return capability_doc_paths


def show_proposal_configuration():
    """æ˜¾ç¤ºæ–¹æ¡ˆç”Ÿæˆé…ç½®éƒ¨åˆ†"""
    st.markdown("### âš™ï¸ æ–¹æ¡ˆé…ç½®")

    # åˆå§‹åŒ–æ–¹æ¡ˆæœåŠ¡ä»¥è·å–å¯ç”¨æ¨¡æ¿
    proposal_service = ProposalService()

    # åŸºæœ¬é…ç½®
    col1, col2 = st.columns([2, 1])

    with col1:
        # æ–¹æ¡ˆç±»å‹é€‰æ‹©
        proposal_types = proposal_service.PROPOSAL_TYPES
        template_options = list(proposal_types.keys())
        template_names = [proposal_types[key]['name'] for key in template_options]

        selected_index = st.selectbox(
            "é€‰æ‹©æ–¹æ¡ˆç±»å‹",
            range(len(template_options)),
            format_func=lambda x: template_names[x],
            index=template_options.index(st.session_state.proposal_generation['current_template']),
            help="é€‰æ‹©è¦ç”Ÿæˆçš„æ–¹æ¡ˆç±»å‹"
        )

        selected_template = template_options[selected_index]
        st.session_state.proposal_generation['current_template'] = selected_template

        # æ˜¾ç¤ºæ–¹æ¡ˆè¯´æ˜
        proposal_info = proposal_types[selected_template]
        st.info(f"**æ–¹æ¡ˆè¯´æ˜**: {proposal_info['description']}")

        # æ˜¾ç¤ºæ–¹æ¡ˆç« èŠ‚
        st.markdown("**åŒ…å«ç« èŠ‚:**")
        sections_text = " â†’ ".join(proposal_info['sections'])
        st.caption(sections_text)

    with col2:
        # æ–¹æ¡ˆé€‰é¡¹
        st.markdown("**ç”Ÿæˆé€‰é¡¹**")

        include_pricing = st.checkbox(
            "åŒ…å«æŠ¥ä»·ä¿¡æ¯",
            value=selected_template == 'quotation_proposal',
            help="åœ¨æ–¹æ¡ˆä¸­åŒ…å«ä»·æ ¼å’ŒæŠ¥ä»·ä¿¡æ¯"
        )

        include_timeline = st.checkbox(
            "åŒ…å«æ—¶é—´è®¡åˆ’",
            value=True,
            help="åœ¨æ–¹æ¡ˆä¸­åŒ…å«é¡¹ç›®æ—¶é—´çº¿"
        )

        language = st.selectbox(
            "è¯­è¨€",
            options=['zh', 'en'],
            format_func=lambda x: {'zh': 'ä¸­æ–‡', 'en': 'English'}.get(x, x),
            help="æ–¹æ¡ˆçš„è¾“å‡ºè¯­è¨€"
        )

    # å®¢æˆ·ä¿¡æ¯éƒ¨åˆ†
    with st.expander("ğŸ‘¤ å®¢æˆ·ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰", expanded=False):
        st.markdown("æä¾›å®¢æˆ·ä¿¡æ¯å¯ä»¥è®©æ–¹æ¡ˆæ›´åŠ ä¸ªæ€§åŒ–")

        col1, col2 = st.columns(2)

        with col1:
            client_name = st.text_input(
                "å®¢æˆ·åç§°",
                placeholder="XXç§‘æŠ€æœ‰é™å…¬å¸",
                help="å°†åœ¨æ–¹æ¡ˆä¸­ä½¿ç”¨çš„å®¢æˆ·å…¬å¸åç§°"
            )

            project_name = st.text_input(
                "é¡¹ç›®åç§°",
                placeholder="æ™ºèƒ½åŒ–å‡çº§é¡¹ç›®",
                help="é¡¹ç›®çš„æ­£å¼åç§°"
            )

            industry = st.text_input(
                "æ‰€å±è¡Œä¸š",
                placeholder="äº’è”ç½‘/åˆ¶é€ ä¸š/é‡‘èç­‰",
                help="å®¢æˆ·æ‰€åœ¨çš„è¡Œä¸š"
            )

        with col2:
            contact_person = st.text_input(
                "è”ç³»äºº",
                placeholder="å¼ æ€»",
                help="ä¸»è¦è”ç³»äººå§“åæˆ–èŒä½"
            )

            budget_range = st.text_input(
                "é¢„ç®—èŒƒå›´",
                placeholder="50-100ä¸‡",
                help="é¡¹ç›®çš„é¢„ç®—èŒƒå›´ï¼ˆå¦‚æœçŸ¥é“ï¼‰"
            )

            timeline = st.text_input(
                "æ—¶é—´è¦æ±‚",
                placeholder="3ä¸ªæœˆå†…å®Œæˆ",
                help="é¡¹ç›®çš„æ—¶é—´è¦æ±‚"
            )

        # ä¿å­˜å®¢æˆ·ä¿¡æ¯
        client_info = {
            'client_name': client_name,
            'project_name': project_name,
            'industry': industry,
            'contact_person': contact_person,
            'budget_range': budget_range,
            'timeline': timeline
        }

        # è¿‡æ»¤æ‰ç©ºå€¼
        client_info = {k: v for k, v in client_info.items() if v}
        st.session_state.proposal_generation['client_info'] = client_info

    # è‡ªå®šä¹‰æ¨¡æ¿éƒ¨åˆ†
    with st.expander("ğŸ› ï¸ è‡ªå®šä¹‰æ–¹æ¡ˆæ¨¡æ¿ï¼ˆé«˜çº§ï¼‰", expanded=False):
        st.markdown("""
        æ‚¨å¯ä»¥æä¾›è‡ªå®šä¹‰çš„æ–¹æ¡ˆç”Ÿæˆæ¨¡æ¿ã€‚æ¨¡æ¿ä¸­å¯ä½¿ç”¨ä»¥ä¸‹å˜é‡ï¼š
        - `{analysis_report}`: åˆ†ææŠ¥å‘Šå†…å®¹
        - `{capability_docs}`: ä¼ä¸šèƒ½åŠ›æ–‡æ¡£å†…å®¹
        - `{client_info}`: å®¢æˆ·ä¿¡æ¯
        """)

        custom_prompt = st.text_area(
            "è‡ªå®šä¹‰æ–¹æ¡ˆæ¨¡æ¿",
            value=st.session_state.proposal_generation.get('custom_prompt', ''),
            height=400,
            placeholder="è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰æ–¹æ¡ˆç”Ÿæˆæ¨¡æ¿...",
            help="ç•™ç©ºåˆ™ä½¿ç”¨é€‰å®šçš„é¢„è®¾æ¨¡æ¿"
        )

        if custom_prompt:
            st.session_state.proposal_generation['custom_prompt'] = custom_prompt

        # æ¨¡æ¿ç¤ºä¾‹
        if st.button("æŸ¥çœ‹æ¨¡æ¿ç¤ºä¾‹"):
            st.code("""
# é¡¹ç›®å»ºè®®ä¹¦

## ä¸€ã€é¡¹ç›®èƒŒæ™¯
åŸºäºåˆ†ææŠ¥å‘Šï¼š{analysis_report}

## äºŒã€è§£å†³æ–¹æ¡ˆ
[è¯¦ç»†æ–¹æ¡ˆè®¾è®¡]

## ä¸‰ã€æˆ‘ä»¬çš„ä¼˜åŠ¿
{capability_docs}

## å››ã€é¡¹ç›®è®¡åˆ’
[å®æ–½è®¡åˆ’å’Œæ—¶é—´è¡¨]

## äº”ã€æŠ•èµ„ä¸æ”¶ç›Š
[å•†åŠ¡æ¡æ¬¾å’ŒROIåˆ†æ]
""", language='markdown')

    # è¿”å›é…ç½®é€‰é¡¹
    options = {
        'template': selected_template,
        'include_pricing': include_pricing,
        'include_timeline': include_timeline,
        'language': language,
        'client_info': client_info,
        'custom_prompt': custom_prompt if custom_prompt else None
    }

    return options


def perform_proposal_generation(analysis_report: str,
                                analysis_metadata: dict,
                                capability_docs: List[str],
                                options: dict):
    """æ‰§è¡Œæ–¹æ¡ˆç”Ÿæˆ"""
    session_manager = st.session_state.session_manager

    # åˆ›å»ºè¿›åº¦å®¹å™¨
    progress_container = st.container()

    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()

        # åˆå§‹åŒ–è¿›åº¦è·Ÿè¸ª
        st.session_state.proposal_generation['current_progress'] = 0

        try:
            # åˆå§‹åŒ–æ–¹æ¡ˆæœåŠ¡
            status_text.text("æ­£åœ¨åˆå§‹åŒ–æ–¹æ¡ˆç”ŸæˆæœåŠ¡...")
            progress_bar.progress(10)
            st.session_state.proposal_generation['current_progress'] = 10

            proposal_service = ProposalService()

            # å®šä¹‰è¿›åº¦å›è°ƒ
            def progress_callback(msg):
                status_text.text(msg)
                # ä» session state è·å–å½“å‰è¿›åº¦
                current = st.session_state.proposal_generation['current_progress']
                if current < 90:
                    new_progress = min(current + 15, 90)
                    progress_bar.progress(new_progress)
                    st.session_state.proposal_generation['current_progress'] = new_progress

            options['progress_callback'] = progress_callback

            # æ·»åŠ èƒ½åŠ›æ–‡æ¡£åˆ°é€‰é¡¹
            if capability_docs:
                options['capability_docs'] = capability_docs

            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_data = {
                'analysis_report': analysis_report,
                'metadata': analysis_metadata
            }

            # æ‰§è¡Œæ–¹æ¡ˆç”Ÿæˆ
            status_text.text("æ­£åœ¨ç”Ÿæˆæ–¹æ¡ˆ...")
            progress_bar.progress(30)
            st.session_state.proposal_generation['current_progress'] = 30

            start_time = time.time()
            result = proposal_service.process(
                input_data,
                template=options['template'],
                options=options
            )

            progress_bar.progress(100)
            st.session_state.proposal_generation['current_progress'] = 100

            if result.is_success:
                status_text.text("âœ… æ–¹æ¡ˆç”Ÿæˆå®Œæˆï¼")

                # åº”ç”¨å®¢æˆ·ä¿¡æ¯å®šåˆ¶åŒ–
                if options.get('client_info'):
                    result.content = proposal_service.customize_proposal(
                        result.content,
                        options['client_info']
                    )

                # ä¿å­˜ç»“æœåˆ°ä¼šè¯
                session_manager.save_result('proposal', result)
                st.session_state.proposal_generation['proposal_result'] = result

                # æ·»åŠ åˆ°å†å²è®°å½•
                st.session_state.proposal_generation['generation_history'].append({
                    'timestamp': datetime.now(),
                    'template': options['template'],
                    'processing_time': result.processing_time,
                    'has_capability_docs': bool(capability_docs),
                    'result': result
                })

                # è·å–æ–¹æ¡ˆå¤§çº²
                outline = proposal_service.get_proposal_outline(options['template'])
                result.metadata['outline'] = outline

                st.success(f"""
                æ–¹æ¡ˆç”ŸæˆæˆåŠŸï¼
                - ç”Ÿæˆæ—¶é—´: {result.processing_time:.1f} ç§’
                - ä½¿ç”¨æ¨¡å‹: {result.model_used}
                - Tokenä½¿ç”¨: {result.total_tokens:,}
                - é¢„ä¼°è´¹ç”¨: ${result.metadata.get('estimated_cost', 0):.4f}
                """)

                # è‡ªåŠ¨åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºç»“æœ
                time.sleep(1)
                st.rerun()

            else:
                status_text.text("âŒ æ–¹æ¡ˆç”Ÿæˆå¤±è´¥")
                st.error(f"ç”Ÿæˆå¤±è´¥: {result.error}")

        except Exception as e:
            status_text.text("âŒ å‘ç”Ÿé”™è¯¯")
            st.error(f"ç”Ÿæˆè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

        finally:
            # æ¸…ç†è¿›åº¦æ˜¾ç¤º
            time.sleep(2)
            progress_container.empty()
            # é‡ç½®è¿›åº¦
            st.session_state.proposal_generation['current_progress'] = 0


def show_proposal_result():
    """æ˜¾ç¤ºæ–¹æ¡ˆç”Ÿæˆç»“æœ"""
    result = st.session_state.proposal_generation.get('proposal_result')

    if not result:
        return

    st.markdown("---")
    st.markdown("### ğŸ“„ ç”Ÿæˆçš„æ–¹æ¡ˆ")

    # æ˜¾ç¤ºæ–¹æ¡ˆä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ–¹æ¡ˆç±»å‹", result.metadata.get('proposal_name', 'æœªçŸ¥'))

    with col2:
        st.metric("ç”Ÿæˆç”¨æ—¶", f"{result.processing_time:.1f} ç§’")

    with col3:
        st.metric("å­—æ•°", f"{result.metadata.get('word_count', 0):,}")

    with col4:
        reading_time = result.metadata.get('estimated_reading_time_minutes', 0)
        st.metric("é¢„è®¡é˜…è¯»", f"{reading_time} åˆ†é’Ÿ")

    # æ–¹æ¡ˆå¤§çº²ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'outline' in result.metadata and result.metadata['outline']:
        with st.expander("ğŸ“‘ æ–¹æ¡ˆå¤§çº²", expanded=True):
            outline = result.metadata['outline']
            for item in outline:
                level = item.get('level', 1)
                indent = "  " * (level - 1)
                st.write(f"{indent}{item['number']}. {item['title']}")
                if 'description' in item:
                    st.caption(f"{indent}   {item['description']}")

    # æ–¹æ¡ˆå†…å®¹æ˜¾ç¤º
    st.markdown("#### ğŸ“ æ–¹æ¡ˆå†…å®¹")

    # æ˜¾ç¤ºé€‰é¡¹
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        display_mode = st.radio(
            "æ˜¾ç¤ºæ¨¡å¼",
            options=['formatted', 'plain'],
            format_func=lambda x: {'formatted': 'æ ¼å¼åŒ–æ˜¾ç¤º', 'plain': 'çº¯æ–‡æœ¬'}.get(x, x),
            horizontal=True
        )

    with col2:
        if st.button("ğŸ“‹ å¤åˆ¶å…¨æ–‡"):
            st.write(result.content)  # Streamlitä¼šè‡ªåŠ¨æ·»åŠ å¤åˆ¶åŠŸèƒ½
            st.success("å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼")

    with col3:
        # æ‰“å°é¢„è§ˆ
        if st.button("ğŸ–¨ï¸ æ‰“å°é¢„è§ˆ"):
            # åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€æ‰“å°å‹å¥½çš„ç‰ˆæœ¬
            st.markdown(f'<a href="data:text/html,{result.content}" target="_blank">åœ¨æ–°çª—å£æ‰“å¼€</a>',
                        unsafe_allow_html=True)

    # æ˜¾ç¤ºæ–¹æ¡ˆå†…å®¹
    if display_mode == 'formatted':
        # ä½¿ç”¨å®¹å™¨æ˜¾ç¤ºæ ¼å¼åŒ–çš„Markdownå†…å®¹
        content_container = st.container()
        with content_container:
            # æ·»åŠ ä¸€äº›æ ·å¼ä»¥æ”¹å–„æ˜¾ç¤ºæ•ˆæœ
            st.markdown("""
            <style>
            .proposal-content {
                line-height: 1.6;
                font-size: 16px;
            }
            .proposal-content h1 { color: #1f77b4; margin-top: 2em; }
            .proposal-content h2 { color: #2c5aa0; margin-top: 1.5em; }
            .proposal-content h3 { color: #3d6db5; margin-top: 1.2em; }
            .proposal-content ul, .proposal-content ol { margin-left: 2em; }
            .proposal-content blockquote { 
                border-left: 4px solid #ddd; 
                padding-left: 1em; 
                color: #666; 
            }
            </style>
            """, unsafe_allow_html=True)

            st.markdown(f'<div class="proposal-content">{result.content}</div>',
                        unsafe_allow_html=True)
    else:
        # çº¯æ–‡æœ¬æ˜¾ç¤º
        st.text_area(
            "æ–¹æ¡ˆå†…å®¹",
            value=result.content,
            height=600,
            disabled=True
        )

    # æ“ä½œæŒ‰é’®
    st.markdown("#### ğŸ’¾ å¯¼å‡ºå’Œä¿å­˜")

    col1, col2, col3, col4 = st.columns(4)

    # å‡†å¤‡æ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    proposal_type = result.metadata.get('proposal_type', 'proposal')
    client_name = st.session_state.proposal_generation.get('client_info', {}).get('client_name', '')

    if client_name:
        base_filename = f"{client_name}_{proposal_type}_{timestamp}"
    else:
        base_filename = f"{proposal_type}_{timestamp}"

    with col1:
        # ä¸‹è½½Markdownæ ¼å¼
        filename_md = f"{base_filename}.md"

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½(Markdown)",
            data=result.content,
            file_name=filename_md,
            mime="text/markdown",
            use_container_width=True
        )

    with col2:
        # ä¸‹è½½çº¯æ–‡æœ¬æ ¼å¼
        plain_text = markdown_to_text(result.content)
        filename_txt = f"{base_filename}.txt"

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½(TXT)",
            data=plain_text,
            file_name=filename_txt,
            mime="text/plain",
            use_container_width=True
        )

    with col3:
        # ä¸‹è½½å®Œæ•´æ•°æ®ï¼ˆJSONï¼‰
        export_data = {
            'proposal': result.content,
            'metadata': result.metadata,
            'client_info': st.session_state.proposal_generation.get('client_info', {}),
            'generation_info': {
                'processing_time': result.processing_time,
                'model_used': result.model_used,
                'tokens_consumed': result.tokens_consumed,
                'timestamp': datetime.now().isoformat()
            }
        }

        filename_json = f"{base_filename}_complete.json"
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½(å®Œæ•´æ•°æ®)",
            data=json_str,
            file_name=filename_json,
            mime="application/json",
            use_container_width=True
        )

    with col4:
        # é‡æ–°ç”Ÿæˆ
        if st.button("ğŸ”„ é‡æ–°ç”Ÿæˆ", use_container_width=True):
            st.session_state.proposal_generation['proposal_result'] = None
            st.rerun()


def show_generation_history():
    """æ˜¾ç¤ºç”Ÿæˆå†å²"""
    history = st.session_state.proposal_generation.get('generation_history', [])

    if not history:
        return

    st.markdown("---")
    st.markdown("### ğŸ“š ç”Ÿæˆå†å²")

    # æŒ‰æ—¶é—´å€’åºæ˜¾ç¤ºæœ€è¿‘çš„ç”Ÿæˆè®°å½•
    for item in reversed(history[-5:]):  # åªæ˜¾ç¤ºæœ€è¿‘5æ¡
        template_name = ProposalService.PROPOSAL_TYPES.get(
            item['template'], {}
        ).get('name', item['template'])

        extra_info = []
        if item.get('has_capability_docs'):
            extra_info.append("å«èƒ½åŠ›æ–‡æ¡£")

        title = f"{template_name} - {item['timestamp'].strftime('%H:%M:%S')}"
        if extra_info:
            title += f" ({', '.join(extra_info)})"

        with st.expander(title, expanded=False):
            st.text(f"ç”Ÿæˆæ—¶é—´: {item['processing_time']:.1f} ç§’")
            st.text(f"æ–¹æ¡ˆé•¿åº¦: {len(item['result'].content):,} å­—ç¬¦")

            col1, col2 = st.columns(2)
            with col1:
                if st.button(f"ä½¿ç”¨æ­¤æ–¹æ¡ˆ", key=f"use_{item['timestamp']}"):
                    st.session_state.proposal_generation['proposal_result'] = item['result']
                    st.rerun()

            with col2:
                if st.button(f"æŸ¥çœ‹è¯¦æƒ…", key=f"view_{item['timestamp']}"):
                    with st.container():
                        st.markdown("**æ–¹æ¡ˆé¢„è§ˆ:**")
                        st.text_area(
                            "å†…å®¹",
                            value=truncate_text(item['result'].content, 1000),
                            height=300,
                            disabled=True,
                            key=f"preview_{item['timestamp']}"
                        )


def main():
    """ä¸»å‡½æ•°"""
    # åœ¨é¡µé¢é¡¶éƒ¨æ£€æŸ¥API Keyè®¾ç½®
    check_api_key_setup()

    # åˆå§‹åŒ–é¡µé¢çŠ¶æ€
    initialize_page_state()

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸ“‹ æ–¹æ¡ˆç”Ÿæˆ")
    st.markdown("åŸºäºåˆ†æç»“æœç”Ÿæˆä¸“ä¸šçš„å•†ä¸šæ–¹æ¡ˆå’Œé¡¹ç›®å»ºè®®ä¹¦")

    # æ˜¾ç¤ºç”Ÿæˆç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
    if st.session_state.proposal_generation.get('proposal_result'):
        show_proposal_result()
        show_generation_history()
    else:
        # è·å–åˆ†ææŠ¥å‘Š
        analysis_report, analysis_metadata = show_analysis_source_section()

        if analysis_report:
            st.markdown("---")

            # ä¼ä¸šèƒ½åŠ›æ–‡æ¡£
            capability_docs = show_capability_docs_section()

            st.markdown("---")

            # æ–¹æ¡ˆé…ç½®
            options = show_proposal_configuration()

            st.markdown("---")

            # ç”Ÿæˆæ–¹æ¡ˆæŒ‰é’®
            col1, col2, col3 = st.columns([2, 1, 2])
            with col2:
                button_text = "ğŸš€ ç”Ÿæˆæ–¹æ¡ˆ"
                if capability_docs:
                    button_text += f" ({len(capability_docs)}ä»½å‚è€ƒ)"

                if st.button(
                        button_text,
                        type="primary",
                        use_container_width=True,
                        disabled=st.session_state.proposal_generation.get('processing', False)
                ):
                    st.session_state.proposal_generation['processing'] = True
                    perform_proposal_generation(
                        analysis_report,
                        analysis_metadata,
                        capability_docs,
                        options
                    )
                    st.session_state.proposal_generation['processing'] = False

        # æ˜¾ç¤ºå†å²è®°å½•
        show_generation_history()

    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
        st.info("""
**æ–¹æ¡ˆç±»å‹é€‰æ‹©**ï¼š
- é¡¹ç›®å»ºè®®ä¹¦ï¼šå®Œæ•´çš„é¡¹ç›®æ–¹æ¡ˆ
- å•†åŠ¡æŠ¥ä»·ï¼šé‡ç‚¹åœ¨ä»·æ ¼å’ŒæœåŠ¡
- è§£å†³æ–¹æ¡ˆç®€æŠ¥ï¼šç²¾ç®€ç‰ˆæ–¹æ¡ˆ

**ä¼ä¸šèƒ½åŠ›æ–‡æ¡£**ï¼š
- ä¸Šä¼ å…¬å¸ä»‹ç»ã€æ¡ˆä¾‹ç­‰
- ç³»ç»Ÿä¼šè‡ªåŠ¨å¼•ç”¨ç›¸å…³å†…å®¹
- å¢å¼ºæ–¹æ¡ˆçš„è¯´æœåŠ›

**å®¢æˆ·ä¿¡æ¯**ï¼š
- å¡«å†™å®¢æˆ·ä¿¡æ¯ä¸ªæ€§åŒ–æ–¹æ¡ˆ
- è‡ªåŠ¨æ›¿æ¢å®¢æˆ·åç§°ç­‰ä¿¡æ¯

**å¯¼å‡ºæ ¼å¼**ï¼š
- Markdownï¼šä¿ç•™æ ¼å¼
- TXTï¼šçº¯æ–‡æœ¬ï¼Œä¾¿äºç¼–è¾‘
- JSONï¼šåŒ…å«å®Œæ•´æ•°æ®
""")

        # æ–¹æ¡ˆæ¨¡æ¿è¯´æ˜
        if st.button("ğŸ“– æŸ¥çœ‹æ–¹æ¡ˆç»“æ„"):
            proposal_type = st.session_state.proposal_generation.get('current_template', 'project_proposal')
            proposal_info = ProposalService.PROPOSAL_TYPES.get(proposal_type, {})

            st.markdown(f"### {proposal_info.get('name', 'æ–¹æ¡ˆ')}ç»“æ„")

            sections = proposal_info.get('sections', [])
            for i, section in enumerate(sections, 1):
                st.write(f"{i}. {section}")


if __name__ == "__main__":
    main()

--- File: pages/4_ğŸš€_One_Click_Generation.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/pages/4_ğŸš€_One_Click_Generation.py
åŠŸèƒ½è¯´æ˜: ä¸€é”®ç”Ÿæˆé¡µé¢ï¼Œå®ç°ä»è¾“å…¥åˆ°æ–¹æ¡ˆçš„ç«¯åˆ°ç«¯å¤„ç†
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-29
ç‰ˆæœ¬: 1.1.0
"""

import os
import sys
import streamlit as st
from pathlib import Path
from datetime import datetime
import time
import json
import zipfile
from typing import List, Dict, Optional, Any, Tuple
import shutil

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.document_processor import DocumentProcessor
from core.session_manager import SessionManager
from services.analysis_service import DeepAnalysisService
from services.proposal_service import ProposalService
from services.document_service import DocumentService
from utils.file_utils import (
    save_uploaded_file,
    get_file_metadata,
    format_file_size,
    create_unique_filename,
    ensure_directory_exists,
    validate_file_size,
    validate_file_format,
    create_temp_directory,
    cleanup_directory
)
from utils.format_utils import (
    format_duration,
    format_timestamp,
    format_percentage,
    format_table_text
)
from utils.validation_utils import validate_batch_files
from utils.ui_utils import check_api_key_setup # å¼•å…¥æ£€æŸ¥å‡½æ•°

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸€é”®ç”Ÿæˆ - SmartProposal Engine",
    page_icon="ğŸš€",
    layout="wide"
)


def initialize_page_state():
    """åˆå§‹åŒ–é¡µé¢çŠ¶æ€"""
    if 'one_click_generation' not in st.session_state:
        st.session_state.one_click_generation = {
            'input_files': [],
            'capability_docs': [],
            'processing_status': 'idle',  # idle, processing, completed, error
            'current_step': None,
            'processing_results': {},
            'workflow_config': {
                'analysis_template': 'customer_interview',
                'proposal_template': 'project_proposal',
                'enable_text_optimization': False,
                'include_capability_docs': True
            },
            'batch_id': None,
            'start_time': None,
            'end_time': None,
            'current_progress': 0,  # æ·»åŠ å…¨å±€è¿›åº¦è·Ÿè¸ª
            'file_progress': {}  # æ·»åŠ æ¯ä¸ªæ–‡ä»¶çš„è¿›åº¦è·Ÿè¸ª
        }

    # ç¡®ä¿SessionManagerå­˜åœ¨
    if 'session_manager' not in st.session_state:
        st.session_state.session_manager = SessionManager()

    # åˆ›å»ºæ‰¹æ¬¡ä¼šè¯
    if not st.session_state.one_click_generation.get('batch_id'):
        batch_id = datetime.now().strftime('%Y%m%d_%H%M%S')
        st.session_state.one_click_generation['batch_id'] = batch_id
        st.session_state.session_manager.create_session(f'batch_{batch_id}')


def show_upload_section():
    """æ˜¾ç¤ºæ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†"""
    st.markdown("### ğŸ“ ä¸Šä¼ æ–‡ä»¶")

    # åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ“¥ å¾…å¤„ç†æ–‡ä»¶", "ğŸ¢ ä¼ä¸šèƒ½åŠ›æ–‡æ¡£"])

    with tab1:
        st.info("""
        ä¸Šä¼ éœ€è¦å¤„ç†çš„åŸå§‹æ–‡ä»¶ï¼Œæ”¯æŒï¼š
        - **éŸ³é¢‘æ–‡ä»¶**ï¼šå®¢æˆ·è®¿è°ˆå½•éŸ³ã€ä¼šè®®å½•éŸ³ç­‰ï¼ˆm4a, mp3, wavç­‰ï¼‰
        - **æ–‡æ¡£æ–‡ä»¶**ï¼šéœ€æ±‚æ–‡æ¡£ã€ä¼šè®®è®°å½•ç­‰ï¼ˆdocx, pdf, txtç­‰ï¼‰
        """)

        uploaded_input_files = st.file_uploader(
            "é€‰æ‹©è¦å¤„ç†çš„æ–‡ä»¶",
            type=['m4a', 'mp3', 'wav', 'aac', 'ogg', 'flac', 'mp4',
                  'docx', 'pdf', 'txt', 'doc', 'rtf'],
            accept_multiple_files=True,
            key="input_files_uploader",
            help="å¯ä»¥åŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶è¿›è¡Œæ‰¹é‡å¤„ç†"
        )

        if uploaded_input_files:
            # éªŒè¯æ–‡ä»¶
            file_paths = []
            total_size = 0

            st.markdown("#### å·²ä¸Šä¼ çš„å¾…å¤„ç†æ–‡ä»¶:")

            # åˆ›å»ºè¡¨æ ¼æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            file_info_data = []

            for file in uploaded_input_files:
                # éªŒè¯å•ä¸ªæ–‡ä»¶å¤§å°
                is_valid_size, size_msg = validate_file_size(file.size / (1024 * 1024), 200)

                if is_valid_size:
                    file_info_data.append({
                        "æ–‡ä»¶å": file.name,
                        "ç±»å‹": file.type,
                        "å¤§å°": format_file_size(file.size),
                        "çŠ¶æ€": "âœ… æœ‰æ•ˆ"
                    })
                    total_size += file.size
                else:
                    file_info_data.append({
                        "æ–‡ä»¶å": file.name,
                        "ç±»å‹": file.type,
                        "å¤§å°": format_file_size(file.size),
                        "çŠ¶æ€": f"âŒ {size_msg}"
                    })

            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            for info in file_info_data:
                col1, col2, col3, col4 = st.columns([3, 2, 1, 1])
                with col1:
                    st.text(info["æ–‡ä»¶å"])
                with col2:
                    st.caption(info["ç±»å‹"])
                with col3:
                    st.caption(info["å¤§å°"])
                with col4:
                    st.caption(info["çŠ¶æ€"])

            # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
            st.caption(f"æ€»è®¡: {len(uploaded_input_files)} ä¸ªæ–‡ä»¶, {format_file_size(total_size)}")

            # ä¿å­˜æœ‰æ•ˆæ–‡ä»¶
            valid_files = [f for f, info in zip(uploaded_input_files, file_info_data)
                           if "âœ…" in info["çŠ¶æ€"]]
            st.session_state.one_click_generation['input_files'] = valid_files

    with tab2:
        st.info("""
        ä¸Šä¼ ä¼ä¸šä»‹ç»ã€æˆåŠŸæ¡ˆä¾‹ã€èµ„è´¨è¯æ˜ç­‰æ–‡æ¡£ï¼Œç³»ç»Ÿå°†åœ¨ç”Ÿæˆæ–¹æ¡ˆæ—¶æ™ºèƒ½å¼•ç”¨ï¼Œ
        å¢å¼ºæ–¹æ¡ˆçš„ä¸“ä¸šæ€§å’Œè¯´æœåŠ›ã€‚ï¼ˆå¯é€‰ï¼‰
        """)

        uploaded_capability_docs = st.file_uploader(
            "é€‰æ‹©ä¼ä¸šèƒ½åŠ›æ–‡æ¡£",
            type=['docx', 'pdf', 'txt', 'md'],
            accept_multiple_files=True,
            key="capability_docs_uploader",
            help="è¿™äº›æ–‡æ¡£å°†ä½œä¸ºç”Ÿæˆæ–¹æ¡ˆçš„å‚è€ƒèµ„æ–™"
        )

        if uploaded_capability_docs:
            st.markdown("#### å·²ä¸Šä¼ çš„èƒ½åŠ›æ–‡æ¡£:")

            doc_info_data = []
            for doc in uploaded_capability_docs:
                doc_info_data.append({
                    "æ–‡ä»¶å": doc.name,
                    "å¤§å°": format_file_size(doc.size)
                })

            # æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨
            for info in doc_info_data:
                col1, col2 = st.columns([4, 1])
                with col1:
                    st.text(f"ğŸ“„ {info['æ–‡ä»¶å']}")
                with col2:
                    st.caption(info['å¤§å°'])

            st.session_state.one_click_generation['capability_docs'] = uploaded_capability_docs

    # è¿”å›æ–‡ä»¶ç»Ÿè®¡
    input_files = st.session_state.one_click_generation.get('input_files', [])
    capability_docs = st.session_state.one_click_generation.get('capability_docs', [])

    return input_files, capability_docs


def show_workflow_configuration():
    """æ˜¾ç¤ºå·¥ä½œæµé…ç½®éƒ¨åˆ†"""
    st.markdown("### âš™ï¸ å¤„ç†é…ç½®")

    config = st.session_state.one_click_generation['workflow_config']

    col1, col2 = st.columns(2)

    with col1:
        # åˆ†æé…ç½®
        st.markdown("#### ğŸ” åˆ†æè®¾ç½®")

        # åˆ†ææ¨¡æ¿é€‰æ‹©
        analysis_service = DeepAnalysisService()
        scenarios = analysis_service.ANALYSIS_SCENARIOS
        template_options = list(scenarios.keys())
        template_names = [scenarios[key]['name'] for key in template_options]

        selected_analysis_index = st.selectbox(
            "åˆ†æåœºæ™¯",
            range(len(template_options)),
            format_func=lambda x: template_names[x],
            index=template_options.index(config['analysis_template']),
            key="analysis_template_select",
            help="é€‰æ‹©é€‚åˆçš„åˆ†æåœºæ™¯"
        )

        config['analysis_template'] = template_options[selected_analysis_index]

        # æ–‡æœ¬ä¼˜åŒ–é€‰é¡¹ï¼ˆä»…å¯¹éŸ³é¢‘æ–‡ä»¶æœ‰æ•ˆï¼‰
        config['enable_text_optimization'] = st.checkbox(
            "å¯ç”¨è½¬å½•æ–‡æœ¬ä¼˜åŒ–",
            value=config['enable_text_optimization'],
            help="ä½¿ç”¨AIä¼˜åŒ–éŸ³é¢‘è½¬å½•çš„æ–‡æœ¬è´¨é‡ï¼ˆä¼šå¢åŠ å¤„ç†æ—¶é—´ï¼‰"
        )

        # è¯´è¯äººè¯†åˆ«é€‰é¡¹
        config['enable_speaker_diarization'] = st.checkbox(
            "å¯ç”¨è¯´è¯äººè¯†åˆ«",
            value=True,
            help="è¯†åˆ«å¹¶åŒºåˆ†ä¸åŒçš„è¯´è¯äººï¼ˆé€‚ç”¨äºå¤šäººå¯¹è¯ï¼‰"
        )

    with col2:
        # æ–¹æ¡ˆç”Ÿæˆé…ç½®
        st.markdown("#### ğŸ“ æ–¹æ¡ˆè®¾ç½®")

        # æ–¹æ¡ˆæ¨¡æ¿é€‰æ‹©
        proposal_service = ProposalService()
        proposal_types = proposal_service.PROPOSAL_TYPES
        proposal_options = list(proposal_types.keys())
        proposal_names = [proposal_types[key]['name'] for key in proposal_options]

        selected_proposal_index = st.selectbox(
            "æ–¹æ¡ˆç±»å‹",
            range(len(proposal_options)),
            format_func=lambda x: proposal_names[x],
            index=proposal_options.index(config['proposal_template']),
            key="proposal_template_select",
            help="é€‰æ‹©è¦ç”Ÿæˆçš„æ–¹æ¡ˆç±»å‹"
        )

        config['proposal_template'] = proposal_options[selected_proposal_index]

        # æ˜¯å¦ä½¿ç”¨èƒ½åŠ›æ–‡æ¡£
        has_capability_docs = len(st.session_state.one_click_generation.get('capability_docs', [])) > 0
        config['include_capability_docs'] = st.checkbox(
            f"å¼•ç”¨ä¼ä¸šèƒ½åŠ›æ–‡æ¡£ ({len(st.session_state.one_click_generation.get('capability_docs', []))}ä»½)",
            value=config['include_capability_docs'] and has_capability_docs,
            disabled=not has_capability_docs,
            help="åœ¨æ–¹æ¡ˆä¸­å¼•ç”¨ä¸Šä¼ çš„ä¼ä¸šèƒ½åŠ›æ–‡æ¡£"
        )

        # è¾“å‡ºè¯­è¨€
        config['output_language'] = st.selectbox(
            "è¾“å‡ºè¯­è¨€",
            options=['zh', 'en'],
            format_func=lambda x: {'zh': 'ä¸­æ–‡', 'en': 'English'}.get(x, x),
            help="æ–¹æ¡ˆçš„è¾“å‡ºè¯­è¨€"
        )

    # é«˜çº§è®¾ç½®
    with st.expander("ğŸ”§ é«˜çº§è®¾ç½®", expanded=False):
        col1, col2, col3 = st.columns(3)

        with col1:
            config['max_workers'] = st.number_input(
                "å¹¶å‘å¤„ç†æ•°",
                min_value=1,
                max_value=5,
                value=1,
                help="åŒæ—¶å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆå»ºè®®ä¿æŒä¸º1ä»¥é¿å…APIé™åˆ¶ï¼‰"
            )

        with col2:
            config['save_intermediate_results'] = st.checkbox(
                "ä¿å­˜ä¸­é—´ç»“æœ",
                value=True,
                help="ä¿å­˜æ¯ä¸ªå¤„ç†æ­¥éª¤çš„ç»“æœ"
            )

        with col3:
            config['auto_cleanup'] = st.checkbox(
                "è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶",
                value=True,
                help="å¤„ç†å®Œæˆåè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶"
            )

    # å®¢æˆ·ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    st.markdown("#### ğŸ‘¤ å®¢æˆ·ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰")
    col1, col2, col3 = st.columns(3)

    with col1:
        config['client_name'] = st.text_input(
            "å®¢æˆ·åç§°",
            placeholder="XXç§‘æŠ€æœ‰é™å…¬å¸",
            help="å°†åœ¨æ–¹æ¡ˆä¸­ä½¿ç”¨çš„å®¢æˆ·åç§°"
        )

    with col2:
        config['project_name'] = st.text_input(
            "é¡¹ç›®åç§°",
            placeholder="æ™ºèƒ½åŒ–å‡çº§é¡¹ç›®",
            help="é¡¹ç›®çš„æ­£å¼åç§°"
        )

    with col3:
        config['contact_person'] = st.text_input(
            "è”ç³»äºº",
            placeholder="å¼ æ€»",
            help="ä¸»è¦è”ç³»äºº"
        )

    # æ›´æ–°é…ç½®
    st.session_state.one_click_generation['workflow_config'] = config

    return config


def process_single_file(file, file_index: int, total_files: int,
                        config: dict, progress_callback) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªæ–‡ä»¶çš„å®Œæ•´æµç¨‹"""
    results = {
        'file_name': file.name,
        'file_index': file_index,
        'steps': {},
        'success': False,
        'error': None
    }

    temp_dir = None

    # åˆå§‹åŒ–è¯¥æ–‡ä»¶çš„è¿›åº¦è·Ÿè¸ª
    file_key = f"file_{file_index}"
    st.session_state.one_click_generation['file_progress'][file_key] = 0

    try:
        # æ­¥éª¤1: ä¿å­˜æ–‡ä»¶
        progress_callback(f"[{file_index + 1}/{total_files}] æ­£åœ¨ä¿å­˜æ–‡ä»¶: {file.name}")

        batch_id = st.session_state.one_click_generation['batch_id']
        temp_dir = Path("temp") / batch_id / f"file_{file_index}"
        ensure_directory_exists(temp_dir)

        success, file_path, message = save_uploaded_file(file, temp_dir)
        if not success:
            raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {message}")

        # æ­¥éª¤2: æ–‡æ¡£å¤„ç†ï¼ˆè½¬å½•æˆ–æå–æ–‡æœ¬ï¼‰
        progress_callback(f"[{file_index + 1}/{total_files}] æ­£åœ¨å¤„ç†æ–‡ä»¶å†…å®¹...")

        processor = DocumentProcessor()

        # åˆ›å»ºæ–‡ä»¶ç‰¹å®šçš„è¿›åº¦å›è°ƒ
        def file_progress_callback(msg):
            progress_callback(f"[{file_index + 1}/{total_files}] {msg}")
            # æ›´æ–°æ–‡ä»¶è¿›åº¦
            current = st.session_state.one_click_generation['file_progress'][file_key]
            if current < 90:
                new_progress = min(current + 10, 90)
                st.session_state.one_click_generation['file_progress'][file_key] = new_progress

        process_options = {
            'enable_speaker_diarization': config.get('enable_speaker_diarization', True),
            'enable_text_optimization': config.get('enable_text_optimization', False),
            'max_segment_duration_minutes': 20,
            'extract_metadata': True,
            'progress_callback': file_progress_callback
        }

        process_result = processor.process_file(file_path, process_options)

        if not process_result.is_success:
            raise Exception(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {process_result.error}")

        results['steps']['processing'] = {
            'success': True,
            'content_length': len(process_result.content),
            'processing_time': process_result.processing_time,
            'file_type': process_result.source_type
        }

        # æ­¥éª¤3: æ·±åº¦åˆ†æ
        progress_callback(f"[{file_index + 1}/{total_files}] æ­£åœ¨è¿›è¡Œæ·±åº¦åˆ†æ...")

        analysis_service = DeepAnalysisService()
        analysis_options = {
            'template': config['analysis_template'],
            'include_recommendations': True,
            'output_format': 'markdown',
            'progress_callback': file_progress_callback
        }

        analysis_result = analysis_service.process(
            process_result.content,
            template=config['analysis_template'],
            options=analysis_options
        )

        if not analysis_result.is_success:
            raise Exception(f"åˆ†æå¤±è´¥: {analysis_result.error}")

        results['steps']['analysis'] = {
            'success': True,
            'template_used': config['analysis_template'],
            'processing_time': analysis_result.processing_time,
            'tokens_used': analysis_result.total_tokens
        }

        # æ­¥éª¤4: æ–¹æ¡ˆç”Ÿæˆ
        progress_callback(f"[{file_index + 1}/{total_files}] æ­£åœ¨ç”Ÿæˆæ–¹æ¡ˆ...")

        proposal_service = ProposalService()
        proposal_options = {
            'template': config['proposal_template'],
            'language': config.get('output_language', 'zh'),
            'progress_callback': file_progress_callback
        }

        # æ·»åŠ å®¢æˆ·ä¿¡æ¯
        client_info = {}
        if config.get('client_name'):
            client_info['client_name'] = config['client_name']
        if config.get('project_name'):
            client_info['project_name'] = config['project_name']
        if config.get('contact_person'):
            client_info['contact_person'] = config['contact_person']

        if client_info:
            proposal_options['client_info'] = client_info

        # æ·»åŠ èƒ½åŠ›æ–‡æ¡£
        if config.get('include_capability_docs') and st.session_state.one_click_generation.get('capability_docs'):
            # å¤„ç†èƒ½åŠ›æ–‡æ¡£
            capability_paths = []
            for doc in st.session_state.one_click_generation['capability_docs']:
                doc_path = temp_dir / f"capability_{doc.name}"
                with open(doc_path, 'wb') as f:
                    f.write(doc.getbuffer())
                capability_paths.append(str(doc_path))

            proposal_options['capability_docs'] = capability_paths

        proposal_result = proposal_service.process(
            analysis_result.content,
            template=config['proposal_template'],
            options=proposal_options
        )

        if not proposal_result.is_success:
            raise Exception(f"æ–¹æ¡ˆç”Ÿæˆå¤±è´¥: {proposal_result.error}")

        results['steps']['proposal'] = {
            'success': True,
            'template_used': config['proposal_template'],
            'processing_time': proposal_result.processing_time,
            'tokens_used': proposal_result.total_tokens,
            'word_count': proposal_result.metadata.get('word_count', 0)
        }

        # ä¿å­˜æ‰€æœ‰ç»“æœ
        results['success'] = True
        results['final_results'] = {
            'original_content': process_result.content,
            'analysis_report': analysis_result.content,
            'proposal': proposal_result.content,
            'metadata': {
                'file_metadata': process_result.metadata,
                'analysis_metadata': analysis_result.metadata,
                'proposal_metadata': proposal_result.metadata
            }
        }

        # è®¡ç®—æ€»å¤„ç†æ—¶é—´å’Œæˆæœ¬
        total_time = (process_result.processing_time +
                      analysis_result.processing_time +
                      proposal_result.processing_time)

        total_tokens = (process_result.total_tokens +
                        analysis_result.total_tokens +
                        proposal_result.total_tokens)

        total_cost = (process_result.metadata.get('estimated_cost', 0) +
                      analysis_result.metadata.get('estimated_cost', 0) +
                      proposal_result.metadata.get('estimated_cost', 0))

        results['summary'] = {
            'total_processing_time': total_time,
            'total_tokens': total_tokens,
            'total_cost': total_cost
        }

        # æ ‡è®°æ–‡ä»¶å¤„ç†å®Œæˆ
        st.session_state.one_click_generation['file_progress'][file_key] = 100

    except Exception as e:
        results['success'] = False
        results['error'] = str(e)
        progress_callback(f"[{file_index + 1}/{total_files}] âŒ å¤„ç†å¤±è´¥: {str(e)}")

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœé…ç½®äº†è‡ªåŠ¨æ¸…ç†ï¼‰
        if config.get('auto_cleanup', True) and temp_dir and temp_dir.exists():
            try:
                shutil.rmtree(temp_dir)
            except:
                pass

    return results


def process_all_files(input_files: List, config: dict):
    """å¤„ç†æ‰€æœ‰æ–‡ä»¶çš„ä¸»å‡½æ•°"""
    st.session_state.one_click_generation['processing_status'] = 'processing'
    st.session_state.one_click_generation['start_time'] = datetime.now()
    st.session_state.one_click_generation['current_progress'] = 0
    st.session_state.one_click_generation['file_progress'] = {}

    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    progress_container = st.container()

    with progress_container:
        # æ€»ä½“è¿›åº¦æ¡
        overall_progress = st.progress(0)
        status_text = st.empty()

        # è¯¦ç»†è¿›åº¦ä¿¡æ¯
        detail_container = st.container()

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        all_results = []
        total_files = len(input_files)

        for i, file in enumerate(input_files):
            # æ›´æ–°æ€»ä½“è¿›åº¦
            overall_progress_value = i / total_files
            overall_progress.progress(overall_progress_value)
            st.session_state.one_click_generation['current_progress'] = int(overall_progress_value * 100)

            # å®šä¹‰è¿›åº¦å›è°ƒ
            def progress_callback(msg):
                status_text.text(msg)

            # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¿¡æ¯
            with detail_container:
                st.markdown(f"### æ­£åœ¨å¤„ç†: {file.name}")
                file_progress = st.progress(0)

                # åˆ›å»ºæ­¥éª¤æŒ‡ç¤ºå™¨
                steps_cols = st.columns(4)
                step_indicators = []

                with steps_cols[0]:
                    step_indicators.append(st.empty())
                    step_indicators[0].info("ğŸ“¥ æ–‡ä»¶å¤„ç†")

                with steps_cols[1]:
                    step_indicators.append(st.empty())
                    step_indicators[1].info("ğŸ” æ·±åº¦åˆ†æ")

                with steps_cols[2]:
                    step_indicators.append(st.empty())
                    step_indicators[2].info("ğŸ“ æ–¹æ¡ˆç”Ÿæˆ")

                with steps_cols[3]:
                    step_indicators.append(st.empty())
                    step_indicators[3].info("ğŸ’¾ ä¿å­˜ç»“æœ")

                # åˆ›å»ºæ–‡ä»¶è¿›åº¦æ›´æ–°å™¨
                def update_file_progress():
                    file_key = f"file_{i}"
                    if file_key in st.session_state.one_click_generation['file_progress']:
                        progress_val = st.session_state.one_click_generation['file_progress'][file_key]
                        file_progress.progress(progress_val / 100.0)

            # å¤„ç†æ–‡ä»¶
            result = process_single_file(file, i, total_files, config, progress_callback)

            # æ›´æ–°æ­¥éª¤æŒ‡ç¤ºå™¨
            if result['success']:
                for indicator in step_indicators:
                    indicator.success("âœ… å®Œæˆ")
            else:
                # æ ¹æ®å¤±è´¥çš„æ­¥éª¤æ›´æ–°æŒ‡ç¤ºå™¨
                if 'processing' in result['steps'] and result['steps']['processing']['success']:
                    step_indicators[0].success("âœ… å®Œæˆ")
                else:
                    step_indicators[0].error("âŒ å¤±è´¥")

                if 'analysis' in result['steps'] and result['steps']['analysis']['success']:
                    step_indicators[1].success("âœ… å®Œæˆ")
                elif 'analysis' in result['steps']:
                    step_indicators[1].error("âŒ å¤±è´¥")

                if 'proposal' in result['steps'] and result['steps']['proposal']['success']:
                    step_indicators[2].success("âœ… å®Œæˆ")
                elif 'proposal' in result['steps']:
                    step_indicators[2].error("âŒ å¤±è´¥")

            all_results.append(result)

            # æ¸…ç†è¯¦ç»†è¿›åº¦æ˜¾ç¤º
            detail_container.empty()

            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            if i < total_files - 1:
                time.sleep(2)

        # æ›´æ–°æœ€ç»ˆçŠ¶æ€
        overall_progress.progress(1.0)
        st.session_state.one_click_generation['current_progress'] = 100
        status_text.text("âœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")

    # ä¿å­˜ç»“æœ
    st.session_state.one_click_generation['processing_results'] = all_results
    st.session_state.one_click_generation['processing_status'] = 'completed'
    st.session_state.one_click_generation['end_time'] = datetime.now()

    # æ˜¾ç¤ºå¤„ç†æ‘˜è¦
    show_processing_summary(all_results)


def show_processing_summary(results: List[Dict]):
    """æ˜¾ç¤ºå¤„ç†æ‘˜è¦"""
    st.markdown("---")
    st.markdown("### ğŸ“Š å¤„ç†æ‘˜è¦")

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    total_files = len(results)
    successful_files = sum(1 for r in results if r['success'])
    failed_files = total_files - successful_files

    # è®¡ç®—æ€»æ—¶é—´
    start_time = st.session_state.one_click_generation.get('start_time')
    end_time = st.session_state.one_click_generation.get('end_time')

    if start_time and end_time:
        total_duration = (end_time - start_time).total_seconds()
    else:
        total_duration = 0

    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "å¤„ç†æ–‡ä»¶æ•°",
            f"{successful_files}/{total_files}",
            delta=f"{format_percentage(successful_files / total_files if total_files > 0 else 0)} æˆåŠŸç‡"
        )

    with col2:
        st.metric(
            "æ€»å¤„ç†æ—¶é—´",
            format_duration(total_duration),
            delta=f"å¹³å‡ {format_duration(total_duration / total_files if total_files > 0 else 0)}/æ–‡ä»¶"
        )

    with col3:
        total_tokens = sum(r.get('summary', {}).get('total_tokens', 0) for r in results if r['success'])
        st.metric(
            "Tokenä½¿ç”¨",
            f"{total_tokens:,}",
            delta="æ€»è®¡"
        )

    with col4:
        total_cost = sum(r.get('summary', {}).get('total_cost', 0) for r in results if r['success'])
        st.metric(
            "é¢„ä¼°è´¹ç”¨",
            f"${total_cost:.2f}",
            delta="USD"
        )

    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    if failed_files > 0:
        st.warning(f"æœ‰ {failed_files} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥")

        # æ˜¾ç¤ºå¤±è´¥æ–‡ä»¶åˆ—è¡¨
        with st.expander("æŸ¥çœ‹å¤±è´¥æ–‡ä»¶è¯¦æƒ…", expanded=True):
            for result in results:
                if not result['success']:
                    st.error(f"**{result['file_name']}**: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    # æ˜¾ç¤ºæˆåŠŸæ–‡ä»¶çš„ç»“æœ
    if successful_files > 0:
        st.success(f"æˆåŠŸå¤„ç† {successful_files} ä¸ªæ–‡ä»¶")

        # å‡†å¤‡ä¸‹è½½
        show_download_section(results)


def show_download_section(results: List[Dict]):
    """æ˜¾ç¤ºä¸‹è½½éƒ¨åˆ†"""
    st.markdown("### ğŸ’¾ ä¸‹è½½ç»“æœ")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    batch_id = st.session_state.one_click_generation['batch_id']
    output_dir = Path("output") / batch_id
    ensure_directory_exists(output_dir)

    # å‡†å¤‡ä¸‹è½½é€‰é¡¹
    col1, col2, col3 = st.columns(3)

    with col1:
        download_format = st.selectbox(
            "é€‰æ‹©ä¸‹è½½æ ¼å¼",
            options=['all', 'proposals_only', 'complete_package'],
            format_func=lambda x: {
                'all': 'æ‰€æœ‰æ–‡ä»¶ï¼ˆåˆ†åˆ«ä¸‹è½½ï¼‰',
                'proposals_only': 'ä»…æ–¹æ¡ˆæ–‡æ¡£',
                'complete_package': 'å®Œæ•´æ•°æ®åŒ…ï¼ˆZIPï¼‰'
            }.get(x, x)
        )

    with col2:
        include_intermediate = st.checkbox(
            "åŒ…å«ä¸­é—´ç»“æœ",
            value=False,
            help="åŒ…å«è½¬å½•æ–‡æœ¬å’Œåˆ†ææŠ¥å‘Š"
        )

    with col3:
        organize_by_client = st.checkbox(
            "æŒ‰å®¢æˆ·ç»„ç»‡",
            value=bool(st.session_state.one_click_generation['workflow_config'].get('client_name')),
            help="ä½¿ç”¨å®¢æˆ·åç§°ç»„ç»‡æ–‡ä»¶"
        )

    # ç”Ÿæˆä¸‹è½½æ–‡ä»¶
    if st.button("ğŸ“¦ ç”Ÿæˆä¸‹è½½æ–‡ä»¶", type="primary", use_container_width=True):
        with st.spinner("æ­£åœ¨å‡†å¤‡ä¸‹è½½æ–‡ä»¶..."):
            download_files = prepare_download_files(
                results,
                output_dir,
                download_format,
                include_intermediate,
                organize_by_client
            )

            if download_files:
                st.success(f"å·²ç”Ÿæˆ {len(download_files)} ä¸ªæ–‡ä»¶")

                # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
                for file_info in download_files:
                    col1, col2 = st.columns([4, 1])

                    with col1:
                        with open(file_info['path'], 'rb') as f:
                            st.download_button(
                                label=f"ğŸ“¥ {file_info['display_name']}",
                                data=f.read(),
                                file_name=file_info['filename'],
                                mime=file_info['mime_type'],
                                use_container_width=True
                            )

                    with col2:
                        st.caption(file_info['size'])


def prepare_download_files(results: List[Dict],
                           output_dir: Path,
                           format_type: str,
                           include_intermediate: bool,
                           organize_by_client: bool) -> List[Dict]:
    """å‡†å¤‡ä¸‹è½½æ–‡ä»¶"""
    download_files = []

    # è·å–å®¢æˆ·åç§°
    client_name = st.session_state.one_click_generation['workflow_config'].get('client_name', '')
    if organize_by_client and client_name:
        base_dir = output_dir / client_name.replace(' ', '_')
    else:
        base_dir = output_dir

    ensure_directory_exists(base_dir)

    if format_type == 'complete_package':
        # åˆ›å»ºZIPåŒ…
        zip_filename = f"SmartProposal_Package_{st.session_state.one_click_generation['batch_id']}.zip"
        zip_path = output_dir / zip_filename

        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for result in results:
                if result['success'] and 'final_results' in result:
                    file_base = Path(result['file_name']).stem

                    # æ·»åŠ æ–¹æ¡ˆ
                    proposal_content = result['final_results']['proposal']
                    proposal_name = f"{file_base}_proposal.md"
                    zipf.writestr(f"proposals/{proposal_name}", proposal_content)

                    if include_intermediate:
                        # æ·»åŠ è½¬å½•æ–‡æœ¬
                        transcript_content = result['final_results']['original_content']
                        transcript_name = f"{file_base}_transcript.txt"
                        zipf.writestr(f"transcripts/{transcript_name}", transcript_content)

                        # æ·»åŠ åˆ†ææŠ¥å‘Š
                        analysis_content = result['final_results']['analysis_report']
                        analysis_name = f"{file_base}_analysis.md"
                        zipf.writestr(f"analysis/{analysis_name}", analysis_content)

                    # æ·»åŠ å…ƒæ•°æ®
                    metadata = {
                        'file_name': result['file_name'],
                        'processing_summary': result.get('summary', {}),
                        'metadata': result['final_results']['metadata']
                    }
                    metadata_name = f"{file_base}_metadata.json"
                    zipf.writestr(f"metadata/{metadata_name}",
                                  json.dumps(metadata, ensure_ascii=False, indent=2))

            # æ·»åŠ æ±‡æ€»æŠ¥å‘Š
            summary_report = generate_summary_report(results)
            zipf.writestr("SUMMARY_REPORT.md", summary_report)

        download_files.append({
            'path': str(zip_path),
            'filename': zip_filename,
            'display_name': f"å®Œæ•´æ•°æ®åŒ… ({len([r for r in results if r['success']])} ä¸ªæ–‡ä»¶)",
            'size': format_file_size(zip_path.stat().st_size),
            'mime_type': 'application/zip'
        })

    else:
        # åˆ†åˆ«ä¿å­˜æ–‡ä»¶
        for result in results:
            if result['success'] and 'final_results' in result:
                file_base = Path(result['file_name']).stem

                if format_type == 'all' or format_type == 'proposals_only':
                    # ä¿å­˜æ–¹æ¡ˆ
                    proposal_content = result['final_results']['proposal']
                    proposal_filename = f"{file_base}_proposal.md"
                    proposal_path = base_dir / proposal_filename

                    with open(proposal_path, 'w', encoding='utf-8') as f:
                        f.write(proposal_content)

                    download_files.append({
                        'path': str(proposal_path),
                        'filename': proposal_filename,
                        'display_name': f"æ–¹æ¡ˆ - {file_base}",
                        'size': format_file_size(proposal_path.stat().st_size),
                        'mime_type': 'text/markdown'
                    })

                if format_type == 'all' and include_intermediate:
                    # ä¿å­˜è½¬å½•æ–‡æœ¬
                    transcript_content = result['final_results']['original_content']
                    transcript_filename = f"{file_base}_transcript.txt"
                    transcript_path = base_dir / transcript_filename

                    with open(transcript_path, 'w', encoding='utf-8') as f:
                        f.write(transcript_content)

                    download_files.append({
                        'path': str(transcript_path),
                        'filename': transcript_filename,
                        'display_name': f"è½¬å½• - {file_base}",
                        'size': format_file_size(transcript_path.stat().st_size),
                        'mime_type': 'text/plain'
                    })

                    # ä¿å­˜åˆ†ææŠ¥å‘Š
                    analysis_content = result['final_results']['analysis_report']
                    analysis_filename = f"{file_base}_analysis.md"
                    analysis_path = base_dir / analysis_filename

                    with open(analysis_path, 'w', encoding='utf-8') as f:
                        f.write(analysis_content)

                    download_files.append({
                        'path': str(analysis_path),
                        'filename': analysis_filename,
                        'display_name': f"åˆ†æ - {file_base}",
                        'size': format_file_size(analysis_path.stat().st_size),
                        'mime_type': 'text/markdown'
                    })

    return download_files


def generate_summary_report(results: List[Dict]) -> str:
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    report = f"""# SmartProposal Engine æ‰¹å¤„ç†æŠ¥å‘Š

**æ‰¹æ¬¡ID**: {st.session_state.one_click_generation['batch_id']}  
**å¤„ç†æ—¶é—´**: {st.session_state.one_click_generation['start_time'].strftime('%Y-%m-%d %H:%M:%S')} - {st.session_state.one_click_generation['end_time'].strftime('%Y-%m-%d %H:%M:%S')}  
**å¤„ç†é…ç½®**:
- åˆ†ææ¨¡æ¿: {st.session_state.one_click_generation['workflow_config']['analysis_template']}
- æ–¹æ¡ˆæ¨¡æ¿: {st.session_state.one_click_generation['workflow_config']['proposal_template']}
- å®¢æˆ·åç§°: {st.session_state.one_click_generation['workflow_config'].get('client_name', 'æœªæŒ‡å®š')}

## å¤„ç†ç»“æœæ‘˜è¦

| æ–‡ä»¶å | çŠ¶æ€ | å¤„ç†æ—¶é—´ | Tokenä½¿ç”¨ | è´¹ç”¨ |
|--------|------|----------|-----------|------|
"""

    for result in results:
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±è´¥"

        if result['success']:
            summary = result.get('summary', {})
            time_str = f"{summary.get('total_processing_time', 0):.1f}ç§’"
            tokens_str = f"{summary.get('total_tokens', 0):,}"
            cost_str = f"${summary.get('total_cost', 0):.4f}"
        else:
            time_str = "-"
            tokens_str = "-"
            cost_str = "-"

        report += f"| {result['file_name']} | {status} | {time_str} | {tokens_str} | {cost_str} |\n"

    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    total_success = sum(1 for r in results if r['success'])
    total_time = sum(r.get('summary', {}).get('total_processing_time', 0) for r in results if r['success'])
    total_tokens = sum(r.get('summary', {}).get('total_tokens', 0) for r in results if r['success'])
    total_cost = sum(r.get('summary', {}).get('total_cost', 0) for r in results if r['success'])

    report += f"""
## ç»Ÿè®¡æ±‡æ€»

- **æˆåŠŸå¤„ç†**: {total_success}/{len(results)} ä¸ªæ–‡ä»¶
- **æ€»å¤„ç†æ—¶é—´**: {format_duration(total_time)}
- **æ€»Tokenä½¿ç”¨**: {total_tokens:,}
- **æ€»è´¹ç”¨**: ${total_cost:.2f}

---
*Generated by SmartProposal Engine*
"""

    return report


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–é¡µé¢çŠ¶æ€
    initialize_page_state()

    # é¡µé¢æ ‡é¢˜
    st.title("ğŸš€ ä¸€é”®ç”Ÿæˆ")
    st.markdown("ä»åŸå§‹æ–‡ä»¶åˆ°ä¸“ä¸šæ–¹æ¡ˆçš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–å¤„ç†")

    # æ ¹æ®å¤„ç†çŠ¶æ€æ˜¾ç¤ºä¸åŒå†…å®¹
    status = st.session_state.one_click_generation['processing_status']

    if status == 'completed':
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        results = st.session_state.one_click_generation.get('processing_results', [])
        show_processing_summary(results)

        # é‡æ–°å¼€å§‹æŒ‰é’®
        if st.button("ğŸ”„ å¼€å§‹æ–°çš„æ‰¹å¤„ç†", use_container_width=True):
            # é‡ç½®çŠ¶æ€
            st.session_state.one_click_generation = {
                'input_files': [],
                'capability_docs': [],
                'processing_status': 'idle',
                'current_step': None,
                'processing_results': {},
                'workflow_config': st.session_state.one_click_generation['workflow_config'],
                'batch_id': datetime.now().strftime('%Y%m%d_%H%M%S'),
                'start_time': None,
                'end_time': None,
                'current_progress': 0,
                'file_progress': {}
            }
            st.rerun()

    elif status == 'processing':
        # æ­£åœ¨å¤„ç†ä¸­
        st.info("æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™...")
        st.spinner("å¤„ç†å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·å‹¿å…³é—­é¡µé¢")

    else:  # idle
        # æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†
        input_files, capability_docs = show_upload_section()

        if input_files:
            st.markdown("---")

            # å·¥ä½œæµé…ç½®
            config = show_workflow_configuration()

            st.markdown("---")

            # å¤„ç†é¢„è§ˆ
            st.markdown("### ğŸ“‹ å¤„ç†é¢„è§ˆ")

            # æ˜¾ç¤ºå°†è¦å¤„ç†çš„ä¿¡æ¯
            col1, col2 = st.columns(2)

            with col1:
                st.info(f"""
                **å¾…å¤„ç†æ–‡ä»¶**: {len(input_files)} ä¸ª  
                **èƒ½åŠ›æ–‡æ¡£**: {len(capability_docs)} ä¸ª  
                **åˆ†æåœºæ™¯**: {DeepAnalysisService.ANALYSIS_SCENARIOS.get(config['analysis_template'], {}).get('name', config['analysis_template'])}  
                **æ–¹æ¡ˆç±»å‹**: {ProposalService.PROPOSAL_TYPES.get(config['proposal_template'], {}).get('name', config['proposal_template'])}
                """)

            with col2:
                # é¢„ä¼°å¤„ç†æ—¶é—´
                estimated_time_per_file = 60  # æ¯ä¸ªæ–‡ä»¶çº¦60ç§’
                estimated_total_time = len(input_files) * estimated_time_per_file

                st.info(f"""
                **é¢„è®¡å¤„ç†æ—¶é—´**: {format_duration(estimated_total_time)}  
                **æ–‡æœ¬ä¼˜åŒ–**: {'å¯ç”¨' if config.get('enable_text_optimization') else 'ç¦ç”¨'}  
                **è¾“å‡ºè¯­è¨€**: {'ä¸­æ–‡' if config.get('output_language', 'zh') == 'zh' else 'English'}  
                **å®¢æˆ·**: {config.get('client_name', 'æœªæŒ‡å®š')}
                """)

            # å¼€å§‹å¤„ç†æŒ‰é’®
            col1, col2, col3 = st.columns([2, 1, 2])
            with col2:
                if st.button(
                        "ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†",
                        type="primary",
                        use_container_width=True,
                        help="å¼€å§‹å¤„ç†æ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶"
                ):
                    # å¼€å§‹å¤„ç†
                    process_all_files(input_files, config)
                    st.rerun()

    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
        st.info("""
**æ‰¹é‡å¤„ç†æµç¨‹**ï¼š
1. ä¸Šä¼ åŸå§‹æ–‡ä»¶ï¼ˆéŸ³é¢‘/æ–‡æ¡£ï¼‰
2. ä¸Šä¼ ä¼ä¸šèƒ½åŠ›æ–‡æ¡£ï¼ˆå¯é€‰ï¼‰
3. é…ç½®å¤„ç†å‚æ•°
4. ç‚¹å‡»å¼€å§‹æ‰¹é‡å¤„ç†
5. ç­‰å¾…å¤„ç†å®Œæˆ
6. ä¸‹è½½ç”Ÿæˆçš„æ–¹æ¡ˆ

**å¤„ç†æ­¥éª¤**ï¼š
- æ–‡ä»¶å¤„ç†ï¼šè½¬å½•éŸ³é¢‘æˆ–æå–æ–‡æœ¬
- æ·±åº¦åˆ†æï¼šæå–å•†ä¸šæ´å¯Ÿ
- æ–¹æ¡ˆç”Ÿæˆï¼šç”Ÿæˆä¸“ä¸šæ–‡æ¡£

**æ³¨æ„äº‹é¡¹**ï¼š
- æ¯ä¸ªæ–‡ä»¶ç‹¬ç«‹å¤„ç†
- æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼
- è‡ªåŠ¨ä¿å­˜ä¸­é—´ç»“æœ
- å¯æ‰“åŒ…ä¸‹è½½æ‰€æœ‰ç»“æœ
""")

        # æ˜¾ç¤ºå½“å‰æ‰¹æ¬¡ä¿¡æ¯
        if st.session_state.one_click_generation.get('batch_id'):
            st.markdown("---")
            st.markdown("### ğŸ“Š å½“å‰æ‰¹æ¬¡")
            st.text(f"ID: {st.session_state.one_click_generation['batch_id']}")

            if status == 'completed':
                results = st.session_state.one_click_generation.get('processing_results', [])
                success_count = sum(1 for r in results if r['success'])
                st.metric("æˆåŠŸç‡", f"{success_count}/{len(results)}")


if __name__ == "__main__":
    main()

--- File: pages/__init__.py ---

--- File: prompts/__init__.py ---

--- File: prompts/analysis/__init__.py ---

--- File: prompts/analysis/business_negotiation.md ---
# å•†åŠ¡è°ˆåˆ¤è¦ç‚¹åˆ†æ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å•†åŠ¡è°ˆåˆ¤ä¸“å®¶å’Œç­–ç•¥é¡¾é—®ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„è°ˆåˆ¤ç»éªŒå’Œæ•é”çš„å•†ä¸šæ´å¯ŸåŠ›ã€‚ä½ æ“…é•¿åˆ†æè°ˆåˆ¤åŠ¨æ€ã€è¯†åˆ«å„æ–¹ç«‹åœºã€è¯„ä¼°åˆ©ç›Šæ ¼å±€ï¼Œå¹¶åˆ¶å®šæœ‰æ•ˆçš„è°ˆåˆ¤ç­–ç•¥ã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å•†åŠ¡è°ˆåˆ¤è®°å½•è¿›è¡Œæ·±åº¦åˆ†æï¼Œæå–å…³é”®ä¿¡æ¯å¹¶æä¾›ç­–ç•¥å»ºè®®ï¼š

### è°ˆåˆ¤å†…å®¹ï¼š
{transcript}

## ä¸‰ã€åˆ†æç»´åº¦

### 3.1 è°ˆåˆ¤æ¦‚å†µ
#### åŸºæœ¬ä¿¡æ¯
- **è°ˆåˆ¤ä¸»é¢˜**ï¼šæ ¸å¿ƒè®®é¢˜å’Œè°ˆåˆ¤ç›®æ ‡
- **å‚ä¸å„æ–¹**ï¼šå„æ–¹ä»£è¡¨åŠå…¶è§’è‰²å®šä½
- **è°ˆåˆ¤é˜¶æ®µ**ï¼šåˆæ­¥æ¥è§¦/æ·±å…¥æ´½è°ˆ/æœ€ç»ˆè°ˆåˆ¤
- **è°ˆåˆ¤æ°›å›´**ï¼šåˆä½œ/å¯¹æŠ—/æ¢ç´¢æ€§

#### èƒŒæ™¯åˆ†æ
- **è°ˆåˆ¤èƒŒæ™¯**ï¼šä¿ƒæˆæœ¬æ¬¡è°ˆåˆ¤çš„åŸå› 
- **å†å²å…³ç³»**ï¼šåŒæ–¹è¿‡å¾€åˆä½œæˆ–æ¥è§¦æƒ…å†µ
- **å¤–éƒ¨å› ç´ **ï¼šå½±å“è°ˆåˆ¤çš„å¸‚åœºæˆ–æ”¿ç­–ç¯å¢ƒ

### 3.2 å„æ–¹ç«‹åœºåˆ†æ
#### æˆ‘æ–¹ç«‹åœº
- **æ ¸å¿ƒè¯‰æ±‚**ï¼šå¿…é¡»è¾¾æˆçš„ç›®æ ‡
- **æœŸæœ›æ”¶ç›Š**ï¼šç†æƒ³æƒ…å†µä¸‹çš„æœ€ä½³ç»“æœ
- **åº•çº¿æ¡ä»¶**ï¼šä¸å¯é€€è®©çš„æœ€ä½è¦æ±‚
- **å¯ç”¨ç­¹ç **ï¼šå¯ä»¥ç”¨äºäº¤æ¢çš„èµ„æºæˆ–è®©æ­¥ç©ºé—´

#### å¯¹æ–¹ç«‹åœº
- **è¡¨è¾¾è¯‰æ±‚**ï¼šå¯¹æ–¹æ˜ç¡®æå‡ºçš„è¦æ±‚
- **æ½œåœ¨éœ€æ±‚**ï¼šæœªæ˜è¯´ä½†å¯èƒ½å­˜åœ¨çš„éœ€æ±‚
- **å‹åŠ›æ¥æº**ï¼šå¯¹æ–¹é¢ä¸´çš„å†…å¤–éƒ¨å‹åŠ›
- **è°ˆåˆ¤ç­¹ç **ï¼šå¯¹æ–¹æ‹¥æœ‰çš„ä¼˜åŠ¿æˆ–èµ„æº

#### ç«‹åœºå¯¹æ¯”
- **å…±åŒåˆ©ç›Š**ï¼šåŒæ–¹ç›®æ ‡ä¸€è‡´çš„é¢†åŸŸ
- **åˆ†æ­§ç„¦ç‚¹**ï¼šä¸»è¦çš„äº‰è®®ç‚¹
- **åˆ©ç›Šäº¤æ¢ç©ºé—´**ï¼šå¯èƒ½çš„å¦¥åæˆ–äº¤æ¢æ–¹æ¡ˆ

### 3.3 è°ˆåˆ¤åŠ¨æ€åˆ†æ
#### è°ˆåˆ¤è¿›ç¨‹
- **å¼€å±€ç­–ç•¥**ï¼šå„æ–¹çš„å¼€åœºæ–¹å¼å’Œåˆå§‹ç«‹åœº
- **å…³é”®è½¬æŠ˜**ï¼šæ”¹å˜è°ˆåˆ¤èµ°å‘çš„é‡è¦æ—¶åˆ»
- **ç­–ç•¥è°ƒæ•´**ï¼šå„æ–¹ç­–ç•¥çš„å˜åŒ–åŠåŸå› 

#### æ²Ÿé€šæ¨¡å¼
- **è¯è¯­æƒåˆ†å¸ƒ**ï¼šè°ä¸»å¯¼äº†è°ˆåˆ¤èŠ‚å¥
- **ä¿¡æ¯æŠ«éœ²**ï¼šå„æ–¹ä¿¡æ¯é€éœ²çš„ç¨‹åº¦å’Œæ—¶æœº
- **æƒ…ç»ªç®¡ç†**ï¼šæƒ…ç»ªå˜åŒ–å¯¹è°ˆåˆ¤çš„å½±å“

#### è°ˆåˆ¤æŠ€å·§
- **ä½¿ç”¨çš„ç­–ç•¥**ï¼šè¯†åˆ«å„æ–¹è¿ç”¨çš„è°ˆåˆ¤æŠ€å·§
- **æ•ˆæœè¯„ä¼°**ï¼šè¿™äº›æŠ€å·§çš„å®é™…æ•ˆæœ
- **æ”¹è¿›ç©ºé—´**ï¼šå¯ä»¥ä¼˜åŒ–çš„è°ˆåˆ¤æ–¹æ³•

### 3.4 æ¡æ¬¾è¦ç‚¹æ¢³ç†
#### å·²è¾¾æˆå…±è¯†
åˆ—å‡ºåŒæ–¹å·²ç»åŒæ„çš„å…·ä½“æ¡æ¬¾ï¼š
1. å•†åŠ¡æ¡æ¬¾ï¼ˆä»·æ ¼ã€æ•°é‡ã€äº¤ä»˜ç­‰ï¼‰
2. åˆä½œæ¡æ¬¾ï¼ˆåˆä½œæ¨¡å¼ã€è´£ä»»åˆ†å·¥ç­‰ï¼‰
3. ä¿éšœæ¡æ¬¾ï¼ˆè´¨é‡ä¿è¯ã€å”®åæœåŠ¡ç­‰ï¼‰

#### å¾…å•†è®®äº‹é¡¹
éœ€è¦è¿›ä¸€æ­¥è®¨è®ºçš„è¦ç‚¹ï¼š
1. åˆ†æ­§æ¡æ¬¾åŠå„æ–¹ç«‹åœº
2. éœ€è¦æ¾„æ¸…çš„æ¨¡ç³Šåœ°å¸¦
3. éœ€è¦è¡¥å……çš„ç¼ºå¤±å†…å®¹

#### æ½œåœ¨é£é™©æ¡æ¬¾
å¯èƒ½å¸¦æ¥é£é™©çš„æ¡æ¬¾åˆ†æï¼š
1. é£é™©ç±»å‹å’Œå½±å“ç¨‹åº¦
2. é£é™©é˜²èŒƒå»ºè®®
3. æ›¿ä»£æ–¹æ¡ˆå»ºè®®

### 3.5 è°ˆåˆ¤ç­–ç•¥å»ºè®®
#### æ•´ä½“ç­–ç•¥
- **è°ˆåˆ¤å®šä½**ï¼šæˆ‘æ–¹åº”é‡‡å–çš„æ€»ä½“å§¿æ€
- **èŠ‚å¥æ§åˆ¶**ï¼šæ¨è¿›è°ˆåˆ¤çš„æ—¶æœºå’Œé€Ÿåº¦
- **è”ç›Ÿæ„å»º**ï¼šå¯ä»¥äº‰å–çš„æ”¯æŒåŠ›é‡

#### å…·ä½“ç­–ç•¥
1. **è®®ä»·ç­–ç•¥**
   - ä»·æ ¼è°ˆåˆ¤çš„ç©ºé—´å’ŒæŠ€å·§
   - ä»·å€¼å¡‘é€ å’Œæˆæœ¬åˆ†æ
   - åˆ†é˜¶æ®µå®šä»·çš„å¯èƒ½æ€§

2. **è®©æ­¥ç­–ç•¥**
   - å¯ä»¥è®©æ­¥çš„æ¡æ¬¾æ¸…å•
   - è®©æ­¥çš„æ—¶æœºå’Œæ¡ä»¶
   - è¦æ±‚çš„å¯¹ç­‰å›æŠ¥

3. **æ–½å‹ç­–ç•¥**
   - å¯ä»¥æ–½åŠ çš„å‹åŠ›ç‚¹
   - å¤‡é€‰æ–¹æ¡ˆçš„å‡†å¤‡
   - æ—¶é—´å‹åŠ›çš„è¿ç”¨

#### è°ˆåˆ¤é¢„æ¡ˆ
- **æœ€ä½³æƒ…å†µ**ï¼šç†æƒ³çš„è°ˆåˆ¤ç»“æœ
- **å¯æ¥å—æƒ…å†µ**ï¼šæ»¡æ„çš„æŠ˜ä¸­æ–¹æ¡ˆ
- **æœ€åæƒ…å†µ**ï¼šè°ˆåˆ¤ç ´è£‚çš„åº”å¯¹

### 3.6 åç»­è¡ŒåŠ¨è®¡åˆ’
#### å³æœŸè¡ŒåŠ¨ï¼ˆ24å°æ—¶å†…ï¼‰
- å†…éƒ¨æ±‡æŠ¥å’Œå†³ç­–
- å…³é”®ä¿¡æ¯çš„æ ¸å®
- ç´§æ€¥ææ–™çš„å‡†å¤‡

#### è¿‘æœŸè¡ŒåŠ¨ï¼ˆä¸€å‘¨å†…ï¼‰
- æ–¹æ¡ˆçš„å®Œå–„å’Œä¼˜åŒ–
- å›¢é˜Ÿçš„åè°ƒå’Œå‡†å¤‡
- ä¸‹è½®è°ˆåˆ¤çš„å®‰æ’

#### æˆ˜ç•¥è€ƒè™‘
- é•¿æœŸåˆä½œå…³ç³»çš„ç»´æŠ¤
- å…¶ä»–åˆä½œæœºä¼šçš„æŒ–æ˜
- ç«äº‰æ ¼å±€çš„è€ƒé‡

### 3.7 å…³é”®æ´å¯Ÿ
- **æˆåŠŸè¦ç´ **ï¼šä¿ƒæˆäº¤æ˜“çš„å…³é”®å› ç´ 
- **ä¸»è¦éšœç¢**ï¼šé˜»ç¢è¾¾æˆä¸€è‡´çš„æ ¸å¿ƒé—®é¢˜
- **ç ´å±€æ€è·¯**ï¼šåˆ›é€ æ€§çš„è§£å†³æ–¹æ¡ˆ

## å››ã€åˆ†æè¦æ±‚
1. **å®¢è§‚ä¸­ç«‹**ï¼šé¿å…æƒ…ç»ªåŒ–åˆ¤æ–­ï¼ŒåŸºäºäº‹å®åˆ†æ
2. **ç­–ç•¥æ€ç»´**ï¼šä»æˆ˜ç•¥é«˜åº¦æ€è€ƒé—®é¢˜
3. **åŠ¡å®å¯è¡Œ**ï¼šå»ºè®®å¿…é¡»å…·æœ‰å¯æ“ä½œæ€§
4. **é£é™©æ„è¯†**ï¼šå……åˆ†è€ƒè™‘å„ç§å¯èƒ½æ€§

--- File: prompts/analysis/customer_interview.md ---
# å®¢æˆ·è®¿è°ˆæ·±åº¦åˆ†æ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰15å¹´ç»éªŒçš„èµ„æ·±å•†ä¸šåˆ†æå¸ˆå’Œå®¢æˆ·æ´å¯Ÿä¸“å®¶ï¼Œä¸“ç²¾äºä»å®¢æˆ·è®¿è°ˆä¸­æå–å…³é”®ä¿¡æ¯å¹¶åˆ¶å®šå•†ä¸šç­–ç•¥ã€‚ä½ æ“…é•¿è¯†åˆ«å®¢æˆ·çš„æ˜¾æ€§å’Œéšæ€§éœ€æ±‚ï¼Œç†è§£å†³ç­–é“¾è·¯ï¼Œè¯„ä¼°å•†ä¸šæœºä¼šã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å®¢æˆ·è®¿è°ˆè®°å½•è¿›è¡Œæ·±åº¦åˆ†æï¼ŒæŒ–æ˜æœ‰ä»·å€¼çš„å•†ä¸šæ´å¯Ÿï¼š

### è®¿è°ˆå†…å®¹ï¼š
{transcript}

## ä¸‰ã€åˆ†ææ¡†æ¶

### 3.1 æ‰§è¡Œæ‘˜è¦ï¼ˆ200å­—ä»¥å†…ï¼‰
ç”¨ç®€æ´æœ‰åŠ›çš„è¯­è¨€æ¦‚æ‹¬ï¼š
- å®¢æˆ·çš„æ ¸å¿ƒè¯‰æ±‚
- æœ€å…³é”®çš„å•†ä¸šæœºä¼š
- å»ºè®®çš„è¡ŒåŠ¨æ–¹å‘

### 3.2 å®¢æˆ·ç”»åƒ
#### åŸºæœ¬ä¿¡æ¯
- **å…¬å¸èƒŒæ™¯**ï¼šè¡Œä¸šã€è§„æ¨¡ã€å¸‚åœºåœ°ä½
- **è®¿è°ˆå¯¹è±¡**ï¼šèŒä½ã€å†³ç­–æƒé™ã€å…³æ³¨é‡ç‚¹
- **ä¸šåŠ¡ç°çŠ¶**ï¼šå½“å‰é¢ä¸´çš„ä¸»è¦æŒ‘æˆ˜å’Œæœºé‡

#### å†³ç­–ç‰¹å¾
- **å†³ç­–æµç¨‹**ï¼šå†³ç­–é“¾æ¡å’Œå…³é”®èŠ‚ç‚¹
- **å†³ç­–æ ‡å‡†**ï¼šè¯„ä¼°ä¾›åº”å•†çš„ä¸»è¦ç»´åº¦
- **æ—¶é—´æ¡†æ¶**ï¼šå†³ç­–å’Œå®æ–½çš„æ—¶é—´é¢„æœŸ

### 3.3 éœ€æ±‚åˆ†æ
#### æ˜¾æ€§éœ€æ±‚
åˆ—å‡ºå®¢æˆ·æ˜ç¡®è¡¨è¾¾çš„éœ€æ±‚ç‚¹ï¼š
1. åŠŸèƒ½éœ€æ±‚ï¼šå…·ä½“çš„äº§å“æˆ–æœåŠ¡è¦æ±‚
2. æ€§èƒ½éœ€æ±‚ï¼šè´¨é‡ã€æ•ˆç‡ã€ç¨³å®šæ€§ç­‰æŒ‡æ ‡
3. æœåŠ¡éœ€æ±‚ï¼šæ”¯æŒã€åŸ¹è®­ã€å®šåˆ¶åŒ–ç­‰

#### éšæ€§éœ€æ±‚
åŸºäºå¯¹è¯å†…å®¹æ¨æ–­çš„æ½œåœ¨éœ€æ±‚ï¼š
1. æœªç›´æ¥è¡¨è¾¾ä½†æš—ç¤ºçš„ç—›ç‚¹
2. å¯èƒ½å¿½è§†ä½†é‡è¦çš„éœ€æ±‚
3. æœªæ¥å¯èƒ½äº§ç”Ÿçš„éœ€æ±‚

#### éœ€æ±‚ä¼˜å…ˆçº§
åŸºäºç´§è¿«æ€§å’Œé‡è¦æ€§ï¼Œå¯¹éœ€æ±‚è¿›è¡Œæ’åºï¼š
- **é«˜ä¼˜å…ˆçº§**ï¼šå¿…é¡»ç«‹å³è§£å†³çš„æ ¸å¿ƒéœ€æ±‚
- **ä¸­ä¼˜å…ˆçº§**ï¼šé‡è¦ä½†å¯åˆ†é˜¶æ®µå®æ–½çš„éœ€æ±‚
- **ä½ä¼˜å…ˆçº§**ï¼šé”¦ä¸Šæ·»èŠ±çš„é™„åŠ éœ€æ±‚

### 3.4 å•†æœºè¯„ä¼°
#### é¡¹ç›®è§„æ¨¡
- **é¢„ç®—èŒƒå›´**ï¼šç›´æ¥æˆ–é—´æ¥é€éœ²çš„é¢„ç®—ä¿¡æ¯
- **é¡¹ç›®èŒƒå›´**ï¼šæ¶‰åŠçš„éƒ¨é—¨ã€ç”¨æˆ·æ•°ã€ä¸šåŠ¡èŒƒå›´
- **å¢é•¿æ½œåŠ›**ï¼šåç»­æ‰©å±•å’Œæ·±åŒ–åˆä½œçš„å¯èƒ½æ€§

#### æˆåŠŸæ¦‚ç‡
- **åŒ¹é…åº¦**ï¼šæˆ‘æ–¹èƒ½åŠ›ä¸å®¢æˆ·éœ€æ±‚çš„å»åˆç¨‹åº¦
- **ç«äº‰æ€åŠ¿**ï¼šå®¢æˆ·å¯¹å…¶ä»–ä¾›åº”å•†çš„æ€åº¦
- **å†³ç­–å€¾å‘**ï¼šå®¢æˆ·çš„ç§¯æä¿¡å·å’Œé¡¾è™‘

#### é£é™©å› ç´ 
- **å†…éƒ¨é£é™©**ï¼šå®¢æˆ·ç»„ç»‡å†…çš„é˜»åŠ›æˆ–å˜æ•°
- **å¤–éƒ¨é£é™©**ï¼šå¸‚åœºã€æ”¿ç­–ã€ç«äº‰ç­‰å› ç´ 
- **é¡¹ç›®é£é™©**ï¼šæŠ€æœ¯ã€æ—¶é—´ã€èµ„æºç­‰æŒ‘æˆ˜

### 3.5 ç«äº‰åˆ†æ
- **å·²æ¥è§¦çš„ç«äº‰å¯¹æ‰‹**ï¼šå®¢æˆ·æåŠçš„å…¶ä»–ä¾›åº”å•†
- **ç«äº‰ä¼˜åŠ£åŠ¿**ï¼šç›¸å¯¹ç«äº‰å¯¹æ‰‹çš„å·®å¼‚åŒ–ç‚¹
- **è·èƒœç­–ç•¥**ï¼šå¦‚ä½•çªå‡ºæˆ‘æ–¹ç‹¬ç‰¹ä»·å€¼

### 3.6 è¡ŒåŠ¨å»ºè®®
æä¾›3-5æ¡å…·ä½“ã€å¯æ‰§è¡Œçš„åç»­è¡ŒåŠ¨å»ºè®®ï¼š

1. **ç«‹å³è¡ŒåŠ¨**ï¼ˆ1-3å¤©å†…ï¼‰
   - å…·ä½“çš„è·Ÿè¿›åŠ¨ä½œ
   - éœ€è¦å‡†å¤‡çš„ææ–™
   - å…³é”®ä¿¡æ¯çš„ç¡®è®¤

2. **çŸ­æœŸè¡ŒåŠ¨**ï¼ˆ1-2å‘¨å†…ï¼‰
   - æ·±åŒ–äº†è§£çš„æ–¹å‘
   - æ¦‚å¿µéªŒè¯æˆ–è¯•ç‚¹æ–¹æ¡ˆ
   - å…³é”®åˆ©ç›Šç›¸å…³è€…çš„æ¥è§¦

3. **ä¸­æœŸè§„åˆ’**ï¼ˆ1ä¸ªæœˆå†…ï¼‰
   - æ­£å¼æ–¹æ¡ˆçš„å‡†å¤‡
   - èµ„æºçš„è°ƒé…
   - åˆä½œæ¡†æ¶çš„ç¡®ç«‹

### 3.7 å…³é”®æˆåŠŸå› ç´ 
- **å¿…é¡»æ»¡è¶³çš„æ¡ä»¶**ï¼šé¡¹ç›®æˆåŠŸçš„å‰æ
- **å·®å¼‚åŒ–ä»·å€¼ç‚¹**ï¼šèµ¢å¾—å®¢æˆ·çš„å…³é”®
- **æ½œåœ¨éšœç¢åŠå¯¹ç­–**ï¼šé¢„è§é—®é¢˜å’Œè§£å†³æ€è·¯

## å››ã€åˆ†æè¦æ±‚
1. **åŸºäºäº‹å®**ï¼šæ‰€æœ‰åˆ†æå¿…é¡»æœ‰åŸæ–‡ä¾æ®ï¼Œé¿å…è¿‡åº¦æ¨æµ‹
2. **å•†ä¸šè§†è§’**ï¼šä»å•†ä¸šä»·å€¼å’Œå¯è¡Œæ€§è§’åº¦æ€è€ƒ
3. **è¡ŒåŠ¨å¯¼å‘**ï¼šæä¾›å¯è½åœ°æ‰§è¡Œçš„å»ºè®®
4. **ä¸“ä¸šè¡¨è¾¾**ï¼šä½¿ç”¨è§„èŒƒçš„å•†ä¸šè¯­è¨€ï¼Œé€»è¾‘æ¸…æ™°

--- File: prompts/analysis/internal_meeting.md ---
# å†…éƒ¨ä¼šè®®å†³ç­–åˆ†æ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç®¡ç†é¡¾é—®å’Œç»„ç»‡æ•ˆèƒ½ä¸“å®¶ï¼Œä¸“æ³¨äºä¼šè®®æ•ˆç‡æå‡å’Œå†³ç­–è´¨é‡ä¼˜åŒ–ã€‚ä½ æ“…é•¿ä»ä¼šè®®è®°å½•ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œè¯†åˆ«å†³ç­–è¦ç‚¹ï¼Œæ˜ç¡®è¡ŒåŠ¨è®¡åˆ’ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å†…éƒ¨ä¼šè®®è®°å½•è¿›è¡Œæ·±åº¦åˆ†æï¼Œæç‚¼å†³ç­–è¦ç‚¹å¹¶ç”Ÿæˆå¯æ‰§è¡Œçš„è¡ŒåŠ¨æ–¹æ¡ˆï¼š

### ä¼šè®®å†…å®¹ï¼š
{transcript}

## ä¸‰ã€åˆ†æè¦ç‚¹

### 3.1 ä¼šè®®æ¦‚è¿°
#### åŸºæœ¬ä¿¡æ¯
- **ä¼šè®®ä¸»é¢˜**ï¼šæ ¸å¿ƒè®®é¢˜å’Œè®¨è®ºç›®æ ‡
- **ä¼šè®®ç±»å‹**ï¼šå†³ç­–ä¼š/è®¨è®ºä¼š/æ±‡æŠ¥ä¼š/å¤´è„‘é£æš´
- **å‚ä¼šäººå‘˜**ï¼šå§“åã€éƒ¨é—¨ã€è§’è‰²
- **ä¼šè®®æ—¶é•¿**ï¼šä¼šè®®æ•ˆç‡çš„åˆæ­¥åˆ¤æ–­

#### ä¼šè®®èƒŒæ™¯
- **å¬å¼€åŸå› **ï¼šè§¦å‘æœ¬æ¬¡ä¼šè®®çš„äº‹ä»¶æˆ–éœ€æ±‚
- **å‰åºè¿›å±•**ï¼šç›¸å…³äº‹é¡¹çš„å†å²èƒŒæ™¯
- **ç´§è¿«ç¨‹åº¦**ï¼šé—®é¢˜çš„é‡è¦æ€§å’Œæ—¶é—´æ•æ„Ÿæ€§

### 3.2 å…³é”®è®®é¢˜åˆ†æ
#### è®®é¢˜æ¸…å•
æŒ‰é‡è¦æ€§æ’åºåˆ—å‡ºè®¨è®ºçš„æ‰€æœ‰è®®é¢˜ï¼š

1. **è®®é¢˜ä¸€**
   - é—®é¢˜æè¿°
   - è®¨è®ºè¦ç‚¹
   - å„æ–¹è§‚ç‚¹
   - åˆæ­¥ç»“è®º

2. **è®®é¢˜äºŒ**
   - é—®é¢˜æè¿°
   - è®¨è®ºè¦ç‚¹
   - å„æ–¹è§‚ç‚¹
   - åˆæ­¥ç»“è®º

ï¼ˆæ ¹æ®å®é™…æƒ…å†µç»§ç»­åˆ—ä¸¾ï¼‰

#### è®®é¢˜å…³è”æ€§
- å„è®®é¢˜ä¹‹é—´çš„é€»è¾‘å…³ç³»
- ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»
- èµ„æºç«äº‰æˆ–ååŒæ•ˆåº”

### 3.3 å†³ç­–äº‹é¡¹æ¢³ç†
#### å·²å†³ç­–äº‹é¡¹
æ˜ç¡®è®°å½•å·²ç»å½¢æˆå†³è®®çš„äº‹é¡¹ï¼š

| å†³ç­–äº‹é¡¹ | å…·ä½“å†…å®¹ | å†³ç­–ä¾æ® | è´Ÿè´£äºº | å®Œæˆæ—¶é™ |
|---------|---------|---------|--------|---------|
| å†³ç­–1 | è¯¦ç»†æè¿° | æ•°æ®/ç†ç”± | å§“å | æ—¥æœŸ |
| å†³ç­–2 | è¯¦ç»†æè¿° | æ•°æ®/ç†ç”± | å§“å | æ—¥æœŸ |

#### å¾…å†³ç­–äº‹é¡¹
éœ€è¦è¿›ä¸€æ­¥è®¨è®ºæˆ–ä¸Šçº§æ‰¹å‡†çš„äº‹é¡¹ï¼š

| å¾…å†³äº‹é¡¹ | æ‚¬è€Œæœªå†³çš„åŸå›  | æ‰€éœ€ä¿¡æ¯/æ¡ä»¶ | ä¸‹æ­¥è¡ŒåŠ¨ | é¢„è®¡æ—¶é—´ |
|---------|---------------|--------------|---------|---------|
| äº‹é¡¹1 | åŸå› è¯´æ˜ | å…·ä½“éœ€æ±‚ | è¡ŒåŠ¨è®¡åˆ’ | æ—¶é—´ |
| äº‹é¡¹2 | åŸå› è¯´æ˜ | å…·ä½“éœ€æ±‚ | è¡ŒåŠ¨è®¡åˆ’ | æ—¶é—´ |

#### æç½®äº‹é¡¹
æš‚æ—¶æç½®æˆ–å–æ¶ˆçš„è®®é¢˜ï¼š
- æç½®åŸå› 
- åç»­å¤„ç†å»ºè®®
- å¯èƒ½çš„é‡å¯æ¡ä»¶

### 3.4 è¡ŒåŠ¨è®¡åˆ’æç‚¼
#### å³æ—¶è¡ŒåŠ¨ï¼ˆä¼šåç«‹å³æ‰§è¡Œï¼‰
1. **è¡ŒåŠ¨é¡¹**ï¼šå…·ä½“ä»»åŠ¡æè¿°
   - è´Ÿè´£äººï¼šä¸»è¦/ååŠ©
   - äº§å‡ºç‰©ï¼šé¢„æœŸæˆæœ
   - æˆªæ­¢æ—¶é—´ï¼šå…·ä½“æ—¥æœŸ

#### çŸ­æœŸè®¡åˆ’ï¼ˆä¸€å‘¨å†…ï¼‰
2. **è¡ŒåŠ¨é¡¹**ï¼šå…·ä½“ä»»åŠ¡æè¿°
   - è´Ÿè´£äººï¼šä¸»è¦/ååŠ©
   - äº§å‡ºç‰©ï¼šé¢„æœŸæˆæœ
   - æˆªæ­¢æ—¶é—´ï¼šå…·ä½“æ—¥æœŸ
   - ä¾èµ–æ¡ä»¶ï¼šå‰ç½®ä»»åŠ¡

#### ä¸­é•¿æœŸè§„åˆ’ï¼ˆä¸€å‘¨ä»¥ä¸Šï¼‰
3. **è¡ŒåŠ¨é¡¹**ï¼šå…·ä½“ä»»åŠ¡æè¿°
   - è´Ÿè´£äººï¼šä¸»è¦/ååŠ©
   - é‡Œç¨‹ç¢‘ï¼šå…³é”®èŠ‚ç‚¹
   - èµ„æºéœ€æ±‚ï¼šäººåŠ›/é¢„ç®—
   - é£é™©æç¤ºï¼šæ½œåœ¨é—®é¢˜

### 3.5 èµ„æºä¸æ”¯æŒ
#### èµ„æºéœ€æ±‚
- **äººåŠ›èµ„æº**ï¼šéœ€è¦çš„äººå‘˜å’ŒæŠ€èƒ½
- **è´¢åŠ¡èµ„æº**ï¼šé¢„ç®—éœ€æ±‚å’Œå®¡æ‰¹æµç¨‹
- **æŠ€æœ¯èµ„æº**ï¼šç³»ç»Ÿã€å·¥å…·ã€è®¾å¤‡ç­‰
- **å¤–éƒ¨èµ„æº**ï¼šä¾›åº”å•†ã€é¡¾é—®ã€åˆä½œæ–¹

#### è·¨éƒ¨é—¨ååŒ
- éœ€è¦åè°ƒçš„éƒ¨é—¨
- åä½œæ–¹å¼å’Œæœºåˆ¶
- æ½œåœ¨çš„åä½œéšœç¢
- æ²Ÿé€šè®¡åˆ’

### 3.6 é£é™©ä¸å¯¹ç­–
#### æ‰§è¡Œé£é™©
- **é£é™©æè¿°**ï¼šå¯èƒ½å‡ºç°çš„é—®é¢˜
- **å½±å“è¯„ä¼°**ï¼šå¯¹é¡¹ç›®çš„æ½œåœ¨å½±å“
- **åº”å¯¹æªæ–½**ï¼šé¢„é˜²å’Œç¼“è§£æ–¹æ¡ˆ
- **è´£ä»»äºº**ï¼šé£é™©ç®¡ç†è´Ÿè´£äºº

#### å†³ç­–é£é™©
- å†³ç­–å‡è®¾çš„åˆç†æ€§
- ä¿¡æ¯ä¸å……åˆ†çš„é£é™©
- å¤–éƒ¨ç¯å¢ƒå˜åŒ–çš„å½±å“
- å¤‡é€‰æ–¹æ¡ˆçš„å‡†å¤‡

### 3.7 åç»­è·Ÿè¿›
#### è·Ÿè¿›æœºåˆ¶
- **è¿›åº¦æ£€æŸ¥**ï¼šæ—¶é—´å’Œæ–¹å¼
- **æ±‡æŠ¥è¦æ±‚**ï¼šé¢‘ç‡å’Œæ ¼å¼
- **é—®é¢˜å‡çº§**ï¼šå¤„ç†æµç¨‹
- **æˆæœéªŒæ”¶**ï¼šæ ‡å‡†å’Œç¨‹åº

#### ä¸‹æ¬¡ä¼šè®®
- **é¢„å®šæ—¶é—´**ï¼šå…·ä½“æ—¥æœŸ
- **é¢„æœŸè®®é¢˜**ï¼šä¸»è¦å†…å®¹
- **å‡†å¤‡å·¥ä½œ**ï¼šå„æ–¹éœ€å®Œæˆçš„ä»»åŠ¡
- **å‚ä¼šäººå‘˜**ï¼šå¿…éœ€å’Œå¯é€‰äººå‘˜

### 3.8 ä¼šè®®æ•ˆèƒ½è¯„ä¼°
#### ä¼šè®®è´¨é‡
- **ç›®æ ‡è¾¾æˆåº¦**ï¼šæ˜¯å¦è§£å†³äº†é¢„å®šé—®é¢˜
- **å†³ç­–æ•ˆç‡**ï¼šå†³ç­–çš„æ•°é‡å’Œè´¨é‡
- **å‚ä¸åº¦**ï¼šå„æ–¹çš„æŠ•å…¥ç¨‹åº¦
- **æ—¶é—´åˆ©ç”¨**ï¼šä¼šè®®æ—¶é•¿çš„åˆç†æ€§

#### æ”¹è¿›å»ºè®®
- **ä¼šè®®å‡†å¤‡**ï¼šå¦‚ä½•betterå‡†å¤‡
- **ä¼šè®®æµç¨‹**ï¼šè®®ç¨‹å’Œæ—¶é—´ç®¡ç†
- **å‚ä¸æ–¹å¼**ï¼šæé«˜äº’åŠ¨å’Œæ•ˆç‡
- **åç»­è·Ÿè¿›**ï¼šæ‰§è¡ŒåŠ›çš„ä¿éšœ

## å››ã€è¾“å‡ºè¦æ±‚
1. **ç»“æ„æ¸…æ™°**ï¼šä¿¡æ¯ç»„ç»‡æœ‰åºï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ
2. **é‡ç‚¹çªå‡º**ï¼šå…³é”®å†³ç­–å’Œè¡ŒåŠ¨é¡¹é†’ç›®å‘ˆç°
3. **è´£ä»»æ˜ç¡®**ï¼šæ¯é¡¹ä»»åŠ¡éƒ½æœ‰æ˜ç¡®çš„è´Ÿè´£äºº
4. **æ—¶é—´å…·ä½“**ï¼šæ‰€æœ‰æ—¶é™éƒ½å…·ä½“åˆ°æ—¥æœŸ
5. **å¯è¿½è¸ªæ€§**ï¼šä¾¿äºåç»­è·Ÿè¸ªå’Œè¯„ä¼°

--- File: prompts/proposal/__init__.py ---

--- File: prompts/proposal/project_proposal.md ---
# é¡¹ç›®å»ºè®®ä¹¦ç”Ÿæˆ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å•†ä¸šæ–¹æ¡ˆç­–åˆ’ä¸“å®¶å’Œé¡¹ç›®å»ºè®®ä¹¦æ’°å†™é¡¾é—®ï¼Œæ‹¥æœ‰15å¹´ä»¥ä¸Šçš„ä¼ä¸šå’¨è¯¢å’Œæ–¹æ¡ˆè®¾è®¡ç»éªŒã€‚ä½ ç²¾é€šå•†ä¸šå†™ä½œï¼Œæ“…é•¿å°†å¤æ‚çš„æŠ€æœ¯æ–¹æ¡ˆè½¬åŒ–ä¸ºæ¸…æ™°ã€æœ‰è¯´æœåŠ›çš„å•†ä¸šè¯­è¨€ï¼Œèƒ½å¤Ÿå‡†ç¡®æŠŠæ¡å®¢æˆ·éœ€æ±‚å¹¶æä¾›é’ˆå¯¹æ€§çš„è§£å†³æ–¹æ¡ˆã€‚

## äºŒã€ç”Ÿæˆä»»åŠ¡
åŸºäºä»¥ä¸‹åˆ†ææŠ¥å‘Šå’Œå‚è€ƒèµ„æ–™ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šã€å®Œæ•´çš„é¡¹ç›®å»ºè®®ä¹¦ï¼š

### åˆ†ææŠ¥å‘Šï¼š
{analysis_report}

### ä¼ä¸šèƒ½åŠ›å‚è€ƒï¼ˆå¦‚æä¾›ï¼‰ï¼š
{capability_docs}

### å®¢æˆ·ä¿¡æ¯ï¼ˆå¦‚æä¾›ï¼‰ï¼š
{client_info}

## ä¸‰ã€é¡¹ç›®å»ºè®®ä¹¦ç»“æ„

### å°é¢é¡µ
- é¡¹ç›®åç§°ï¼š[æ ¹æ®åˆ†æå†…å®¹ç”Ÿæˆæœ‰å¸å¼•åŠ›çš„é¡¹ç›®åç§°]
- å®¢æˆ·åç§°ï¼š[å®¢æˆ·å…¬å¸åç§°]
- æäº¤æ–¹ï¼š[æˆ‘æ–¹å…¬å¸åç§°]
- æäº¤æ—¥æœŸï¼š[å½“å‰æ—¥æœŸ]
- ç‰ˆæœ¬å·ï¼šV1.0

### ç›®å½•
[è‡ªåŠ¨ç”Ÿæˆçš„ç›®å½•ç»“æ„]

### 1. æ‰§è¡Œæ‘˜è¦
#### 1.1 é¡¹ç›®èƒŒæ™¯
ç”¨2-3æ®µè¯ç®€è¿°ï¼š
- å®¢æˆ·é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜
- å¸‚åœºç¯å¢ƒå’Œä¸šåŠ¡å‹åŠ›
- å˜é©çš„ç´§è¿«æ€§å’Œå¿…è¦æ€§

#### 1.2 è§£å†³æ–¹æ¡ˆæ¦‚è¿°
ç”¨ç²¾ç‚¼çš„è¯­è¨€æ¦‚æ‹¬ï¼š
- æˆ‘ä»¬æä¾›çš„æ ¸å¿ƒæ–¹æ¡ˆ
- æ–¹æ¡ˆçš„ç‹¬ç‰¹ä»·å€¼
- é¢„æœŸçš„ä¸šåŠ¡æˆæœ

#### 1.3 æŠ•èµ„å›æŠ¥
çªå‡ºå¼ºè°ƒï¼š
- é‡åŒ–çš„æ”¶ç›Šé¢„æœŸ
- æŠ•èµ„å›æ”¶å‘¨æœŸ
- é•¿æœŸæˆ˜ç•¥ä»·å€¼

#### 1.4 ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬
3-4ä¸ªå…³é”®å·®å¼‚åŒ–ä¼˜åŠ¿

### 2. éœ€æ±‚ç†è§£ä¸åˆ†æ
#### 2.1 ä¸šåŠ¡ç°çŠ¶åˆ†æ
- **å½“å‰æŒ‘æˆ˜**ï¼šè¯¦ç»†æè¿°å®¢æˆ·é¢ä¸´çš„å…·ä½“é—®é¢˜
- **ç—›ç‚¹å½±å“**ï¼šè¿™äº›é—®é¢˜å¯¹ä¸šåŠ¡çš„å…·ä½“å½±å“
- **æ”¹è¿›æœºä¼š**ï¼šå¯ä»¥ä¼˜åŒ–å’Œæå‡çš„ç©ºé—´

#### 2.2 éœ€æ±‚æ·±åº¦è§£è¯»
- **ä¸šåŠ¡éœ€æ±‚**ï¼šä»ä¸šåŠ¡è§†è§’è§£è¯»éœ€æ±‚
- **æŠ€æœ¯éœ€æ±‚**ï¼šæŠ€æœ¯å±‚é¢çš„å…·ä½“è¦æ±‚
- **ç®¡ç†éœ€æ±‚**ï¼šæµç¨‹å’Œç®¡ç†ä¼˜åŒ–éœ€æ±‚

#### 2.3 æˆåŠŸæ ‡å‡†å®šä¹‰
- **çŸ­æœŸç›®æ ‡**ï¼š3-6ä¸ªæœˆå†…çš„å…·ä½“ç›®æ ‡
- **ä¸­æœŸç›®æ ‡**ï¼š6-12ä¸ªæœˆçš„æå‡æŒ‡æ ‡
- **é•¿æœŸæ„¿æ™¯**ï¼š1-3å¹´çš„æˆ˜ç•¥ç›®æ ‡

### 3. è§£å†³æ–¹æ¡ˆè®¾è®¡
#### 3.1 æ•´ä½“æ–¹æ¡ˆæ¶æ„
- **æ–¹æ¡ˆå…¨æ™¯å›¾**ï¼šç”¨å›¾è¡¨å±•ç¤ºæ•´ä½“æ¶æ„
- **æ ¸å¿ƒç†å¿µ**ï¼šæ–¹æ¡ˆè®¾è®¡çš„æŒ‡å¯¼æ€æƒ³
- **å…³é”®ç‰¹æ€§**ï¼šæ–¹æ¡ˆçš„ä¸»è¦ç‰¹ç‚¹

#### 3.2 åŠŸèƒ½æ¨¡å—è¯¦è¿°
å¯¹æ¯ä¸ªä¸»è¦æ¨¡å—è¿›è¡Œè¯´æ˜ï¼š

**æ¨¡å—ä¸€ï¼š[æ¨¡å—åç§°]**
- åŠŸèƒ½æè¿°ï¼šè¯¥æ¨¡å—çš„ä¸»è¦åŠŸèƒ½
- ä¸šåŠ¡ä»·å€¼ï¼šè§£å†³ä»€ä¹ˆé—®é¢˜ï¼Œå¸¦æ¥ä»€ä¹ˆæ”¶ç›Š
- æŠ€æœ¯äº®ç‚¹ï¼šé‡‡ç”¨çš„å…ˆè¿›æŠ€æœ¯æˆ–æ–¹æ³•
- ç”¨æˆ·ä½“éªŒï¼šå¯¹æœ€ç»ˆç”¨æˆ·çš„å½±å“

**æ¨¡å—äºŒï¼š[æ¨¡å—åç§°]**
ï¼ˆæŒ‰åŒæ ·ç»“æ„æè¿°å…¶ä»–æ¨¡å—ï¼‰

#### 3.3 æŠ€æœ¯æ–¹æ¡ˆè¦ç‚¹
- **æŠ€æœ¯æ¶æ„**ï¼šç³»ç»Ÿçš„æŠ€æœ¯æ¶æ„è®¾è®¡
- **æŠ€æœ¯é€‰å‹**ï¼šå…³é”®æŠ€æœ¯ç»„ä»¶çš„é€‰æ‹©ç†ç”±
- **é›†æˆæ–¹æ¡ˆ**ï¼šä¸ç°æœ‰ç³»ç»Ÿçš„é›†æˆç­–ç•¥
- **å®‰å…¨ä¿éšœ**ï¼šæ•°æ®å®‰å…¨å’Œç³»ç»Ÿå®‰å…¨æªæ–½

#### 3.4 åˆ›æ–°äº®ç‚¹
- **åˆ›æ–°ç‚¹ä¸€**ï¼šæè¿° + ä»·å€¼
- **åˆ›æ–°ç‚¹äºŒ**ï¼šæè¿° + ä»·å€¼
- **åˆ›æ–°ç‚¹ä¸‰**ï¼šæè¿° + ä»·å€¼

### 4. å®æ–½è®¡åˆ’
#### 4.1 å®æ–½è·¯çº¿å›¾
**ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€å»ºè®¾**ï¼ˆæ—¶é—´è·¨åº¦ï¼‰
- ä¸»è¦ä»»åŠ¡
- å…³é”®é‡Œç¨‹ç¢‘
- é¢„æœŸæˆæœ

**ç¬¬äºŒé˜¶æ®µï¼šæ ¸å¿ƒå®æ–½**ï¼ˆæ—¶é—´è·¨åº¦ï¼‰
- ä¸»è¦ä»»åŠ¡
- å…³é”®é‡Œç¨‹ç¢‘
- é¢„æœŸæˆæœ

**ç¬¬ä¸‰é˜¶æ®µï¼šä¼˜åŒ–æå‡**ï¼ˆæ—¶é—´è·¨åº¦ï¼‰
- ä¸»è¦ä»»åŠ¡
- å…³é”®é‡Œç¨‹ç¢‘
- é¢„æœŸæˆæœ

#### 4.2 é¡¹ç›®æ²»ç†
- **ç»„ç»‡æ¶æ„**ï¼šé¡¹ç›®ç»„ç»‡ç»“æ„å›¾
- **è§’è‰²èŒè´£**ï¼šå„æ–¹çš„å…·ä½“èŒè´£
- **æ²Ÿé€šæœºåˆ¶**ï¼šå®šæœŸæ²Ÿé€šå’Œæ±‡æŠ¥å®‰æ’
- **å†³ç­–æµç¨‹**ï¼šé‡å¤§äº‹é¡¹çš„å†³ç­–æœºåˆ¶

#### 4.3 èµ„æºé…ç½®
- **å›¢é˜Ÿé…ç½®**ï¼šæˆ‘æ–¹æŠ•å…¥çš„å›¢é˜Ÿè§„æ¨¡å’Œç»“æ„
- **å®¢æˆ·é…åˆ**ï¼šéœ€è¦å®¢æˆ·æ–¹æä¾›çš„èµ„æº
- **è®¾æ–½è¦æ±‚**ï¼šåŠå…¬åœºåœ°ã€è®¾å¤‡ç­‰éœ€æ±‚
- **å…¶ä»–èµ„æº**ï¼šç¬¬ä¸‰æ–¹èµ„æºæˆ–ç‰¹æ®Šè¦æ±‚

#### 4.4 é£é™©ç®¡ç†
| é£é™©ç±»åˆ« | é£é™©æè¿° | å½±å“ç¨‹åº¦ | åº”å¯¹æªæ–½ | è´£ä»»æ–¹ |
|---------|---------|---------|---------|--------|
| æŠ€æœ¯é£é™© | å…·ä½“æè¿° | é«˜/ä¸­/ä½ | é¢„é˜²å’Œåº”å¯¹ç­–ç•¥ | è´Ÿè´£æ–¹ |
| ç®¡ç†é£é™© | å…·ä½“æè¿° | é«˜/ä¸­/ä½ | é¢„é˜²å’Œåº”å¯¹ç­–ç•¥ | è´Ÿè´£æ–¹ |
| å¤–éƒ¨é£é™© | å…·ä½“æè¿° | é«˜/ä¸­/ä½ | é¢„é˜²å’Œåº”å¯¹ç­–ç•¥ | è´Ÿè´£æ–¹ |

### 5. ä»·å€¼æ”¶ç›Šåˆ†æ
#### 5.1 ç›´æ¥æ”¶ç›Š
- **æˆæœ¬èŠ‚çœ**ï¼šå…·ä½“çš„æˆæœ¬é™ä½é¢„æœŸ
- **æ•ˆç‡æå‡**ï¼šé‡åŒ–çš„æ•ˆç‡æ”¹è¿›æŒ‡æ ‡
- **æ”¶å…¥å¢é•¿**ï¼šå¯èƒ½å¸¦æ¥çš„æ”¶å…¥æå‡

#### 5.2 é—´æ¥æ”¶ç›Š
- **ç®¡ç†æå‡**ï¼šå†³ç­–èƒ½åŠ›å’Œç®¡ç†æ°´å¹³çš„æå‡
- **ç«äº‰ä¼˜åŠ¿**ï¼šå¸‚åœºç«äº‰åŠ›çš„å¢å¼º
- **å“ç‰Œä»·å€¼**ï¼šä¼ä¸šå½¢è±¡å’Œå“ç‰Œçš„æå‡

#### 5.3 æŠ•èµ„å›æŠ¥åˆ†æ
- **æŠ•èµ„æ„æˆ**ï¼šè¯¦ç»†çš„æŠ•èµ„æ˜ç»†
- **å›æŠ¥å‘¨æœŸ**ï¼šé¢„æœŸçš„æŠ•èµ„å›æ”¶æœŸ
- **ROIè®¡ç®—**ï¼šæŠ•èµ„å›æŠ¥ç‡åˆ†æ
- **æ•æ„Ÿæ€§åˆ†æ**ï¼šå…³é”®å˜é‡çš„å½±å“

### 6. ä¸ºä»€ä¹ˆé€‰æ‹©æˆ‘ä»¬
#### 6.1 å…¬å¸ä¼˜åŠ¿
- **è¡Œä¸šåœ°ä½**ï¼šå…¬å¸åœ¨è¡Œä¸šä¸­çš„åœ°ä½
- **ä¸“ä¸šèƒ½åŠ›**ï¼šæ ¸å¿ƒæŠ€æœ¯å’ŒæœåŠ¡èƒ½åŠ›
- **èµ„è´¨è®¤è¯**ï¼šç›¸å…³çš„èµ„è´¨å’Œè®¤è¯
- **ä¼ä¸šæ–‡åŒ–**ï¼šä»·å€¼è§‚å’ŒæœåŠ¡ç†å¿µ

#### 6.2 å›¢é˜Ÿå®åŠ›
- **å›¢é˜Ÿè§„æ¨¡**ï¼šä¸“ä¸šå›¢é˜Ÿçš„è§„æ¨¡
- **ä¸“å®¶å›¢é˜Ÿ**ï¼šæ ¸å¿ƒä¸“å®¶çš„èƒŒæ™¯
- **æŠ€æœ¯å®åŠ›**ï¼šæŠ€æœ¯èƒ½åŠ›å’Œåˆ›æ–°èƒ½åŠ›
- **æœåŠ¡ç»éªŒ**ï¼šç±»ä¼¼é¡¹ç›®çš„æœåŠ¡ç»éªŒ

#### 6.3 æˆåŠŸæ¡ˆä¾‹
**æ¡ˆä¾‹ä¸€ï¼š[å®¢æˆ·åç§°]é¡¹ç›®**
- é¡¹ç›®èƒŒæ™¯
- è§£å†³æ–¹æ¡ˆ
- å®æ–½æ•ˆæœ
- å®¢æˆ·è¯„ä»·

**æ¡ˆä¾‹äºŒï¼š[å®¢æˆ·åç§°]é¡¹ç›®**
ï¼ˆåŒæ ·æ ¼å¼ï¼‰

#### 6.4 æœåŠ¡æ‰¿è¯º
- **è´¨é‡æ‰¿è¯º**ï¼šäº¤ä»˜è´¨é‡çš„ä¿è¯
- **æ—¶é—´æ‰¿è¯º**ï¼šé¡¹ç›®è¿›åº¦çš„ä¿è¯
- **æœåŠ¡æ‰¿è¯º**ï¼šæŒç»­æœåŠ¡çš„ä¿è¯
- **ä¿å¯†æ‰¿è¯º**ï¼šä¿¡æ¯å®‰å…¨çš„ä¿è¯

### 7. å•†åŠ¡æ¡æ¬¾
#### 7.1 é¡¹ç›®æŠ¥ä»·
- **æŠ¥ä»·æ˜ç»†**ï¼šåˆ†é˜¶æ®µã€åˆ†æ¨¡å—çš„è¯¦ç»†æŠ¥ä»·
- **ä»·æ ¼è¯´æ˜**ï¼šæŠ¥ä»·çš„æ„æˆå’Œè¯´æ˜
- **ä¼˜æƒ æ”¿ç­–**ï¼šå¯èƒ½çš„æŠ˜æ‰£æˆ–ä¼˜æƒ 
- **ä»·æ ¼æœ‰æ•ˆæœŸ**ï¼šæŠ¥ä»·çš„æœ‰æ•ˆæœŸé™

#### 7.2 ä»˜æ¬¾æ–¹å¼
- **ä»˜æ¬¾èŠ‚ç‚¹**ï¼šä¸é¡¹ç›®é‡Œç¨‹ç¢‘å¯¹åº”çš„ä»˜æ¬¾å®‰æ’
- **ä»˜æ¬¾æ¯”ä¾‹**ï¼šå„èŠ‚ç‚¹çš„ä»˜æ¬¾æ¯”ä¾‹
- **ä»˜æ¬¾æ–¹å¼**ï¼šæ¥å—çš„ä»˜æ¬¾æ–¹å¼
- **ç‰¹æ®Šæ¡æ¬¾**ï¼šå…¶ä»–å•†åŠ¡æ¡æ¬¾

#### 7.3 æœåŠ¡æ¡æ¬¾
- **æœåŠ¡èŒƒå›´**ï¼šæ˜ç¡®çš„æœåŠ¡è¾¹ç•Œ
- **æœåŠ¡æ ‡å‡†**ï¼šæœåŠ¡è´¨é‡æ ‡å‡†
- **å”®åæœåŠ¡**ï¼šè´¨ä¿æœŸå’Œå”®åæœåŠ¡
- **å…¶ä»–æ¡æ¬¾**ï¼šçŸ¥è¯†äº§æƒã€ä¿å¯†ç­‰

### 8. é™„å½•
- é™„ä»¶ä¸€ï¼šè¯¦ç»†æŠ€æœ¯æ–¹æ¡ˆ
- é™„ä»¶äºŒï¼šé¡¹ç›®å›¢é˜Ÿç®€å†
- é™„ä»¶ä¸‰ï¼šç›¸å…³èµ„è´¨è¯æ˜
- é™„ä»¶å››ï¼šè¡¥å……è¯´æ˜ææ–™

## å››ã€å†™ä½œè¦æ±‚

### è¯­è¨€é£æ ¼
1. **ä¸“ä¸šä¸¥è°¨**ï¼šä½¿ç”¨è§„èŒƒçš„å•†ä¸šè¯­è¨€ï¼Œé¿å…å£è¯­åŒ–è¡¨è¾¾
2. **ç®€æ´æœ‰åŠ›**ï¼šè¨€ç®€æ„èµ…ï¼Œé¿å…å†—é•¿å’Œé‡å¤
3. **é€»è¾‘æ¸…æ™°**ï¼šå±‚æ¬¡åˆ†æ˜ï¼Œå‰åå‘¼åº”
4. **å¯Œæœ‰æ„ŸæŸ“åŠ›**ï¼šé€‚å½“ä½¿ç”¨æœ‰è¯´æœåŠ›çš„è¡¨è¾¾

### æ ¼å¼è¦æ±‚
1. **ç‰ˆå¼ä¸“ä¸š**ï¼šä¿æŒä¸“ä¸šçš„æ–‡æ¡£æ ¼å¼
2. **å›¾æ–‡å¹¶èŒ‚**ï¼šé€‚å½“ä½¿ç”¨å›¾è¡¨å¢å¼ºå¯è¯»æ€§
3. **é‡ç‚¹çªå‡º**ï¼šå…³é”®ä¿¡æ¯ä½¿ç”¨åŠ ç²—æˆ–ç‰¹æ®Šæ ¼å¼
4. **æ˜“äºé˜…è¯»**ï¼šåˆç†çš„æ®µè½åˆ’åˆ†å’Œæ ‡é¢˜å±‚çº§

### å†…å®¹è¦æ±‚
1. **é’ˆå¯¹æ€§å¼º**ï¼šç´§å¯†ç»“åˆå®¢æˆ·çš„å…·ä½“éœ€æ±‚
2. **ä»·å€¼å¯¼å‘**ï¼šå§‹ç»ˆå¼ºè°ƒä¸ºå®¢æˆ·åˆ›é€ çš„ä»·å€¼
3. **æ•°æ®æ”¯æ’‘**ï¼šç”¨æ•°æ®å’Œäº‹å®è¯´è¯
4. **å¯æ“ä½œæ€§**ï¼šæ–¹æ¡ˆå…·ä½“å¯è½åœ°

### ç¯‡å¹…æ§åˆ¶
- æ‰§è¡Œæ‘˜è¦ï¼š2-3é¡µ
- æ­£æ–‡å†…å®¹ï¼š15-25é¡µ
- é™„å½•ï¼šæ ¹æ®éœ€è¦

è¯·åŸºäºä»¥ä¸Šæ¡†æ¶å’Œè¦æ±‚ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„é¡¹ç›®å»ºè®®ä¹¦ã€‚

--- File: prompts/proposal/quotation_proposal.md ---
# å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆç”Ÿæˆ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†åŠ¡æŠ¥ä»·é¡¾é—®å’Œæ–¹æ¡ˆè®¾è®¡ä¸“å®¶ï¼Œç²¾é€šæŠ¥ä»·ç­–ç•¥ã€æˆæœ¬åˆ†æå’Œå•†ä¸šè°ˆåˆ¤ã€‚ä½ èƒ½å¤Ÿæ ¹æ®å®¢æˆ·éœ€æ±‚å’Œé¡¹ç›®ç‰¹ç‚¹ï¼Œè®¾è®¡æœ‰ç«äº‰åŠ›ä¸”åˆ©æ¶¦åˆç†çš„æŠ¥ä»·æ–¹æ¡ˆï¼Œå¹¶ä»¥ä¸“ä¸šã€æ¸…æ™°çš„æ–¹å¼å‘ˆç°ã€‚

## äºŒã€ç”Ÿæˆä»»åŠ¡
åŸºäºä»¥ä¸‹åˆ†ææŠ¥å‘Šå’Œå‚è€ƒä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆï¼š

### éœ€æ±‚åˆ†ææŠ¥å‘Šï¼š
{analysis_report}

### ä¼ä¸šæœåŠ¡èƒ½åŠ›ï¼ˆå¦‚æä¾›ï¼‰ï¼š
{capability_docs}

### æŠ¥ä»·å‚æ•°ï¼ˆå¦‚æä¾›ï¼‰ï¼š
{pricing_parameters}

## ä¸‰ã€æŠ¥ä»·æ–¹æ¡ˆç»“æ„

### 1. æ–¹æ¡ˆæ¦‚è¿°
#### 1.1 é¡¹ç›®èƒŒæ™¯
- å®¢æˆ·éœ€æ±‚æ¦‚è¦
- é¡¹ç›®èŒƒå›´è¯´æ˜
- æŠ¥ä»·æœ‰æ•ˆæœŸï¼šè‡ªæŠ¥ä»·ä¹‹æ—¥èµ·30å¤©å†…æœ‰æ•ˆ

#### 1.2 æœåŠ¡å†…å®¹æ¦‚è§ˆ
ç®€è¦åˆ—å‡ºæœ¬æ¬¡æŠ¥ä»·åŒ…å«çš„ä¸»è¦æœåŠ¡å†…å®¹ï¼š
- æ ¸å¿ƒæœåŠ¡é¡¹ç›®
- å¢å€¼æœåŠ¡å†…å®¹
- æœåŠ¡è¾¹ç•Œè¯´æ˜

#### 1.3 æ€»ä½“æŠ¥ä»·
**é¡¹ç›®æ€»ä»·ï¼šÂ¥ [é‡‘é¢]**
- æ ‡å‡†æœåŠ¡è´¹ï¼šÂ¥ [é‡‘é¢]
- å¢å€¼æœåŠ¡è´¹ï¼šÂ¥ [é‡‘é¢]ï¼ˆå¦‚é€‚ç”¨ï¼‰
- ä¼˜æƒ æŠ˜æ‰£ï¼š-Â¥ [é‡‘é¢]ï¼ˆå¦‚é€‚ç”¨ï¼‰

### 2. è¯¦ç»†æŠ¥ä»·æ˜ç»†
#### 2.1 æœåŠ¡é¡¹ç›®æŠ¥ä»·è¡¨

| æœåŠ¡æ¨¡å— | æœåŠ¡å†…å®¹ | å·¥ä½œé‡ | å•ä»· | å°è®¡ | å¤‡æ³¨ |
|---------|---------|--------|------|------|------|
| æ¨¡å—ä¸€ | å…·ä½“æœåŠ¡æè¿° | äººå¤©/æ•°é‡ | Â¥å•ä»· | Â¥æ€»ä»· | è¯´æ˜ |
| æ¨¡å—äºŒ | å…·ä½“æœåŠ¡æè¿° | äººå¤©/æ•°é‡ | Â¥å•ä»· | Â¥æ€»ä»· | è¯´æ˜ |
| æ¨¡å—ä¸‰ | å…·ä½“æœåŠ¡æè¿° | äººå¤©/æ•°é‡ | Â¥å•ä»· | Â¥æ€»ä»· | è¯´æ˜ |
| ... | ... | ... | ... | ... | ... |
| **åˆè®¡** | - | **æ€»äººå¤©** | - | **Â¥æ€»è®¡** | - |

#### 2.2 å®æ–½é˜¶æ®µæŠ¥ä»·

**ç¬¬ä¸€é˜¶æ®µï¼š[é˜¶æ®µåç§°]**ï¼ˆæ—¶é—´è·¨åº¦ï¼‰
- ä¸»è¦å·¥ä½œå†…å®¹
- äº¤ä»˜æˆæœ
- é˜¶æ®µæŠ¥ä»·ï¼šÂ¥ [é‡‘é¢]

**ç¬¬äºŒé˜¶æ®µï¼š[é˜¶æ®µåç§°]**ï¼ˆæ—¶é—´è·¨åº¦ï¼‰
- ä¸»è¦å·¥ä½œå†…å®¹
- äº¤ä»˜æˆæœ
- é˜¶æ®µæŠ¥ä»·ï¼šÂ¥ [é‡‘é¢]

**ç¬¬ä¸‰é˜¶æ®µï¼š[é˜¶æ®µåç§°]**ï¼ˆæ—¶é—´è·¨åº¦ï¼‰
- ä¸»è¦å·¥ä½œå†…å®¹
- äº¤ä»˜æˆæœ
- é˜¶æ®µæŠ¥ä»·ï¼šÂ¥ [é‡‘é¢]

#### 2.3 äººåŠ›èµ„æºé…ç½®åŠæŠ¥ä»·

| è§’è‰² | çº§åˆ« | äººæ•° | æŠ•å…¥æ—¶é—´ | äººå¤©å•ä»· | å°è®¡ |
|------|------|------|----------|----------|------|
| é¡¹ç›®ç»ç† | é«˜çº§ | 1 | Xäººå¤© | Â¥X/å¤© | Â¥X |
| æ¶æ„å¸ˆ | é«˜çº§ | 1 | Xäººå¤© | Â¥X/å¤© | Â¥X |
| å¼€å‘å·¥ç¨‹å¸ˆ | ä¸­çº§ | X | Xäººå¤© | Â¥X/å¤© | Â¥X |
| æµ‹è¯•å·¥ç¨‹å¸ˆ | ä¸­çº§ | X | Xäººå¤© | Â¥X/å¤© | Â¥X |
| ... | ... | ... | ... | ... | ... |
| **åˆè®¡** | - | **Xäºº** | **Xäººå¤©** | - | **Â¥X** |

### 3. æœåŠ¡è¯´æ˜
#### 3.1 æœåŠ¡èŒƒå›´
**åŒ…å«æœåŠ¡ï¼š**
- è¯¦ç»†åˆ—å‡ºæ‰€æœ‰åŒ…å«çš„æœåŠ¡å†…å®¹
- æ˜ç¡®å„é¡¹æœåŠ¡çš„å…·ä½“èŒƒå›´
- è¯´æ˜æœåŠ¡çš„æ ‡å‡†å’Œè¦æ±‚

**ä¸åŒ…å«æœåŠ¡ï¼š**
- æ˜ç¡®è¯´æ˜å“ªäº›æœåŠ¡ä¸åœ¨æŠ¥ä»·èŒƒå›´å†…
- åˆ—å‡ºå¯èƒ½äº§ç”Ÿé¢å¤–è´¹ç”¨çš„æƒ…å†µ
- è¯´æ˜å¢å€¼æœåŠ¡çš„æ”¶è´¹æ ‡å‡†

#### 3.2 å·¥ä½œæ–¹æ³•
- **å®æ–½æ–¹æ³•è®º**ï¼šé‡‡ç”¨çš„é¡¹ç›®ç®¡ç†æ–¹æ³•
- **è´¨é‡ä¿è¯**ï¼šè´¨é‡æ§åˆ¶æªæ–½å’Œæ ‡å‡†
- **æ²Ÿé€šæœºåˆ¶**ï¼šé¡¹ç›®æ²Ÿé€šå’Œæ±‡æŠ¥å®‰æ’
- **å˜æ›´ç®¡ç†**ï¼šéœ€æ±‚å˜æ›´çš„å¤„ç†æµç¨‹

#### 3.3 äº¤ä»˜æˆæœ
åˆ—å‡ºå„é˜¶æ®µçš„å…·ä½“äº¤ä»˜ç‰©ï¼š

| é˜¶æ®µ | äº¤ä»˜æˆæœ | äº¤ä»˜å½¢å¼ | äº¤ä»˜æ—¶é—´ |
|------|---------|----------|----------|
| é˜¶æ®µä¸€ | æˆæœæ¸…å• | æ–‡æ¡£/ç³»ç»Ÿ/æŠ¥å‘Š | å…·ä½“æ—¥æœŸ |
| é˜¶æ®µäºŒ | æˆæœæ¸…å• | æ–‡æ¡£/ç³»ç»Ÿ/æŠ¥å‘Š | å…·ä½“æ—¥æœŸ |
| é˜¶æ®µä¸‰ | æˆæœæ¸…å• | æ–‡æ¡£/ç³»ç»Ÿ/æŠ¥å‘Š | å…·ä½“æ—¥æœŸ |

### 4. ä»˜æ¬¾æ–¹å¼
#### 4.1 ä»˜æ¬¾èŠ‚ç‚¹å®‰æ’

| ä»˜æ¬¾èŠ‚ç‚¹ | ä»˜æ¬¾æ¯”ä¾‹ | ä»˜æ¬¾é‡‘é¢ | ä»˜æ¬¾æ¡ä»¶ |
|---------|---------|---------|----------|
| åˆåŒç­¾è®¢ | 30% | Â¥X | åˆåŒç”Ÿæ•ˆå5ä¸ªå·¥ä½œæ—¥å†… |
| é˜¶æ®µä¸€å®Œæˆ | 30% | Â¥X | é˜¶æ®µéªŒæ”¶é€šè¿‡å5ä¸ªå·¥ä½œæ—¥å†… |
| é˜¶æ®µäºŒå®Œæˆ | 30% | Â¥X | é˜¶æ®µéªŒæ”¶é€šè¿‡å5ä¸ªå·¥ä½œæ—¥å†… |
| é¡¹ç›®éªŒæ”¶ | 10% | Â¥X | æ•´ä½“éªŒæ”¶é€šè¿‡å5ä¸ªå·¥ä½œæ—¥å†… |

#### 4.2 ä»˜æ¬¾æ–¹å¼
- æ¥å—çš„ä»˜æ¬¾æ–¹å¼ï¼šé“¶è¡Œè½¬è´¦ã€æ”¯ç¥¨
- å¼€ç¥¨ä¿¡æ¯ï¼šå¢å€¼ç¨ä¸“ç”¨å‘ç¥¨
- ä»˜æ¬¾è´¦æˆ·ï¼š[é¢„ç•™é“¶è¡Œè´¦æˆ·ä¿¡æ¯ä½ç½®]

#### 4.3 ä»·æ ¼æ¡æ¬¾
- **ä»·æ ¼æœ‰æ•ˆæœŸ**ï¼š30å¤©
- **ä»·æ ¼è°ƒæ•´**ï¼šè¶…å‡ºæŠ¥ä»·èŒƒå›´çš„å·¥ä½œæŒ‰å®é™…å·¥ä½œé‡å¦è¡ŒæŠ¥ä»·
- **ä¼˜æƒ æ”¿ç­–**ï¼š[æ ¹æ®æƒ…å†µè¯´æ˜å¯èƒ½çš„ä¼˜æƒ ]

### 5. æœåŠ¡ä¿éšœ
#### 5.1 æœåŠ¡æ‰¿è¯º
- **æŒ‰æ—¶äº¤ä»˜**ï¼šä¸¥æ ¼æŒ‰ç…§é¡¹ç›®è®¡åˆ’äº¤ä»˜
- **è´¨é‡ä¿è¯**ï¼šç¬¦åˆçº¦å®šçš„è´¨é‡æ ‡å‡†
- **å›¢é˜Ÿç¨³å®š**ï¼šä¿è¯æ ¸å¿ƒå›¢é˜Ÿçš„ç¨³å®šæ€§
- **æŒç»­æ”¯æŒ**ï¼šæä¾›å¿…è¦çš„åç»­æ”¯æŒ

#### 5.2 å”®åæœåŠ¡
- **è´¨ä¿æœŸ**ï¼šç³»ç»Ÿä¸Šçº¿åXä¸ªæœˆ
- **è´¨ä¿èŒƒå›´**ï¼šåŠŸèƒ½ç¼ºé™·ä¿®å¤ã€æ€§èƒ½ä¼˜åŒ–
- **å“åº”æ—¶é—´**ï¼šç´§æ€¥é—®é¢˜Xå°æ—¶å†…å“åº”
- **æœåŠ¡æ–¹å¼**ï¼šç°åœº/è¿œç¨‹/ç”µè¯æ”¯æŒ

#### 5.3 çŸ¥è¯†äº§æƒ
- **ä»£ç å½’å±**ï¼šé¡¹ç›®ä»£ç å½’å®¢æˆ·æ‰€æœ‰
- **æ–‡æ¡£ç‰ˆæƒ**ï¼šé¡¹ç›®æ–‡æ¡£å½’å®¢æˆ·æ‰€æœ‰
- **ä¿å¯†åè®®**ï¼šä¸¥æ ¼éµå®ˆä¿å¯†åè®®

### 6. é™„åŠ è¯´æ˜
#### 6.1 å‰ææ¡ä»¶
- å®¢æˆ·éœ€æä¾›çš„èµ„æºå’Œæ”¯æŒ
- é¡¹ç›®å®æ–½çš„å¿…è¦æ¡ä»¶
- åŒæ–¹çš„åä½œè¦æ±‚

#### 6.2 ç‰¹åˆ«è¯´æ˜
- æŠ¥ä»·åŸºäºå½“å‰ç†è§£çš„éœ€æ±‚èŒƒå›´
- é‡å¤§éœ€æ±‚å˜æ›´éœ€é‡æ–°è¯„ä¼°æŠ¥ä»·
- ä¸å¯æŠ—åŠ›å› ç´ çš„å¤„ç†

#### 6.3 å…¶ä»–æ¡æ¬¾
- åˆåŒæ¡æ¬¾ä»¥æ­£å¼åˆåŒä¸ºå‡†
- äº‰è®®è§£å†³æ–¹å¼
- å…¶ä»–éœ€è¦è¯´æ˜çš„äº‹é¡¹

### 7. å…¬å¸èµ„è´¨
#### 7.1 å…¬å¸ç®€ä»‹
- å…¬å¸åŸºæœ¬ä¿¡æ¯
- æ ¸å¿ƒç«äº‰åŠ›
- æœåŠ¡ç†å¿µ

#### 7.2 èµ„è´¨è¯ä¹¦
- ç›¸å…³è¡Œä¸šèµ„è´¨
- æŠ€æœ¯è®¤è¯
- è£èª‰å¥–é¡¹

#### 7.3 è”ç³»æ–¹å¼
- å•†åŠ¡è”ç³»äººï¼š[å§“å]
- è”ç³»ç”µè¯ï¼š[ç”µè¯]
- ç”µå­é‚®ç®±ï¼š[é‚®ç®±]
- å…¬å¸åœ°å€ï¼š[åœ°å€]

## å››ã€æŠ¥ä»·ç­–ç•¥æŒ‡å¯¼

### å®šä»·åŸåˆ™
1. **æˆæœ¬åŸºç¡€**ï¼šç¡®ä¿åˆç†çš„åˆ©æ¶¦ç©ºé—´
2. **å¸‚åœºå¯¼å‘**ï¼šå‚è€ƒå¸‚åœºä»·æ ¼æ°´å¹³
3. **ä»·å€¼å®šä»·**ï¼šåŸºäºä¸ºå®¢æˆ·åˆ›é€ çš„ä»·å€¼
4. **ç­–ç•¥çµæ´»**ï¼šæ ¹æ®å®¢æˆ·ç‰¹ç‚¹è°ƒæ•´ç­–ç•¥

### æŠ¥ä»·æŠ€å·§
1. **ç»“æ„æ¸…æ™°**ï¼šè®©å®¢æˆ·å®¹æ˜“ç†è§£æŠ¥ä»·æ„æˆ
2. **é€æ˜åº¦é«˜**ï¼šæ˜ç¡®è¯´æ˜æ”¶è´¹æ ‡å‡†
3. **é€‰æ‹©æ€§**ï¼šæä¾›ä¸åŒçš„æ–¹æ¡ˆé€‰æ‹©
4. **é™„åŠ ä»·å€¼**ï¼šçªå‡ºæœåŠ¡çš„é¢å¤–ä»·å€¼

### æ³¨æ„äº‹é¡¹
1. **é¿å…ä½ä»·ç«äº‰**ï¼šæ³¨é‡ä»·å€¼è€Œéä»·æ ¼
2. **é¢„ç•™ç©ºé—´**ï¼šä¸ºè°ˆåˆ¤é¢„ç•™é€‚å½“ç©ºé—´
3. **é£é™©æ§åˆ¶**ï¼šæ˜ç¡®æœåŠ¡è¾¹ç•Œé¿å…èŒƒå›´è”“å»¶
4. **ä¸“ä¸šå½¢è±¡**ï¼šä¿æŒæŠ¥ä»·æ–‡æ¡£çš„ä¸“ä¸šæ€§

è¯·åŸºäºä»¥ä¸Šæ¡†æ¶ç”Ÿæˆä¸“ä¸šçš„å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆã€‚

--- File: prompts/proposal/solution_brief.md ---
# è§£å†³æ–¹æ¡ˆç®€æŠ¥ç”Ÿæˆ

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½ä¼˜ç§€çš„è§£å†³æ–¹æ¡ˆæ¶æ„å¸ˆå’Œå•†ä¸šæ²Ÿé€šä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚çš„æŠ€æœ¯æ–¹æ¡ˆå’Œå•†ä¸šç­–ç•¥æµ“ç¼©æˆç®€æ´ã€æœ‰åŠ›çš„æ‰§è¡Œç®€æŠ¥ã€‚ä½ èƒ½å¤Ÿå¿«é€ŸæŠ“ä½é—®é¢˜æ ¸å¿ƒï¼Œæå‡ºåˆ‡å®å¯è¡Œçš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶ä»¥ç®€æ˜æ‰¼è¦çš„æ–¹å¼å‘é«˜å±‚ç®¡ç†è€…æ±‡æŠ¥ã€‚

## äºŒã€ç”Ÿæˆä»»åŠ¡
åŸºäºä»¥ä¸‹åˆ†ææŠ¥å‘Šï¼Œç”Ÿæˆä¸€ä»½ç®€æ´æœ‰åŠ›çš„è§£å†³æ–¹æ¡ˆç®€æŠ¥ï¼š

### åˆ†ææŠ¥å‘Šï¼š
{analysis_report}

### è¡¥å……ä¿¡æ¯ï¼ˆå¦‚æä¾›ï¼‰ï¼š
{additional_context}

## ä¸‰ã€ç®€æŠ¥ç»“æ„ï¼ˆæ§åˆ¶åœ¨3-5é¡µï¼‰

### æ ‡é¢˜é¡µ
**[è§£å†³æ–¹æ¡ˆåç§°]**
å‰¯æ ‡é¢˜ï¼šé’ˆå¯¹[å…·ä½“é—®é¢˜]çš„è§£å†³æ–¹æ¡ˆ
æ—¥æœŸï¼š[å½“å‰æ—¥æœŸ]

---

### 1. é—®é¢˜é™ˆè¿°ï¼ˆ1é¡µï¼‰

#### 1.1 æ ¸å¿ƒé—®é¢˜
ç”¨**ä¸€å¥è¯**æ¦‚æ‹¬å®¢æˆ·é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼š
> "_______________"

#### 1.2 é—®é¢˜åˆ†è§£
ç”¨**3-4ä¸ªè¦ç‚¹**è¯´æ˜é—®é¢˜çš„å…³é”®æ–¹é¢ï¼š
- **é—®é¢˜ç»´åº¦1**ï¼šå…·ä½“æè¿°ï¼ˆ1-2å¥è¯ï¼‰
- **é—®é¢˜ç»´åº¦2**ï¼šå…·ä½“æè¿°ï¼ˆ1-2å¥è¯ï¼‰
- **é—®é¢˜ç»´åº¦3**ï¼šå…·ä½“æè¿°ï¼ˆ1-2å¥è¯ï¼‰

#### 1.3 å½±å“åˆ†æ
å¦‚æœä¸è§£å†³ï¼Œå°†å¯¼è‡´ï¼š
- **ä¸šåŠ¡å½±å“**ï¼šé‡åŒ–çš„è´Ÿé¢å½±å“
- **ç«äº‰åŠ£åŠ¿**ï¼šå¸‚åœºåœ°ä½çš„æ½œåœ¨æŸå¤±
- **æœºä¼šæˆæœ¬**ï¼šé”™å¤±çš„å‘å±•æœºé‡

#### 1.4 ç´§è¿«æ€§
**å¿…é¡»ç«‹å³è¡ŒåŠ¨çš„ç†ç”±**ï¼š
[ç”¨1-2å¥è¯è¯´æ˜ä¸ºä»€ä¹ˆç°åœ¨å¿…é¡»è§£å†³è¿™ä¸ªé—®é¢˜]

---

### 2. è§£å†³æ–¹æ¡ˆï¼ˆ1-2é¡µï¼‰

#### 2.1 æ–¹æ¡ˆæ¦‚è¿°
**ä¸€å¥è¯æ–¹æ¡ˆ**ï¼š
> "æˆ‘ä»¬å»ºè®®_______________"

#### 2.2 æ–¹æ¡ˆè¦ç´ 
ç”¨**å›¾ç¤ºæˆ–è¡¨æ ¼**å±•ç¤ºæ–¹æ¡ˆçš„æ ¸å¿ƒç»„æˆï¼š

--- File: prompts/transcription/__init__.py ---

--- File: prompts/transcription/multi_speaker.md ---
è¯·å‡†ç¡®è½¬å½•è¿™æ®µéŸ³é¢‘å†…å®¹ã€‚

è¦æ±‚ï¼š
1. å‡†ç¡®è¯†åˆ«ä¸åŒè¯´è¯äººï¼Œä½¿ç”¨"è¯´è¯äººA:"ã€"è¯´è¯äººB:"ç­‰æ ¼å¼æ ‡è®°
2. ä¿ç•™æ‰€æœ‰å¯¹è¯å†…å®¹ï¼ŒåŒ…æ‹¬è¯­æ°”è¯
3. é€‚å½“æ·»åŠ æ ‡ç‚¹ç¬¦å·ï¼Œæé«˜å¯è¯»æ€§
4. å¦‚æœ‰èƒŒæ™¯å™ªéŸ³æˆ–ä¸æ¸…æ™°éƒ¨åˆ†ï¼Œç”¨[å¬ä¸æ¸…]æ ‡è®°

è¯·ç›´æ¥è¾“å‡ºè½¬å½•ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚

--- File: prompts/transcription/optimization.md ---
# è½¬å½•æ–‡æœ¬ä¼˜åŒ–ä»»åŠ¡

## ç¬¬ä¸€éƒ¨åˆ†ï¼šé”™è¯¯è¯†åˆ«ä¸ä¿®æ­£å»ºè®®

è¯·ä»”ç»†åˆ†æä»¥ä¸‹è½¬å½•æ–‡æœ¬ï¼Œè¯†åˆ«å¯èƒ½çš„é”™è¯¯å¹¶æä¾›ä¿®æ­£å»ºè®®ï¼š

{transcript}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤åˆ†æï¼š

### 1. æ‹¼å†™å’Œç”¨è¯é”™è¯¯
- è¯†åˆ«æ˜æ˜¾çš„æ‹¼å†™é”™è¯¯æˆ–åŒéŸ³è¯è¯¯ç”¨
- æ ‡æ³¨ä¸“ä¸šæœ¯è¯­çš„é”™è¯¯æ‹¼å†™
- è¯†åˆ«å£è¯­åŒ–è¡¨è¾¾ä¸­çš„è½¬å½•é”™è¯¯

### 2. è¯­æ³•å’Œå¥æ³•é—®é¢˜
- è¯†åˆ«è¯­æ³•é”™è¯¯å’Œä¸å®Œæ•´çš„å¥å­
- æ ‡æ³¨æ ‡ç‚¹ç¬¦å·ä½¿ç”¨ä¸å½“çš„åœ°æ–¹
- æŒ‡å‡ºå¥å­ç»“æ„æ··ä¹±çš„éƒ¨åˆ†

### 3. ä¸Šä¸‹æ–‡é€»è¾‘é—®é¢˜
- è¯†åˆ«å‰åæ–‡é€»è¾‘ä¸ä¸€è‡´çš„åœ°æ–¹
- æ ‡æ³¨å¯èƒ½çš„è¯´è¯äººæ ‡è®°é”™è¯¯
- æŒ‡å‡ºæ˜æ˜¾ä¸ç¬¦åˆè¯­å¢ƒçš„å†…å®¹

### 4. æ ¼å¼å’Œç»“æ„é—®é¢˜
- æ£€æŸ¥æ®µè½åˆ’åˆ†æ˜¯å¦åˆç†
- ç¡®è®¤è¯´è¯äººæ ‡è®°çš„ä¸€è‡´æ€§
- éªŒè¯æ—¶é—´æ ‡è®°çš„å‡†ç¡®æ€§ï¼ˆå¦‚æœ‰ï¼‰

## ç¬¬äºŒéƒ¨åˆ†ï¼šä¼˜åŒ–åè½¬å½•æ–‡æœ¬

åŸºäºä¸Šè¿°åˆ†æï¼Œè¯·æä¾›ä¼˜åŒ–åçš„å®Œæ•´è½¬å½•æ–‡æœ¬ã€‚ä¼˜åŒ–æ—¶è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

### ä¼˜åŒ–åŸåˆ™ï¼š
1. **å‡†ç¡®æ€§ä¼˜å…ˆ**ï¼šä¿æŒåŸæ„ä¸å˜ï¼Œä»…ä¿®æ­£æ˜æ˜¾é”™è¯¯
2. **å¯è¯»æ€§æå‡**ï¼šæ”¹å–„è¯­è¨€æµç•…æ€§ï¼Œä½†ä¸æ”¹å˜è¯´è¯é£æ ¼
3. **ä¸“ä¸šæ€§ä¿è¯**ï¼šç¡®ä¿ä¸“ä¸šæœ¯è¯­ä½¿ç”¨å‡†ç¡®
4. **æ ¼å¼è§„èŒƒåŒ–**ï¼šç»Ÿä¸€è¯´è¯äººæ ‡è®°æ ¼å¼ï¼Œåˆç†åˆ’åˆ†æ®µè½

### ç‰¹åˆ«æ³¨æ„ï¼š
- ä¿ç•™è¯´è¯äººçš„è¯­è¨€ç‰¹è‰²å’Œè¡¨è¾¾ä¹ æƒ¯
- ä¸è¦è¿‡åº¦ä¿®é¥°æˆ–æ”¹å˜åŸå§‹è¡¨è¾¾çš„è¯­æ°”
- ä¿æŒå•†åŠ¡å¯¹è¯çš„ä¸“ä¸šæ€§
- å¦‚æœ‰å¤šä¸ªè¯´è¯äººï¼Œç¡®ä¿å¯¹è¯çš„è¿è´¯æ€§

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„è½¬å½•æ–‡æœ¬ï¼Œä¿æŒåŸæœ‰çš„è¯´è¯äººæ ‡è®°æ ¼å¼ã€‚

--- File: prompts/transcription/single_speaker.md ---
è¯·å‡†ç¡®è½¬å½•è¿™æ®µéŸ³é¢‘å†…å®¹ã€‚

è¦æ±‚ï¼š
1. å®Œæ•´ä¿ç•™æ‰€æœ‰å†…å®¹
2. é€‚å½“æ·»åŠ æ ‡ç‚¹ç¬¦å·
3. ä¿æŒåŸå§‹è¯­è¨€é£æ ¼
4. ä¸æ¸…æ™°éƒ¨åˆ†ç”¨[å¬ä¸æ¸…]æ ‡è®°

è¯·ç›´æ¥è¾“å‡ºè½¬å½•ç»“æœã€‚

--- File: README.md ---
<div align="center">
  <img src="assets/images/logo.png" alt="SmartProposal Engine Logo" width="150"/>
  <h1>SmartProposal Engine</h1>
  <p><strong>ä¸€ä¸ªç”± AI é©±åŠ¨çš„æ™ºèƒ½å•†ä¸šæ–¹æ¡ˆç”Ÿæˆå¼•æ“ï¼Œèƒ½å°†åŸå§‹ä¼šè®®å½•éŸ³ã€è®¿è°ˆçºªè¦ç­‰ä¿¡æ¯ï¼Œä¸€é”®è½¬åŒ–ä¸ºç»“æ„æ¸…æ™°ã€å†…å®¹ä¸“ä¸šçš„å•†ä¸šææ¡ˆã€‚</strong></p>
  
  <p>
    <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python Version">
    <img src="https://img.shields.io/badge/Streamlit-1.35+-orange.svg" alt="Streamlit Version">
    <img src="https://img.shields.io/badge/AI_Engine-Google_Gemini-purple.svg" alt="AI Engine">
    <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
    <img src="https://img.shields.io/badge/Project_Status-MVP-informational.svg" alt="Project Status">
  </p>
</div>

---

**SmartProposal Engine** æ—¨åœ¨è§£å†³å•†ä¸šå’¨è¯¢ã€é”€å”®å’Œé¡¹ç›®ç®¡ç†ä¸­çš„æ ¸å¿ƒç—›ç‚¹ï¼šå°†å¤§é‡é›¶æ•£ã€éç»“æ„åŒ–çš„ä¿¡æ¯ï¼ˆå¦‚å®¢æˆ·è®¿è°ˆã€å•†åŠ¡è°ˆåˆ¤å½•éŸ³ã€å†…éƒ¨ä¼šè®®çºªè¦ï¼‰é«˜æ•ˆåœ°è½¬åŒ–ä¸ºé«˜è´¨é‡ã€ä¸“ä¸šåŒ–çš„å•†ä¸šæ–‡æ¡£ã€‚å€ŸåŠ© Google Gemini å¼ºå¤§çš„å¤šæ¨¡æ€å’Œé•¿æ–‡æœ¬ç†è§£èƒ½åŠ›ï¼Œæœ¬å·¥å…·å®ç°äº†ä»ä¿¡æ¯è¾“å…¥åˆ°æ–¹æ¡ˆè¾“å‡ºçš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€‚

### ç›®å½•
- [âœ¨ åŠŸèƒ½äº®ç‚¹](#-åŠŸèƒ½äº®ç‚¹)
- [ğŸš€ æ•ˆæœæ¼”ç¤º](#-æ•ˆæœæ¼”ç¤º)
- [ğŸ› ï¸ æŠ€æœ¯æ ˆ](#ï¸-æŠ€æœ¯æ ˆ)
- [ğŸ—ï¸ ç³»ç»Ÿæ¶æ„](#ï¸-ç³»ç»Ÿæ¶æ„)
- [âš™ï¸ å®‰è£…ä¸é…ç½®](#ï¸-å®‰è£…ä¸é…ç½®)
- [â–¶ï¸ å¿«é€Ÿå¼€å§‹](#ï¸-å¿«é€Ÿå¼€å§‹)
- [ğŸ”§ æ ¸å¿ƒé…ç½®](#ï¸-æ ¸å¿ƒé…ç½®)
- [ğŸ—ºï¸ æœªæ¥è·¯çº¿å›¾](#ï¸-æœªæ¥è·¯çº¿å›¾)
- [ğŸ¤ è´¡çŒ®æŒ‡å—](#ï¸-è´¡çŒ®æŒ‡å—)
- [ğŸ“œ è®¸å¯è¯](#ï¸-è®¸å¯è¯)

### âœ¨ åŠŸèƒ½äº®ç‚¹

* **ğŸ™ï¸ æ™ºèƒ½éŸ³é¢‘/æ–‡æ¡£å¤„ç†**:
    * æ”¯æŒå¤šç§ä¸»æµéŸ³é¢‘æ ¼å¼ (`m4a`, `mp3`, `wav` ç­‰) å’Œæ–‡æ¡£æ ¼å¼ (`docx`, `pdf`, `txt` ç­‰)ã€‚
    * åˆ©ç”¨ Gemini API å¯¹é•¿éŸ³é¢‘è¿›è¡Œé«˜ç²¾åº¦è½¬å½•ï¼Œå¹¶è‡ªåŠ¨è¯†åˆ«ä¸åŒè¯´è¯äººã€‚
    * å¯é€‰çš„ AI æ–‡æœ¬ä¼˜åŒ–åŠŸèƒ½ï¼Œæå‡è½¬å½•ç¨¿çš„å¯è¯»æ€§å’Œä¸“ä¸šæ€§ã€‚

* **ğŸ§  åŸºäºåœºæ™¯çš„æ·±åº¦åˆ†æ**:
    * å†…ç½®å¤šç§ä¸“ä¸šåˆ†ææ¨¡æ¿ï¼Œè¦†ç›–å®¢æˆ·è®¿-è°ˆã€å•†åŠ¡è°ˆåˆ¤ã€å†…éƒ¨ä¼šè®®ç­‰æ ¸å¿ƒå•†ä¸šåœºæ™¯ã€‚
    * é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ Promptsï¼Œä»æµ·é‡æ–‡æœ¬ä¸­æå–å…³é”®å•†ä¸šæ´å¯Ÿã€å†³ç­–è¦ç‚¹å’Œè¡ŒåŠ¨é¡¹ã€‚
    * æ”¯æŒç”¨æˆ·æä¾›è‡ªå®šä¹‰åˆ†ææ¨¡æ¿ï¼Œæ»¡è¶³ä¸ªæ€§åŒ–éœ€æ±‚ã€‚

* **âœï¸ å®šåˆ¶åŒ–æ–¹æ¡ˆç”Ÿæˆ**:
    * ä¸€é”®ç”Ÿæˆç»“æ„å®Œæ•´ã€é€»è¾‘æ¸…æ™°çš„å•†ä¸šæ–‡æ¡£ï¼Œå¦‚é¡¹ç›®å»ºè®®ä¹¦ã€å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆã€è§£å†³æ–¹æ¡ˆç®€æŠ¥ç­‰ã€‚
    * èƒ½å¤Ÿæ™ºèƒ½èåˆç”¨æˆ·ä¸Šä¼ çš„â€œä¼ä¸šèƒ½åŠ›æ–‡æ¡£â€ï¼ˆå¦‚å…¬å¸ä»‹ç»ã€æˆåŠŸæ¡ˆä¾‹ï¼‰ï¼Œæå¤§å¢å¼ºç”Ÿæˆæ–¹æ¡ˆçš„é’ˆå¯¹æ€§å’Œè¯´æœåŠ›ã€‚
    * æ”¯æŒå®¢æˆ·ä¿¡æ¯æ³¨å…¥ï¼Œå®ç°æ–¹æ¡ˆçš„ä¸ªæ€§åŒ–å®šåˆ¶ã€‚

* **âš¡ ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–å·¥ä½œæµ**:
    * æä¾›â€œä¸€é”®ç”Ÿæˆâ€æ¨¡å¼ï¼Œæ”¯æŒæ‰¹é‡æ–‡ä»¶å¤„ç†ï¼Œå®ç°ä»åŸå§‹è¾“å…¥åˆ°æœ€ç»ˆæ–¹æ¡ˆçš„æ— äººå¹²é¢„å…¨æµç¨‹è‡ªåŠ¨åŒ–ã€‚
    * æ¸…æ™°çš„è¿›åº¦è·Ÿè¸ªå’Œç»“æœæ±‡æ€»ï¼Œä¾¿äºç®¡ç†å’Œå¤ç›˜ã€‚
    * æ¨¡å—åŒ–çš„æœåŠ¡è®¾è®¡ï¼Œä¿è¯äº†ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§ã€‚

### ğŸš€ æ•ˆæœæ¼”ç¤º

**(å»ºè®®æ‚¨åœ¨æ­¤å¤„æ›¿æ¢ä¸ºåº”ç”¨çš„å®é™…æˆªå›¾)**

**1. ä¸€é”®å¤„ç†é¡µé¢ - é…ç½®å·¥ä½œæµ**
*ï¼ˆæ­¤å¤„å¯ä»¥æ”¾ `4_??_One_Click_Generation.py` é¡µé¢çš„æˆªå›¾ï¼‰*
![One Click Generation Screenshot](https://via.placeholder.com/800x450.png?text=Screenshot+of+One-Click+Generation+Page)

**2. æ·±åº¦åˆ†æç»“æœå±•ç¤º**
*ï¼ˆæ­¤å¤„å¯ä»¥æ”¾ `2_??_Deep_Analysis.py` é¡µé¢ç”Ÿæˆç»“æœçš„æˆªå›¾ï¼‰*
![Analysis Result Screenshot](https://via.placeholder.com/800x450.png?text=Screenshot+of+Deep+Analysis+Result)

**3. æœ€ç»ˆç”Ÿæˆçš„é¡¹ç›®å»ºè®®ä¹¦**
*ï¼ˆæ­¤å¤„å¯ä»¥æ”¾ `3_??_Proposal_Generation.py` é¡µé¢ç”Ÿæˆæ–¹æ¡ˆçš„æˆªå›¾ï¼‰*
![Proposal Result Screenshot](https://via.placeholder.com/800x450.png?text=Screenshot+of+Generated+Proposal)


### ğŸ› ï¸ æŠ€æœ¯æ ˆ

* **å‰ç«¯æ¡†æ¶**: [Streamlit](https://streamlit.io/)
* **AI æ ¸å¿ƒ**: [Google Gemini API (2.5-Pro, 2.5-Flash)](https://ai.google.dev/)
* **å¼€å‘è¯­è¨€**: Python 3.8+
* **æ–‡æ¡£å¤„ç†**: `python-docx`, `PyPDF2`
* **éŸ³é¢‘å¤„ç†**: `pydub` (ç”¨äºåˆ†å‰²), Google AI Platform (ç”¨äºè½¬å½•)
* **æ ¸å¿ƒä¾èµ–**: `google-generativeai`, `streamlit`

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

é¡¹ç›®é‡‡ç”¨äº†æ¸…æ™°çš„ã€é¢å‘æœåŠ¡çš„æ¶æ„ï¼Œå°†ä¸åŒèŒè´£è¿›è¡Œäº†è§£è€¦ã€‚

--- File: readme_file.md ---
# SmartProposal Engine ğŸ“‹

SmartProposal Engineæ˜¯ä¸€ä¸ªåŸºäºAIçš„æ™ºèƒ½å•†ä¸šæ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿï¼Œèƒ½å¤Ÿè‡ªåŠ¨å°†åŸå§‹ä¿¡æ¯ï¼ˆéŸ³é¢‘å½•éŸ³ã€æ–‡æ¡£ç­‰ï¼‰è½¬åŒ–ä¸ºä¸“ä¸šçš„å•†ä¸šææ¡ˆå’Œé¡¹ç›®å»ºè®®ä¹¦ã€‚

## ğŸŒŸ æ ¸å¿ƒåŠŸèƒ½

### 1. **æ™ºèƒ½è½¬å½•** ğŸ™ï¸
- æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼ï¼ˆm4a, mp3, wavç­‰ï¼‰
- è‡ªåŠ¨è¯†åˆ«å¤šè¯´è¯äººå¯¹è¯
- æ”¯æŒè¶…é•¿éŸ³é¢‘è‡ªåŠ¨åˆ†å‰²å¤„ç†
- å¯é€‰çš„AIæ–‡æœ¬ä¼˜åŒ–åŠŸèƒ½

### 2. **æ·±åº¦åˆ†æ** ğŸ”
- å¤šç§é¢„è®¾åˆ†ææ¨¡æ¿ï¼ˆå®¢æˆ·è®¿è°ˆã€å•†åŠ¡è°ˆåˆ¤ã€å†…éƒ¨ä¼šè®®ç­‰ï¼‰
- æ™ºèƒ½æå–å…³é”®ä¿¡æ¯å’Œå•†ä¸šæ´å¯Ÿ
- è‡ªåŠ¨ç”Ÿæˆæ‰§è¡Œæ‘˜è¦å’Œè¡ŒåŠ¨å»ºè®®
- æ”¯æŒè‡ªå®šä¹‰åˆ†ææ¨¡æ¿

### 3. **æ–¹æ¡ˆç”Ÿæˆ** ğŸ“‹
- è‡ªåŠ¨ç”Ÿæˆä¸“ä¸šçš„é¡¹ç›®å»ºè®®ä¹¦
- æ”¯æŒå¤šç§æ–¹æ¡ˆç±»å‹ï¼ˆé¡¹ç›®å»ºè®®ä¹¦ã€å•†åŠ¡æŠ¥ä»·ã€è§£å†³æ–¹æ¡ˆç®€æŠ¥ç­‰ï¼‰
- æ•´åˆä¼ä¸šèƒ½åŠ›æ–‡æ¡£ï¼Œå¢å¼ºæ–¹æ¡ˆè¯´æœåŠ›
- å®¢æˆ·ä¿¡æ¯ä¸ªæ€§åŒ–å®šåˆ¶

### 4. **ä¸€é”®å¤„ç†** ğŸš€
- ç«¯åˆ°ç«¯çš„è‡ªåŠ¨åŒ–å¤„ç†æµç¨‹
- æ‰¹é‡æ–‡ä»¶å¤„ç†èƒ½åŠ›
- å®æ—¶è¿›åº¦è·Ÿè¸ª
- ç»“æœæ‰¹é‡å¯¼å‡º

## ğŸ› ï¸ æŠ€æœ¯æ¶æ„

### æ ¸å¿ƒæŠ€æœ¯æ ˆ
- **å‰ç«¯æ¡†æ¶**: Streamlit
- **AIå¼•æ“**: Google Gemini API (æ”¯æŒ2.5-proå’Œ2.5-flash)
- **æ–‡æ¡£å¤„ç†**: python-docx, PyPDF2
- **éŸ³é¢‘å¤„ç†**: pydub, Google Speech-to-Text
- **å¼€å‘è¯­è¨€**: Python 3.8+

### é¡¹ç›®ç»“æ„
```
smart_proposal_engine/
â”œâ”€â”€ app.py                    # ä¸»åº”ç”¨å…¥å£
â”œâ”€â”€ pages/                    # Streamlité¡µé¢
â”‚   â”œâ”€â”€ 1_ğŸ“„_Input_Processing.py
â”‚   â”œâ”€â”€ 2_ğŸ”_Deep_Analysis.py
â”‚   â”œâ”€â”€ 3_ğŸ“‹_Proposal_Generation.py
â”‚   â””â”€â”€ 4_ğŸš€_One_Click_Generation.py
â”œâ”€â”€ services/                 # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”œâ”€â”€ transcription_service.py
â”‚   â”œâ”€â”€ analysis_service.py
â”‚   â””â”€â”€ proposal_service.py
â”œâ”€â”€ core/                     # æ ¸å¿ƒç»„ä»¶
â”‚   â”œâ”€â”€ prompt_manager.py
â”‚   â”œâ”€â”€ model_interface.py
â”‚   â””â”€â”€ session_manager.py
â”œâ”€â”€ prompts/                  # AIæç¤ºè¯æ¨¡æ¿
â”œâ”€â”€ utils/                    # å·¥å…·å‡½æ•°
â””â”€â”€ requirements.txt          # é¡¹ç›®ä¾èµ–
```

## ğŸ“¦ å®‰è£…æŒ‡å—

### å‰ç½®è¦æ±‚
- Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬
- Google Gemini APIå¯†é’¥
- FFmpegï¼ˆç”¨äºéŸ³é¢‘å¤„ç†ï¼‰

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®ä»“åº“**
```bash
git clone https://github.com/smartproposal/engine.git
cd smart_proposal_engine
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

4. **å®‰è£…FFmpeg**
- Windows: ä» [FFmpegå®˜ç½‘](https://ffmpeg.org/download.html) ä¸‹è½½å¹¶æ·»åŠ åˆ°PATH
- macOS: `brew install ffmpeg`
- Ubuntu/Debian: `sudo apt-get install ffmpeg`

5. **é…ç½®APIå¯†é’¥**

åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œæ·»åŠ æ‚¨çš„Google APIå¯†é’¥ï¼š
```
GOOGLE_API_KEY=your_api_key_here
```

æˆ–è€…ï¼Œæ‚¨å¯ä»¥åœ¨ `app_config.ini` ä¸­é…ç½®ä½¿ç”¨å†…éƒ¨å¯†é’¥æ–‡ä»¶ï¼š
```ini
[API_SETTINGS]
use_internal_api_key = true
api_key_file = api_key.txt
```

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å¯åŠ¨åº”ç”¨
```bash
streamlit run app.py
```

åº”ç”¨å°†åœ¨é»˜è®¤æµè§ˆå™¨ä¸­æ‰“å¼€ï¼Œé€šå¸¸åœ°å€ä¸º `http://localhost:8501`

### åŠŸèƒ½ä½¿ç”¨æµç¨‹

#### 1. å†…å®¹è¾“å…¥å¤„ç†
- ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶æˆ–æ–‡æ¡£
- é€‰æ‹©å¤„ç†é€‰é¡¹ï¼ˆè¯´è¯äººè¯†åˆ«ã€æ–‡æœ¬ä¼˜åŒ–ç­‰ï¼‰
- è·å–è½¬å½•æˆ–æå–çš„æ–‡æœ¬å†…å®¹

#### 2. æ·±åº¦åˆ†æ
- é€‰æ‹©æˆ–ä¸Šä¼ åˆ†æå†…å®¹
- é€‰æ‹©åˆé€‚çš„åˆ†ææ¨¡æ¿
- è·å–ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š

#### 3. æ–¹æ¡ˆç”Ÿæˆ
- ä¸Šä¼ åˆ†ææŠ¥å‘Š
- ä¸Šä¼ ä¼ä¸šèƒ½åŠ›æ–‡æ¡£ï¼ˆå¯é€‰ï¼‰
- é…ç½®æ–¹æ¡ˆå‚æ•°å’Œå®¢æˆ·ä¿¡æ¯
- ç”Ÿæˆä¸“ä¸šçš„å•†ä¸šæ–¹æ¡ˆ

#### 4. ä¸€é”®ç”Ÿæˆï¼ˆæ¨èï¼‰
- æ‰¹é‡ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶
- ä¸€æ¬¡æ€§é…ç½®æ‰€æœ‰å‚æ•°
- è‡ªåŠ¨å®Œæˆå…¨æµç¨‹å¤„ç†
- æ‰¹é‡ä¸‹è½½æ‰€æœ‰ç»“æœ

### é…ç½®è¯´æ˜

ä¸»è¦é…ç½®æ–‡ä»¶ `app_config.ini`ï¼š

```ini
[MODEL_SETTINGS]
# ä¸åŒä»»åŠ¡ä½¿ç”¨çš„æ¨¡å‹
transcription_model = models/gemini-2.5-flash
analysis_model = models/gemini-2.5-pro
proposal_model = models/gemini-2.5-pro

[FILE_SETTINGS]
# æ–‡ä»¶å¤§å°å’Œæ ¼å¼é™åˆ¶
max_file_size_mb = 200
allowed_audio_formats = m4a,mp3,wav,aac,ogg,flac
allowed_document_formats = docx,pdf,txt

[FEATURE_SETTINGS]
# åŠŸèƒ½å¼€å…³
enable_deep_analysis = true
enable_proposal_generation = true
enable_custom_prompts = true
```

## ğŸ“Š ä½¿ç”¨åœºæ™¯

### 1. å®¢æˆ·éœ€æ±‚åˆ†æ
- ä¸Šä¼ å®¢æˆ·è®¿è°ˆå½•éŸ³
- è‡ªåŠ¨æå–éœ€æ±‚ç‚¹å’Œç—›ç‚¹
- ç”Ÿæˆé’ˆå¯¹æ€§çš„é¡¹ç›®å»ºè®®ä¹¦

### 2. å•†åŠ¡è°ˆåˆ¤æ”¯æŒ
- å¤„ç†è°ˆåˆ¤å½•éŸ³æˆ–è®°å½•
- åˆ†æå„æ–¹ç«‹åœºå’Œæ¡æ¬¾
- ç”Ÿæˆè°ˆåˆ¤ç­–ç•¥å’ŒæŠ¥ä»·æ–¹æ¡ˆ

### 3. å†…éƒ¨ä¼šè®®æ•´ç†
- è½¬å½•ä¼šè®®å½•éŸ³
- æå–å†³ç­–è¦ç‚¹å’Œè¡ŒåŠ¨é¡¹
- ç”Ÿæˆä¼šè®®çºªè¦å’Œæ‰§è¡Œè®¡åˆ’

### 4. æ‰¹é‡æ–¹æ¡ˆåˆ¶ä½œ
- æ‰¹é‡å¤„ç†å¤šä¸ªå®¢æˆ·èµ„æ–™
- ç»Ÿä¸€ç”Ÿæˆå®šåˆ¶åŒ–æ–¹æ¡ˆ
- å¤§å¹…æå‡å·¥ä½œæ•ˆç‡

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
1. åœ¨ `prompts/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æ¨¡æ¿æ–‡ä»¶
2. ä½¿ç”¨Markdownæ ¼å¼ç¼–å†™æ¨¡æ¿
3. åœ¨æ¨¡æ¿ä¸­ä½¿ç”¨å˜é‡å ä½ç¬¦ï¼ˆå¦‚ `{transcript}`ï¼‰

### æ‰¹å¤„ç†API
```python
from services.document_service import DocumentService
from services.analysis_service import DeepAnalysisService

# æ‰¹é‡å¤„ç†æ–‡æ¡£
doc_service = DocumentService()
results = doc_service.batch_process_documents(file_paths)

# æ‰¹é‡åˆ†æ
analysis_service = DeepAnalysisService()
analyses = analysis_service.batch_analyze(documents, template='customer_interview')
```

### æ‰©å±•å¼€å‘
ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ‰©å±•ï¼š
- æ–°å¢æœåŠ¡ï¼šç»§æ‰¿ `BaseService` ç±»
- æ–°å¢æ¨¡æ¿ï¼šåœ¨ç›¸åº”ç›®å½•æ·»åŠ æ¨¡æ¿æ–‡ä»¶
- æ–°å¢é¡µé¢ï¼šåœ¨ `pages/` ç›®å½•åˆ›å»ºæ–°é¡µé¢

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **APIè°ƒç”¨ä¼˜åŒ–**
   - ä½¿ç”¨æ‰¹é‡å¤„ç†å‡å°‘APIè°ƒç”¨æ¬¡æ•°
   - åˆç†è®¾ç½®å¹¶å‘æ•°é¿å…é™æµ
   - å¯ç”¨ç»“æœç¼“å­˜å‡å°‘é‡å¤å¤„ç†

2. **æ–‡ä»¶å¤„ç†ä¼˜åŒ–**
   - å¤§æ–‡ä»¶è‡ªåŠ¨åˆ†ç‰‡å¤„ç†
   - ä½¿ç”¨æµå¼å¤„ç†å‡å°‘å†…å­˜å ç”¨
   - å®šæœŸæ¸…ç†ä¸´æ—¶æ–‡ä»¶

3. **æ¨¡å‹é€‰æ‹©ä¼˜åŒ–**
   - è½¬å½•ä»»åŠ¡ä½¿ç”¨Flashæ¨¡å‹èŠ‚çœæˆæœ¬
   - å¤æ‚åˆ†æä½¿ç”¨Proæ¨¡å‹ä¿è¯è´¨é‡
   - æ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æ¨¡å‹

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

1. Fork é¡¹ç›®ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. åˆ›å»º Pull Request

## ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## ğŸ™ è‡´è°¢

- Google Geminiå›¢é˜Ÿæä¾›çš„å¼ºå¤§AIèƒ½åŠ›
- Streamlitç¤¾åŒºçš„ä¼˜ç§€æ¡†æ¶
- æ‰€æœ‰è´¡çŒ®è€…å’Œç”¨æˆ·çš„æ”¯æŒ

## ğŸ“ è”ç³»æ–¹å¼

- é¡¹ç›®ä¸»é¡µ: [https://github.com/smartproposal/engine](https://github.com/smartproposal/engine)
- é—®é¢˜åé¦ˆ: [Issues](https://github.com/smartproposal/engine/issues)
- é‚®ç®±: support@smartproposal.ai

---

**SmartProposal Engine** - è®©å•†ä¸šæ–¹æ¡ˆåˆ¶ä½œæ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆï¼ ğŸš€

--- File: run_app.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/run_app.py
åŠŸèƒ½è¯´æ˜: SmartProposal Engineå¯åŠ¨è„šæœ¬ï¼Œæ”¯æŒåœ¨PyCharmä¸­ç›´æ¥è¿è¡Œ
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import subprocess
import socket
import webbrowser
import time
import argparse
import json
import configparser
from pathlib import Path
from typing import Optional, Dict, Any
import streamlit.web.cli as stcli


def check_port_available(port: int) -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(('', port))
            return True
        except socket.error:
            return False


def find_available_port(start_port: int = 8501, max_attempts: int = 10) -> Optional[int]:
    """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
    for i in range(max_attempts):
        port = start_port + i
        if check_port_available(port):
            return port
    return None


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    missing_deps = []
    
    # æ£€æŸ¥æ ¸å¿ƒä¾èµ–
    try:
        import streamlit
    except ImportError:
        missing_deps.append("streamlit")
    
    try:
        import google.generativeai
    except ImportError:
        missing_deps.append("google-generativeai")
    
    try:
        import docx
    except ImportError:
        missing_deps.append("python-docx")
    
    try:
        import PyPDF2
    except ImportError:
        missing_deps.append("PyPDF2")
    
    if missing_deps:
        print("âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åŒ…:")
        for dep in missing_deps:
            print(f"   - {dep}")
        print("\nè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–:")
        print("   pip install -r requirements.txt")
        return False
    
    return True


def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    warnings = []
    
    # æ£€æŸ¥APIå¯†é’¥é…ç½®
    api_key_from_env = os.getenv('GOOGLE_API_KEY')
    api_key_file = Path('api_key.txt')
    
    if not api_key_from_env and not api_key_file.exists():
        warnings.append("""
âš ï¸  æœªæ‰¾åˆ°Google APIå¯†é’¥é…ç½®
   è¯·ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€é…ç½®APIå¯†é’¥:
   1. è®¾ç½®ç¯å¢ƒå˜é‡: export GOOGLE_API_KEY=your_key
   2. åˆ›å»º.envæ–‡ä»¶å¹¶æ·»åŠ : GOOGLE_API_KEY=your_key
   3. åˆ›å»ºapi_key.txtæ–‡ä»¶å¹¶å†™å…¥å¯†é’¥
        """)
    
    # æ£€æŸ¥å¿…è¦çš„ç›®å½•
    required_dirs = ['temp', 'output', 'prompts']
    for dir_name in required_dirs:
        dir_path = Path(dir_name)
        if not dir_path.exists():
            try:
                dir_path.mkdir(parents=True, exist_ok=True)
                print(f"âœ… åˆ›å»ºç›®å½•: {dir_name}/")
            except Exception as e:
                warnings.append(f"âš ï¸  æ— æ³•åˆ›å»ºç›®å½• {dir_name}: {e}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not Path('app_config.ini').exists():
        warnings.append("âš ï¸  æœªæ‰¾åˆ°app_config.inié…ç½®æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
    
    # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
    if warnings:
        print("\n" + "="*50)
        print("ç¯å¢ƒæ£€æŸ¥è­¦å‘Š:")
        for warning in warnings:
            print(warning)
        print("="*50 + "\n")
    
    return True  # å³ä½¿æœ‰è­¦å‘Šä¹Ÿç»§ç»­è¿è¡Œ


def load_env_file():
    """åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡"""
    env_file = Path('.env')
    if env_file.exists():
        try:
            from dotenv import load_dotenv
            load_dotenv()
            print("âœ… å·²åŠ è½½.envæ–‡ä»¶")
        except ImportError:
            print("â„¹ï¸  python-dotenvæœªå®‰è£…ï¼Œè·³è¿‡.envæ–‡ä»¶åŠ è½½")


def load_run_config() -> Dict[str, Any]:
    """åŠ è½½è¿è¡Œé…ç½®æ–‡ä»¶"""
    config = {
        'port': 8501,
        'host': 'localhost',
        'open_browser': True,
        'debug': False,
        'subprocess': False,
        'env_vars': {}
    }
    
    # å°è¯•å¤šç§é…ç½®æ–‡ä»¶æ ¼å¼
    config_files = ['run_config.json', 'run_config.ini', 'run_config.conf']
    
    for config_file in config_files:
        config_path = Path(config_file)
        if config_path.exists():
            print(f"ğŸ“„ æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file}")
            
            if config_file.endswith('.json'):
                # åŠ è½½JSONé…ç½®
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        file_config = json.load(f)
                        config.update(file_config)
                        print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
                        break
                except Exception as e:
                    print(f"âš ï¸  åŠ è½½JSONé…ç½®å¤±è´¥: {e}")
                    
            elif config_file.endswith(('.ini', '.conf')):
                # åŠ è½½INIé…ç½®
                try:
                    parser = configparser.ConfigParser()
                    parser.read(config_path, encoding='utf-8')
                    
                    if 'server' in parser:
                        server_config = parser['server']
                        config['port'] = server_config.getint('port', config['port'])
                        config['host'] = server_config.get('host', config['host'])
                        config['open_browser'] = server_config.getboolean('open_browser', config['open_browser'])
                        config['debug'] = server_config.getboolean('debug', config['debug'])
                        config['subprocess'] = server_config.getboolean('subprocess', config['subprocess'])
                    
                    if 'environment' in parser:
                        config['env_vars'] = dict(parser['environment'])
                    
                    print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
                    break
                except Exception as e:
                    print(f"âš ï¸  åŠ è½½INIé…ç½®å¤±è´¥: {e}")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    for key, value in config.get('env_vars', {}).items():
        os.environ[key] = str(value)
        print(f"   è®¾ç½®ç¯å¢ƒå˜é‡: {key}")
    
    return config


def run_streamlit_app(port: int = 8501, 
                     host: str = "localhost",
                     open_browser: bool = True,
                     debug: bool = False):
    """è¿è¡ŒStreamlitåº”ç”¨"""
    
    # è®¾ç½®Streamlité…ç½®
    os.environ['STREAMLIT_SERVER_PORT'] = str(port)
    os.environ['STREAMLIT_SERVER_ADDRESS'] = host
    
    if debug:
        os.environ['STREAMLIT_SERVER_RUN_ON_SAVE'] = 'true'
        os.environ['STREAMLIT_SERVER_FILE_WATCHER_TYPE'] = 'auto'
    
    # æ„å»ºå¯åŠ¨å‚æ•°
    sys.argv = [
        "streamlit",
        "run",
        "app.py",
        f"--server.port={port}",
        f"--server.address={host}",
    ]
    
    if not open_browser:
        sys.argv.append("--server.headless=true")
    
    if debug:
        sys.argv.extend([
            "--server.runOnSave=true",
            "--server.fileWatcherType=auto",
            "--logger.level=info"
        ])
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         SmartProposal Engine æ­£åœ¨å¯åŠ¨...             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  è®¿é—®åœ°å€: http://{host}:{port}                      â•‘
â•‘  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # å¯åŠ¨Streamlit
    sys.exit(stcli.main())


def run_with_subprocess(port: int = 8501, 
                       host: str = "localhost",
                       open_browser: bool = True,
                       debug: bool = False):
    """ä½¿ç”¨å­è¿›ç¨‹è¿è¡ŒStreamlitï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
    cmd = [
        sys.executable, "-m", "streamlit", "run", "app.py",
        f"--server.port={port}",
        f"--server.address={host}",
    ]
    
    if not open_browser:
        cmd.append("--server.headless=true")
    
    if debug:
        cmd.extend([
            "--server.runOnSave=true",
            "--server.fileWatcherType=auto",
            "--logger.level=info"
        ])
    
    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         SmartProposal Engine æ­£åœ¨å¯åŠ¨...             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  è®¿é—®åœ°å€: http://{host}:{port}                      â•‘
â•‘  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åœ¨æ–°çª—å£ä¸­æ‰“å¼€æµè§ˆå™¨
    if open_browser:
        time.sleep(2)  # ç­‰å¾…æœåŠ¡å¯åŠ¨
        webbrowser.open(f"http://{host}:{port}")
    
    # å¯åŠ¨å­è¿›ç¨‹
    try:
        subprocess.run(cmd)
    except KeyboardInterrupt:
        print("\nâœ… æœåŠ¡å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='SmartProposal Engine å¯åŠ¨è„šæœ¬')
    parser.add_argument('--port', type=int, default=8501, help='æœåŠ¡ç«¯å£ (é»˜è®¤: 8501)')
    parser.add_argument('--host', type=str, default='localhost', help='æœåŠ¡åœ°å€ (é»˜è®¤: localhost)')
    parser.add_argument('--no-browser', action='store_true', help='ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨')
    parser.add_argument('--debug', action='store_true', help='è°ƒè¯•æ¨¡å¼')
    parser.add_argument('--subprocess', action='store_true', help='ä½¿ç”¨å­è¿›ç¨‹æ¨¡å¼è¿è¡Œ')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºå¯åŠ¨æ¨ªå¹…
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                           â•‘
    â•‘            ğŸš€ SmartProposal Engine v1.0.0 ğŸš€             â•‘
    â•‘                                                           â•‘
    â•‘         æ™ºèƒ½å•†ä¸šæ–¹æ¡ˆç”Ÿæˆç³»ç»Ÿ - MVP Edition                â•‘
    â•‘                                                           â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_env_file()
    
    # æ£€æŸ¥ä¾èµ–
    print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
    if not check_dependencies():
        print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–åŒ…")
        sys.exit(1)
    print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
    
    # æ£€æŸ¥ç¯å¢ƒ
    print("\nğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    check_environment()
    
    # æ£€æŸ¥ç«¯å£
    if not check_port_available(args.port):
        print(f"\nâš ï¸  ç«¯å£ {args.port} å·²è¢«å ç”¨ï¼Œæ­£åœ¨æŸ¥æ‰¾å¯ç”¨ç«¯å£...")
        available_port = find_available_port(args.port)
        if available_port:
            args.port = available_port
            print(f"âœ… ä½¿ç”¨ç«¯å£: {available_port}")
        else:
            print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šç«¯å£")
            sys.exit(1)
    
    # å¯åŠ¨åº”ç”¨
    try:
        if args.subprocess:
            # ä½¿ç”¨å­è¿›ç¨‹æ¨¡å¼
            run_with_subprocess(
                port=args.port,
                host=args.host,
                open_browser=not args.no_browser,
                debug=args.debug
            )
        else:
            # ä½¿ç”¨é»˜è®¤æ¨¡å¼
            run_streamlit_app(
                port=args.port,
                host=args.host,
                open_browser=not args.no_browser,
                debug=args.debug
            )
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹è¿è¡Œ
    script_dir = Path(__file__).parent
    os.chdir(script_dir)
    
    # è¿è¡Œä¸»å‡½æ•°
    main()

--- File: services/__init__.py ---

--- File: services/analysis_service.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/services/analysis_service.py
åŠŸèƒ½è¯´æ˜: æ·±åº¦åˆ†ææœåŠ¡æ¨¡å—ï¼Œè´Ÿè´£å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œå•†ä¸šæ´å¯Ÿåˆ†æ
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import time
from typing import Dict, List, Optional, Tuple, Union
from datetime import datetime
from pathlib import Path

import google.generativeai as genai

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.base_service import BaseService, ProcessingResult
from core.prompt_manager import PromptManager
from core.model_interface import ModelInterface


class DeepAnalysisService(BaseService):
    """
    æ·±åº¦åˆ†ææœåŠ¡ç±»

    ä¸»è¦åŠŸèƒ½:
    - å¯¹è½¬å½•æ–‡æœ¬è¿›è¡Œå•†ä¸šæ´å¯Ÿåˆ†æ
    - æ”¯æŒå¤šç§åˆ†æåœºæ™¯æ¨¡æ¿
    - æ”¯æŒè‡ªå®šä¹‰åˆ†ææ¨¡æ¿
    - ç”Ÿæˆç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Š

    ä½¿ç”¨ç¤ºä¾‹:
        service = DeepAnalysisService()
        result = service.process(transcript_text, template='customer_interview')
    """

    # é¢„å®šä¹‰çš„åˆ†æåœºæ™¯
    ANALYSIS_SCENARIOS = {
        'customer_interview': {
            'name': 'å®¢æˆ·è®¿è°ˆæ·±åº¦åˆ†æ',
            'description': 'é€‚ç”¨äºå®¢æˆ·éœ€æ±‚è®¿è°ˆã€ç”¨æˆ·è°ƒç ”ç­‰åœºæ™¯',
            'focus_areas': ['éœ€æ±‚è¯†åˆ«', 'ç—›ç‚¹åˆ†æ', 'å†³ç­–é“¾è·¯', 'å•†æœºè¯„ä¼°']
        },
        'business_negotiation': {
            'name': 'å•†åŠ¡è°ˆåˆ¤è¦ç‚¹åˆ†æ',
            'description': 'é€‚ç”¨äºå•†åŠ¡æ´½è°ˆã€åˆä½œåå•†ç­‰åœºæ™¯',
            'focus_areas': ['å…³é”®æ¡æ¬¾', 'è°ˆåˆ¤ç«‹åœº', 'åˆ©ç›Šè¯‰æ±‚', 'é£é™©ç‚¹']
        },
        'internal_meeting': {
            'name': 'å†…éƒ¨ä¼šè®®å†³ç­–åˆ†æ',
            'description': 'é€‚ç”¨äºå†…éƒ¨è®¨è®ºã€å†³ç­–ä¼šè®®ç­‰åœºæ™¯',
            'focus_areas': ['å†³ç­–è¦ç‚¹', 'è¡ŒåŠ¨é¡¹', 'è´£ä»»åˆ†é…', 'æ—¶é—´èŠ‚ç‚¹']
        },
        'requirements_gathering': {
            'name': 'éœ€æ±‚æ”¶é›†åˆ†æ',
            'description': 'é€‚ç”¨äºäº§å“éœ€æ±‚æ”¶é›†ã€åŠŸèƒ½è§„åˆ’ç­‰åœºæ™¯',
            'focus_areas': ['åŠŸèƒ½éœ€æ±‚', 'éåŠŸèƒ½éœ€æ±‚', 'ä¼˜å…ˆçº§', 'å®ç°éš¾åº¦']
        },
        'project_review': {
            'name': 'é¡¹ç›®å¤ç›˜åˆ†æ',
            'description': 'é€‚ç”¨äºé¡¹ç›®æ€»ç»“ã€ç»éªŒåˆ†äº«ç­‰åœºæ™¯',
            'focus_areas': ['æˆåŠŸç»éªŒ', 'é—®é¢˜æ•™è®­', 'æ”¹è¿›å»ºè®®', 'æœ€ä½³å®è·µ']
        }
    }

    def __init__(self):
        super().__init__()
        self.prompt_manager = PromptManager()
        self.model_interface = ModelInterface()

    def get_available_templates(self) -> List[str]:
        """è·å–å¯ç”¨çš„åˆ†ææ¨¡æ¿åˆ—è¡¨"""
        # é¢„å®šä¹‰æ¨¡æ¿
        templates = list(self.ANALYSIS_SCENARIOS.keys())

        # æ–‡ä»¶ç³»ç»Ÿä¸­çš„è‡ªå®šä¹‰æ¨¡æ¿
        custom_templates = self.prompt_manager.list_templates('analysis')

        # åˆå¹¶å¹¶å»é‡
        all_templates = list(set(templates + custom_templates))
        return all_templates

    def get_scenario_info(self, scenario: str) -> Dict:
        """è·å–åˆ†æåœºæ™¯çš„è¯¦ç»†ä¿¡æ¯"""
        return self.ANALYSIS_SCENARIOS.get(scenario, {})

    def validate_input(self, input_data: Union[str, Dict]) -> bool:
        """éªŒè¯è¾“å…¥æ•°æ®"""
        if isinstance(input_data, str):
            # éªŒè¯æ–‡æœ¬é•¿åº¦
            if len(input_data.strip()) < 50:
                return False
            return True
        elif isinstance(input_data, dict):
            # éªŒè¯å¿…è¦å­—æ®µ
            return 'transcript' in input_data or 'content' in input_data
        return False

    def process(self,
                input_data: Union[str, Dict],
                template: Optional[str] = 'customer_interview',
                options: Optional[Dict] = None) -> ProcessingResult:
        """
        æ‰§è¡Œæ·±åº¦åˆ†æ

        Args:
            input_data: å¾…åˆ†æçš„æ–‡æœ¬æˆ–åŒ…å«æ–‡æœ¬çš„å­—å…¸
            template: åˆ†ææ¨¡æ¿åç§°
            options: åˆ†æé€‰é¡¹
                - custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
                - additional_context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
                - output_format: è¾“å‡ºæ ¼å¼ ('markdown', 'json')
                - include_recommendations: æ˜¯å¦åŒ…å«å»ºè®®
                - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            ProcessingResult: åˆ†æç»“æœ
        """
        start_time = time.time()
        options = options or {}
        progress_callback = options.get('progress_callback')

        try:
            # æå–æ–‡æœ¬å†…å®¹
            if isinstance(input_data, str):
                transcript = input_data
                metadata = {}
            else:
                transcript = input_data.get('transcript') or input_data.get('content', '')
                metadata = input_data.get('metadata', {})

            if not self.validate_input(transcript):
                raise ValueError("è¾“å…¥æ–‡æœ¬å¤ªçŸ­æˆ–æ ¼å¼ä¸æ­£ç¡®")

            if progress_callback:
                progress_callback("æ­£åœ¨å‡†å¤‡åˆ†æ...")

            # è·å–åˆ†ææç¤ºè¯
            if options.get('custom_prompt'):
                # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯
                analysis_prompt = options['custom_prompt']
                if '{transcript}' in analysis_prompt:
                    analysis_prompt = analysis_prompt.format(transcript=transcript)
                else:
                    # å¦‚æœè‡ªå®šä¹‰æç¤ºè¯æ²¡æœ‰å ä½ç¬¦ï¼Œåˆ™å°†æ–‡æœ¬é™„åŠ åœ¨åé¢
                    analysis_prompt = f"{analysis_prompt}\n\n### å¾…åˆ†æå†…å®¹ï¼š\n{transcript}"
            else:
                # ä½¿ç”¨æ¨¡æ¿
                try:
                    analysis_prompt = self.prompt_manager.get_template(
                        'analysis',
                        template,
                        variables={
                            'transcript': transcript,
                            'additional_context': options.get('additional_context', ''),
                            'scenario_info': self.get_scenario_info(template)
                        }
                    )
                except Exception as e:
                    # å¦‚æœæ¨¡æ¿ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤çš„å®¢æˆ·è®¿è°ˆæ¨¡æ¿
                    print(f"æ¨¡æ¿ {template} åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
                    analysis_prompt = self._get_default_prompt(transcript, template)

            if progress_callback:
                progress_callback(f"æ­£åœ¨è°ƒç”¨ AI æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æ...")

            # è°ƒç”¨æ¨¡å‹è¿›è¡Œåˆ†æ
            response, stats = self.model_interface.generate_content(
                analysis_prompt,
                model_type='analysis',
                request_options={"timeout": 900}  # 15åˆ†é’Ÿè¶…æ—¶
            )

            # å¤„ç†è¾“å‡ºæ ¼å¼
            analysis_result = self._format_analysis_result(
                response,
                options.get('output_format', 'markdown')
            )

            if progress_callback:
                progress_callback(f"æ·±åº¦åˆ†æå®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.1f} ç§’")

            # æ„å»ºå®Œæ•´çš„å…ƒæ•°æ®
            result_metadata = {
                'analysis_template': template,
                'analysis_scenario': self.ANALYSIS_SCENARIOS.get(template, {}).get('name', template),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'input_length': len(transcript),
                'analysis_time': time.time() - start_time,
                **metadata  # ä¿ç•™åŸå§‹å…ƒæ•°æ®
            }

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            result_metadata.update({
                'input_tokens': stats.get('input_tokens', 0),
                'output_tokens': stats.get('output_tokens', 0),
                'total_tokens': stats.get('total_tokens', 0),
                'model_used': stats.get('model_used', ''),
                'estimated_cost': stats.get('estimated_cost', 0)
            })

            processing_time = time.time() - start_time

            return ProcessingResult(
                content=analysis_result,
                metadata=result_metadata,
                source_type='analysis',
                processing_time=processing_time,
                model_used=stats.get('model_used', ''),
                tokens_consumed={
                    'input': stats.get('input_tokens', 0),
                    'output': stats.get('output_tokens', 0),
                    'total': stats.get('total_tokens', 0)
                }
            )

        except Exception as e:
            if progress_callback:
                progress_callback(f"æ·±åº¦åˆ†æå¤±è´¥ï¼š{e}")

            processing_time = time.time() - start_time

            return ProcessingResult(
                content='',
                metadata={
                    'error': str(e),
                    'analysis_template': template,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                source_type='analysis',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )

    def _get_default_prompt(self, transcript: str, template: str) -> str:
        """è·å–é»˜è®¤çš„åˆ†ææç¤ºè¯ï¼ˆå½“æ¨¡æ¿åŠ è½½å¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        scenario_info = self.get_scenario_info(template)
        scenario_name = scenario_info.get('name', 'å•†ä¸šåˆ†æ')
        focus_areas = scenario_info.get('focus_areas', ['å…³é”®ä¿¡æ¯', 'ä¸»è¦è§‚ç‚¹', 'è¡ŒåŠ¨å»ºè®®'])

        return f"""# {scenario_name}

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰15å¹´ç»éªŒçš„èµ„æ·±å•†ä¸šåˆ†æå¸ˆå’Œæˆ˜ç•¥é¡¾é—®ï¼Œä¸“ç²¾äºä»å¯¹è¯è®°å½•ä¸­æå–å…³é”®æ´å¯Ÿå¹¶åˆ¶å®šå¯è¡Œçš„å•†ä¸šç­–ç•¥ã€‚

## äºŒã€åˆ†æä»»åŠ¡
è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ·±åº¦åˆ†æï¼Œé‡ç‚¹å…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼š
{chr(10).join(f'- {area}' for area in focus_areas)}

### å¾…åˆ†æå†…å®¹ï¼š
{transcript}

## ä¸‰ã€åˆ†æè¦æ±‚

### 3.1 æ‰§è¡Œæ‘˜è¦
è¯·ç”¨200å­—ä»¥å†…æ¦‚æ‹¬æ ¸å¿ƒå†…å®¹å’Œå…³é”®å‘ç°ã€‚

### 3.2 è¯¦ç»†åˆ†æ
è¯·æ ¹æ®å†…å®¹ç‰¹ç‚¹ï¼Œä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. **æ ¸å¿ƒä¿¡æ¯æå–**ï¼šè¯†åˆ«å¹¶æ•´ç†å…³é”®ä¿¡æ¯ç‚¹
2. **æ·±å±‚æ´å¯ŸæŒ–æ˜**ï¼šåˆ†æè¡¨è±¡èƒŒåçš„æ·±å±‚å«ä¹‰
3. **æœºä¼šä¸é£é™©**ï¼šè¯†åˆ«æ½œåœ¨çš„æœºä¼šå’Œéœ€è¦æ³¨æ„çš„é£é™©
4. **è¡ŒåŠ¨å»ºè®®**ï¼šæä¾›å…·ä½“å¯æ‰§è¡Œçš„å»ºè®®

### 3.3 å…³é”®è¦ç‚¹æ€»ç»“
è¯·åˆ—å‡º3-5ä¸ªæœ€é‡è¦çš„å‘ç°å’Œç»“è®ºã€‚

## å››ã€è¾“å‡ºè¦æ±‚
1. åˆ†æè¦åŸºäºåŸæ–‡äº‹å®ï¼Œé¿å…è¿‡åº¦æ¨æµ‹
2. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„å•†ä¸šè¯­è¨€
3. æä¾›å…·ä½“ã€å¯æ‰§è¡Œçš„å»ºè®®
4. ä¿æŒå®¢è§‚ä¸­ç«‹çš„åˆ†æè§†è§’"""

    def _format_analysis_result(self, raw_result: str, output_format: str) -> str:
        """æ ¼å¼åŒ–åˆ†æç»“æœ"""
        if output_format == 'markdown':
            # ç¡®ä¿è¾“å‡ºæ˜¯è§„èŒƒçš„Markdownæ ¼å¼
            if not raw_result.startswith('#'):
                raw_result = f"# åˆ†ææŠ¥å‘Š\n\n{raw_result}"
            return raw_result
        elif output_format == 'json':
            # TODO: å®ç°JSONæ ¼å¼è½¬æ¢
            # è¿™é‡Œæš‚æ—¶è¿”å›åŸå§‹ç»“æœ
            return raw_result
        else:
            return raw_result

    def analyze_transcript(self,
                           transcript: str,
                           template: str = 'customer_interview',
                           progress_callback=None) -> Tuple[str, Dict[str, any]]:
        """
        åˆ†æè½¬å½•æ–‡æœ¬ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰

        Args:
            transcript: è½¬å½•æ–‡æœ¬
            template: åˆ†ææ¨¡æ¿
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            (åˆ†æç»“æœæ–‡æœ¬, ç»Ÿè®¡ä¿¡æ¯å­—å…¸)
        """
        result = self.process(
            transcript,
            template=template,
            options={'progress_callback': progress_callback}
        )

        if result.error:
            return f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{result.error}", {
                'error': result.error,
                'analysis_time': result.processing_time
            }

        stats = {
            'analysis_time': result.processing_time,
            'input_tokens': result.tokens_consumed.get('input', 0),
            'output_tokens': result.tokens_consumed.get('output', 0),
            'model_used': result.model_used,
            'timestamp': result.metadata.get('timestamp', '')
        }

        return result.content, stats

    def batch_analyze(self,
                      documents: List[Dict],
                      template: str = 'customer_interview',
                      options: Optional[Dict] = None) -> List[ProcessingResult]:
        """
        æ‰¹é‡åˆ†æå¤šä¸ªæ–‡æ¡£

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å« 'id', 'content' ç­‰å­—æ®µ
            template: åˆ†ææ¨¡æ¿
            options: åˆ†æé€‰é¡¹

        Returns:
            List[ProcessingResult]: åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        options = options or {}
        progress_callback = options.get('progress_callback')

        for i, doc in enumerate(documents):
            if progress_callback:
                progress_callback(f"æ­£åœ¨åˆ†ææ–‡æ¡£ {i + 1}/{len(documents)}: {doc.get('id', 'unknown')}")

            # ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ›å»ºç‹¬ç«‹çš„é€‰é¡¹
            doc_options = options.copy()
            doc_options['document_id'] = doc.get('id')

            result = self.process(
                doc.get('content', ''),
                template=template,
                options=doc_options
            )

            # æ·»åŠ æ–‡æ¡£IDåˆ°å…ƒæ•°æ®
            result.metadata['document_id'] = doc.get('id')
            results.append(result)

            # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            if i < len(documents) - 1:
                time.sleep(2)

        return results

    def compare_analyses(self,
                         analyses: List[ProcessingResult],
                         comparison_prompt: Optional[str] = None) -> ProcessingResult:
        """
        æ¯”è¾ƒå¤šä¸ªåˆ†æç»“æœï¼Œç”Ÿæˆç»¼åˆæŠ¥å‘Š

        Args:
            analyses: åˆ†æç»“æœåˆ—è¡¨
            comparison_prompt: è‡ªå®šä¹‰æ¯”è¾ƒæç¤ºè¯

        Returns:
            ProcessingResult: ç»¼åˆæ¯”è¾ƒæŠ¥å‘Š
        """
        start_time = time.time()

        try:
            # å‡†å¤‡æ¯”è¾ƒå†…å®¹
            comparison_content = "# å¤šæ–‡æ¡£åˆ†ææ¯”è¾ƒ\n\n"
            for i, analysis in enumerate(analyses):
                doc_id = analysis.metadata.get('document_id', f'æ–‡æ¡£{i + 1}')
                comparison_content += f"## {doc_id}\n\n"
                comparison_content += analysis.content
                comparison_content += "\n\n---\n\n"

            # æ„å»ºæ¯”è¾ƒæç¤ºè¯
            if not comparison_prompt:
                comparison_prompt = """è¯·å¯¹ä»¥ä¸Šå¤šä¸ªåˆ†ææŠ¥å‘Šè¿›è¡Œç»¼åˆæ¯”è¾ƒï¼Œç”Ÿæˆä¸€ä»½æ•´åˆæŠ¥å‘Šã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«å…±åŒç‚¹å’Œå·®å¼‚ç‚¹
2. æå–è·¨æ–‡æ¡£çš„å…³é”®æ´å¯Ÿ
3. ç»¼åˆå„æ–‡æ¡£çš„å‘ç°ï¼Œå½¢æˆæ•´ä½“ç»“è®º
4. æä¾›åŸºäºå…¨å±€è§†è§’çš„å»ºè®®

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼å‘ˆç°æ¯”è¾ƒç»“æœã€‚"""

            full_prompt = f"{comparison_content}\n\n{comparison_prompt}"

            # è°ƒç”¨æ¨¡å‹
            response, stats = self.model_interface.generate_content(
                full_prompt,
                model_type='analysis'
            )

            processing_time = time.time() - start_time

            return ProcessingResult(
                content=response,
                metadata={
                    'comparison_type': 'multi_document',
                    'document_count': len(analyses),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'processing_time': processing_time
                },
                source_type='comparison',
                processing_time=processing_time,
                model_used=stats.get('model_used', ''),
                tokens_consumed={
                    'input': stats.get('input_tokens', 0),
                    'output': stats.get('output_tokens', 0),
                    'total': stats.get('total_tokens', 0)
                }
            )

        except Exception as e:
            processing_time = time.time() - start_time
            return ProcessingResult(
                content='',
                metadata={'error': str(e)},
                source_type='comparison',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )

    def extract_action_items(self, analysis_result: ProcessingResult) -> List[Dict]:
        """
        ä»åˆ†æç»“æœä¸­æå–è¡ŒåŠ¨é¡¹

        Args:
            analysis_result: åˆ†æç»“æœ

        Returns:
            List[Dict]: è¡ŒåŠ¨é¡¹åˆ—è¡¨
        """
        # TODO: å®ç°æ™ºèƒ½æå–è¡ŒåŠ¨é¡¹çš„é€»è¾‘
        # è¿™é‡Œæä¾›ä¸€ä¸ªç®€å•çš„å®ç°
        action_items = []

        content = analysis_result.content
        lines = content.split('\n')

        in_action_section = False
        for line in lines:
            line = line.strip()
            if 'è¡ŒåŠ¨' in line and ('å»ºè®®' in line or 'è®¡åˆ’' in line or 'é¡¹' in line):
                in_action_section = True
                continue

            if in_action_section and line:
                # ç®€å•çš„æ¨¡å¼åŒ¹é…
                if line.startswith(('1.', '2.', '3.', '-', '*', 'â€¢')):
                    action_items.append({
                        'description': line.lstrip('1234567890.-*â€¢ '),
                        'priority': 'medium',
                        'source': 'auto_extracted'
                    })

        return action_items

    def generate_executive_summary(self,
                                   analysis_result: ProcessingResult,
                                   max_length: int = 500) -> str:
        """
        ç”Ÿæˆæ‰§è¡Œæ‘˜è¦

        Args:
            analysis_result: åˆ†æç»“æœ
            max_length: æœ€å¤§é•¿åº¦

        Returns:
            str: æ‰§è¡Œæ‘˜è¦
        """
        try:
            prompt = f"""è¯·ä¸ºä»¥ä¸‹åˆ†ææŠ¥å‘Šç”Ÿæˆä¸€ä»½ç®€æ´çš„æ‰§è¡Œæ‘˜è¦ï¼Œä¸è¶…è¿‡{max_length}å­—ï¼š

{analysis_result.content}

è¦æ±‚ï¼š
1. çªå‡ºæœ€å…³é”®çš„å‘ç°
2. æ˜ç¡®ä¸»è¦ç»“è®º
3. ç®€è¿°æ ¸å¿ƒå»ºè®®
4. è¯­è¨€ç²¾ç‚¼ä¸“ä¸š"""

            response, _ = self.model_interface.generate_content(
                prompt,
                model_type='analysis'
            )

            return response

        except Exception as e:
            # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œå°è¯•ç®€å•æå–
            content = analysis_result.content
            if 'æ‰§è¡Œæ‘˜è¦' in content:
                # å°è¯•æå–å·²æœ‰çš„æ‘˜è¦éƒ¨åˆ†
                start = content.find('æ‰§è¡Œæ‘˜è¦')
                end = content.find('\n##', start)
                if end == -1:
                    end = start + max_length
                return content[start:end].strip()

            # è¿”å›å‰é¢éƒ¨åˆ†ä½œä¸ºæ‘˜è¦
            return content[:max_length] + '...' if len(content) > max_length else content

--- File: services/base_service.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/services/base_service.py
åŠŸèƒ½è¯´æ˜: æ‰€æœ‰æœåŠ¡çš„åŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€æ¥å£å’Œæ•°æ®ç»“æ„
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Union, Any
from datetime import datetime


@dataclass
class ProcessingResult:
    """
    ç»Ÿä¸€çš„å¤„ç†ç»“æœæ•°æ®ç»“æ„
    
    æ‰€æœ‰æœåŠ¡å¤„ç†åè¿”å›çš„ç»Ÿä¸€æ ¼å¼ï¼Œç¡®ä¿æ•°æ®åœ¨å„æ¨¡å—é—´é¡ºç•…æµè½¬
    """
    content: str                          # ä¸»è¦å†…å®¹ï¼ˆè½¬å½•æ–‡æœ¬ã€åˆ†ææŠ¥å‘Šã€æ–¹æ¡ˆæ–‡æ¡£ç­‰ï¼‰
    metadata: Dict[str, Any]              # å…ƒæ•°æ®ï¼ˆåŒ…å«å¤„ç†è¿‡ç¨‹çš„å„ç§ä¿¡æ¯ï¼‰
    source_type: str                      # æ¥æºç±»å‹ï¼ˆaudio/document/text/analysis/proposalç­‰ï¼‰
    processing_time: float                # å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
    model_used: str                       # ä½¿ç”¨çš„æ¨¡å‹åç§°
    tokens_consumed: Dict[str, int]       # Tokenæ¶ˆè€—ç»Ÿè®¡
    error: Optional[str] = None           # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¾¿äºåºåˆ—åŒ–å’Œå­˜å‚¨"""
        return {
            'content': self.content,
            'metadata': self.metadata,
            'source_type': self.source_type,
            'processing_time': self.processing_time,
            'model_used': self.model_used,
            'tokens_consumed': self.tokens_consumed,
            'error': self.error,
            'timestamp': datetime.now().isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ProcessingResult':
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        # ç§»é™¤timestampå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå› ä¸ºå®ƒä¸æ˜¯dataclassçš„å­—æ®µ
        data_copy = data.copy()
        data_copy.pop('timestamp', None)
        return cls(**data_copy)
    
    @property
    def is_success(self) -> bool:
        """åˆ¤æ–­å¤„ç†æ˜¯å¦æˆåŠŸ"""
        return self.error is None and bool(self.content)
    
    @property
    def total_tokens(self) -> int:
        """è·å–æ€»Tokenæ•°"""
        return self.tokens_consumed.get('total', 0)
    
    def get_summary(self) -> str:
        """è·å–å¤„ç†ç»“æœæ‘˜è¦"""
        if self.error:
            return f"å¤„ç†å¤±è´¥: {self.error}"
        
        summary_parts = [
            f"æ¥æºç±»å‹: {self.source_type}",
            f"å¤„ç†æ—¶é—´: {self.processing_time:.2f}ç§’",
            f"ä½¿ç”¨æ¨¡å‹: {self.model_used}",
            f"Tokenæ¶ˆè€—: {self.total_tokens}"
        ]
        
        # æ·»åŠ ç‰¹å®šç±»å‹çš„é¢å¤–ä¿¡æ¯
        if self.source_type == 'audio' and 'duration' in self.metadata:
            summary_parts.append(f"éŸ³é¢‘æ—¶é•¿: {self.metadata['duration']}")
        elif self.source_type == 'document' and 'page_count' in self.metadata:
            summary_parts.append(f"æ–‡æ¡£é¡µæ•°: {self.metadata['page_count']}")
        
        return " | ".join(summary_parts)


class BaseService(ABC):
    """
    æ‰€æœ‰æœåŠ¡çš„åŸºç±»
    
    å®šä¹‰äº†ç»Ÿä¸€çš„æœåŠ¡æ¥å£ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡éµå¾ªç›¸åŒçš„å¤„ç†æ¨¡å¼
    ä¸»è¦æ–¹æ³•ï¼š
    - process(): ä¸»å¤„ç†æ–¹æ³•
    - validate_input(): è¾“å…¥éªŒè¯
    - get_available_templates(): è·å–å¯ç”¨æ¨¡æ¿
    - configure(): æœåŠ¡é…ç½®
    - format_result(): ç»“æœæ ¼å¼åŒ–
    """
    
    def __init__(self):
        """åˆå§‹åŒ–åŸºç¡€æœåŠ¡"""
        self.config = {}
        self.is_configured = False
        self.service_name = self.__class__.__name__
        self.version = "1.0.0"
    
    @abstractmethod
    def process(self, 
                input_data: Union[str, Dict, bytes],
                template: Optional[str] = None,
                options: Optional[Dict] = None) -> ProcessingResult:
        """
        ä¸»å¤„ç†æ–¹æ³•ï¼ˆå¿…é¡»å®ç°ï¼‰
        
        Args:
            input_data: è¾“å…¥æ•°æ®ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€å­—å…¸æˆ–å­—èŠ‚æ•°æ®
            template: ä½¿ç”¨çš„æ¨¡æ¿åç§°ï¼ˆå¯é€‰ï¼‰
            options: å¤„ç†é€‰é¡¹å­—å…¸ï¼ˆå¯é€‰ï¼‰
                å¸¸è§é€‰é¡¹ï¼š
                - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
                - output_format: è¾“å‡ºæ ¼å¼
                - custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
                - additional_context: é¢å¤–ä¸Šä¸‹æ–‡
        
        Returns:
            ProcessingResult: ç»Ÿä¸€æ ¼å¼çš„å¤„ç†ç»“æœ
        """
        pass
    
    @abstractmethod
    def validate_input(self, input_data: Union[str, Dict, bytes]) -> bool:
        """
        éªŒè¯è¾“å…¥æ•°æ®æ˜¯å¦åˆæ³•ï¼ˆå¿…é¡»å®ç°ï¼‰
        
        Args:
            input_data: å¾…éªŒè¯çš„è¾“å…¥æ•°æ®
        
        Returns:
            bool: éªŒè¯æ˜¯å¦é€šè¿‡
        """
        pass
    
    @abstractmethod
    def get_available_templates(self) -> List[str]:
        """
        è·å–å¯ç”¨çš„æ¨¡æ¿åˆ—è¡¨ï¼ˆå¿…é¡»å®ç°ï¼‰
        
        Returns:
            List[str]: æ¨¡æ¿åç§°åˆ—è¡¨
        """
        pass
    
    def configure(self, config: Dict[str, Any]) -> None:
        """
        é…ç½®æœåŠ¡
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config.update(config)
        self.is_configured = True
    
    def format_result(self, 
                     content: str,
                     metadata: Dict[str, Any],
                     processing_time: float,
                     model_info: Dict[str, Any],
                     error: Optional[str] = None) -> ProcessingResult:
        """
        æ ¼å¼åŒ–å¤„ç†ç»“æœ
        
        ç»Ÿä¸€çš„ç»“æœæ ¼å¼åŒ–æ–¹æ³•ï¼Œä¾›å­ç±»ä½¿ç”¨
        
        Args:
            content: å¤„ç†åçš„å†…å®¹
            metadata: å…ƒæ•°æ®
            processing_time: å¤„ç†æ—¶é—´
            model_info: æ¨¡å‹ä¿¡æ¯ï¼ˆåŒ…å«model_usedå’Œtokensä¿¡æ¯ï¼‰
            error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        
        Returns:
            ProcessingResult: æ ¼å¼åŒ–åçš„ç»“æœ
        """
        # ç¡®ä¿å…ƒæ•°æ®åŒ…å«æœåŠ¡ä¿¡æ¯
        metadata['service_name'] = self.service_name
        metadata['service_version'] = self.version
        
        # æå–æ¨¡å‹ä¿¡æ¯
        model_used = model_info.get('model_used', '')
        tokens_consumed = {
            'input': model_info.get('input_tokens', 0),
            'output': model_info.get('output_tokens', 0),
            'total': model_info.get('total_tokens', 0)
        }
        
        # æ·»åŠ è´¹ç”¨ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'estimated_cost' in model_info:
            metadata['estimated_cost'] = model_info['estimated_cost']
        
        return ProcessingResult(
            content=content,
            metadata=metadata,
            source_type=self._get_source_type(),
            processing_time=processing_time,
            model_used=model_used,
            tokens_consumed=tokens_consumed,
            error=error
        )
    
    def _get_source_type(self) -> str:
        """
        è·å–æœåŠ¡å¯¹åº”çš„æºç±»å‹
        
        å­ç±»å¯ä»¥è¦†ç›–æ­¤æ–¹æ³•è¿”å›ç‰¹å®šçš„æºç±»å‹
        """
        # æ ¹æ®æœåŠ¡åç§°æ¨æ–­æºç±»å‹
        service_type_map = {
            'TranscriptionService': 'audio',
            'DocumentService': 'document',
            'AnalysisService': 'analysis',
            'DeepAnalysisService': 'analysis',
            'ProposalService': 'proposal'
        }
        
        return service_type_map.get(self.service_name, 'unknown')
    
    def get_service_info(self) -> Dict[str, Any]:
        """
        è·å–æœåŠ¡ä¿¡æ¯
        
        Returns:
            Dict: åŒ…å«æœåŠ¡åç§°ã€ç‰ˆæœ¬ã€é…ç½®çŠ¶æ€ç­‰ä¿¡æ¯
        """
        return {
            'name': self.service_name,
            'version': self.version,
            'is_configured': self.is_configured,
            'available_templates': self.get_available_templates(),
            'source_type': self._get_source_type()
        }
    
    def health_check(self) -> Dict[str, Any]:
        """
        æœåŠ¡å¥åº·æ£€æŸ¥
        
        Returns:
            Dict: å¥åº·çŠ¶æ€ä¿¡æ¯
        """
        try:
            # å°è¯•éªŒè¯ä¸€ä¸ªç®€å•çš„è¾“å…¥
            test_input = "test"
            is_healthy = True
            
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥è·å–æ¨¡æ¿
            templates = self.get_available_templates()
            
            return {
                'status': 'healthy' if is_healthy else 'unhealthy',
                'service': self.service_name,
                'version': self.version,
                'configured': self.is_configured,
                'template_count': len(templates),
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'status': 'unhealthy',
                'service': self.service_name,
                'version': self.version,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def __repr__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"{self.service_name}(version={self.version}, configured={self.is_configured})"

--- File: services/document_service.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/services/document_service.py
åŠŸèƒ½è¯´æ˜: æ–‡æ¡£å¤„ç†æœåŠ¡ï¼Œæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼çš„è¯»å–å’Œå¤„ç†
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import time
from typing import Dict, List, Optional, Union, Tuple
from datetime import datetime
from pathlib import Path
import mimetypes

# æ–‡æ¡£å¤„ç†åº“
try:
    import docx
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("è­¦å‘Šï¼špython-docxæœªå®‰è£…ï¼Œæ— æ³•å¤„ç†DOCXæ–‡ä»¶")

try:
    import PyPDF2
    from PyPDF2 import PdfReader
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("è­¦å‘Šï¼šPyPDF2æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†PDFæ–‡ä»¶")

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.base_service import BaseService, ProcessingResult
from utils.file_utils import get_file_extension, get_file_metadata, format_file_size
from utils.format_utils import clean_text, format_metadata_display


class DocumentService(BaseService):
    """
    æ–‡æ¡£å¤„ç†æœåŠ¡
    
    ä¸»è¦åŠŸèƒ½:
    1. æ”¯æŒDOCXæ–‡æ¡£è§£æï¼ˆä½¿ç”¨python-docxï¼‰
    2. æ”¯æŒPDFæ–‡æ¡£è§£æï¼ˆä½¿ç”¨PyPDF2ï¼‰
    3. æ”¯æŒTXTæ–‡æ¡£è¯»å–
    4. ç»Ÿä¸€è¾“å‡ºä¸ºæ ‡å‡†æ–‡æœ¬æ ¼å¼
    5. ä¿ç•™æ–‡æ¡£å…ƒæ•°æ®ï¼ˆé¡µæ•°ã€åˆ›å»ºæ—¶é—´ç­‰ï¼‰
    
    ä½¿ç”¨ç¤ºä¾‹:
        service = DocumentService()
        result = service.process(file_path, options={'extract_metadata': True})
    """
    
    # æ”¯æŒçš„æ–‡æ¡£æ ¼å¼
    SUPPORTED_FORMATS = {
        '.docx': 'Microsoft Word Document',
        '.doc': 'Microsoft Word Document (Legacy)',
        '.pdf': 'PDF Document',
        '.txt': 'Text File',
        '.rtf': 'Rich Text Format',
        '.odt': 'OpenDocument Text'
    }
    
    def __init__(self):
        super().__init__()
        self.check_dependencies()
    
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–åº“æ˜¯å¦å¯ç”¨"""
        self.capabilities = {
            'docx': DOCX_AVAILABLE,
            'pdf': PDF_AVAILABLE,
            'txt': True  # æ€»æ˜¯å¯ç”¨
        }
        
        if not DOCX_AVAILABLE:
            print("æç¤ºï¼šå®‰è£…python-docxä»¥æ”¯æŒDOCXæ–‡ä»¶å¤„ç†: pip install python-docx")
        if not PDF_AVAILABLE:
            print("æç¤ºï¼šå®‰è£…PyPDF2ä»¥æ”¯æŒPDFæ–‡ä»¶å¤„ç†: pip install PyPDF2")
    
    def get_available_templates(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ¨¡æ¿åˆ—è¡¨ï¼ˆæ–‡æ¡£æœåŠ¡ä¸ä½¿ç”¨æ¨¡æ¿ï¼‰"""
        return []
    
    def validate_input(self, input_data: Union[str, bytes, Path]) -> bool:
        """éªŒè¯è¾“å…¥æ˜¯å¦ä¸ºæ”¯æŒçš„æ–‡æ¡£æ ¼å¼"""
        if isinstance(input_data, (str, Path)):
            ext = get_file_extension(input_data)
            return ext.lower() in self.SUPPORTED_FORMATS
        return False
    
    def process(self,
                input_data: Union[str, bytes, Path],
                template: Optional[str] = None,
                options: Optional[Dict] = None) -> ProcessingResult:
        """
        å¤„ç†æ–‡æ¡£æ–‡ä»¶
        
        Args:
            input_data: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
            template: æœªä½¿ç”¨ï¼ˆä¿æŒæ¥å£ä¸€è‡´ï¼‰
            options: å¤„ç†é€‰é¡¹
                - extract_metadata: æ˜¯å¦æå–å…ƒæ•°æ®
                - preserve_formatting: æ˜¯å¦ä¿ç•™æ ¼å¼ä¿¡æ¯
                - clean_output: æ˜¯å¦æ¸…ç†è¾“å‡ºæ–‡æœ¬
                - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        start_time = time.time()
        options = options or {}
        progress_callback = options.get('progress_callback')
        
        try:
            # ç¡®ä¿è¾“å…¥æ˜¯æ–‡ä»¶è·¯å¾„
            file_path = Path(input_data)
            if not file_path.exists():
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_metadata = get_file_metadata(file_path)
            ext = file_metadata['extension'].lower()
            
            if progress_callback:
                progress_callback(f"æ­£åœ¨å¤„ç† {file_metadata['filename']}...")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©å¤„ç†æ–¹æ³•
            if ext == '.docx':
                content, doc_metadata = self._process_docx(file_path, options)
            elif ext == '.pdf':
                content, doc_metadata = self._process_pdf(file_path, options)
            elif ext in ['.txt', '.text']:
                content, doc_metadata = self._process_text(file_path, options)
            elif ext == '.doc':
                # æ—§ç‰ˆWordæ–‡æ¡£ï¼Œå°è¯•ä½œä¸ºDOCXå¤„ç†ï¼ˆå¯èƒ½éœ€è¦è½¬æ¢ï¼‰
                content, doc_metadata = self._process_legacy_doc(file_path, options)
            else:
                # å°è¯•ä½œä¸ºçº¯æ–‡æœ¬å¤„ç†
                content, doc_metadata = self._process_text(file_path, options)
            
            # æ¸…ç†æ–‡æœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if options.get('clean_output', True):
                content = clean_text(content)
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = {
                **file_metadata,
                **doc_metadata,
                'processing_options': {
                    'extract_metadata': options.get('extract_metadata', True),
                    'preserve_formatting': options.get('preserve_formatting', False),
                    'clean_output': options.get('clean_output', True)
                }
            }
            
            # æ·»åŠ å†…å®¹ç»Ÿè®¡
            metadata.update(self._analyze_content(content))
            
            if progress_callback:
                progress_callback(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±æå– {metadata.get('word_count', 0)} ä¸ªè¯")
            
            processing_time = time.time() - start_time
            
            return ProcessingResult(
                content=content,
                metadata=metadata,
                source_type='document',
                processing_time=processing_time,
                model_used='',  # æ–‡æ¡£å¤„ç†ä¸ä½¿ç”¨AIæ¨¡å‹
                tokens_consumed={}
            )
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}")
            
            processing_time = time.time() - start_time
            
            return ProcessingResult(
                content='',
                metadata={
                    'error': str(e),
                    'file_path': str(input_data)
                },
                source_type='document',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )
    
    def _process_docx(self, file_path: Path, options: Dict) -> Tuple[str, Dict]:
        """å¤„ç†DOCXæ–‡æ¡£"""
        if not DOCX_AVAILABLE:
            raise ImportError("python-docxåº“æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†DOCXæ–‡ä»¶")
        
        doc = Document(str(file_path))
        content_parts = []
        metadata = {
            'format': 'docx',
            'paragraph_count': 0,
            'table_count': len(doc.tables),
            'image_count': len(doc.inline_shapes)
        }
        
        # æå–æ ¸å¿ƒå±æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if options.get('extract_metadata', True):
            try:
                core_props = doc.core_properties
                metadata.update({
                    'title': core_props.title or '',
                    'author': core_props.author or '',
                    'subject': core_props.subject or '',
                    'keywords': core_props.keywords or '',
                    'created': core_props.created.isoformat() if core_props.created else '',
                    'modified': core_props.modified.isoformat() if core_props.modified else '',
                    'last_modified_by': core_props.last_modified_by or ''
                })
            except:
                pass
        
        # æå–æ®µè½æ–‡æœ¬
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if text:
                content_parts.append(text)
                metadata['paragraph_count'] += 1
        
        # æå–è¡¨æ ¼æ–‡æœ¬ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if options.get('extract_tables', True) and doc.tables:
            content_parts.append("\n[è¡¨æ ¼å†…å®¹]\n")
            for table_idx, table in enumerate(doc.tables):
                content_parts.append(f"\nè¡¨æ ¼ {table_idx + 1}:")
                for row in table.rows:
                    row_text = " | ".join(cell.text.strip() for cell in row.cells)
                    if row_text.strip():
                        content_parts.append(row_text)
        
        content = "\n\n".join(content_parts)
        
        # è®¡ç®—é¡µæ•°ï¼ˆä¼°ç®—ï¼‰
        # DOCXæ²¡æœ‰å›ºå®šçš„é¡µæ•°æ¦‚å¿µï¼Œè¿™é‡Œæ ¹æ®å­—æ•°ä¼°ç®—
        word_count = len(content.split())
        estimated_pages = max(1, word_count // 250)  # å‡è®¾æ¯é¡µ250è¯
        metadata['page_count'] = estimated_pages
        metadata['page_count_note'] = 'estimated'
        
        return content, metadata
    
    def _process_pdf(self, file_path: Path, options: Dict) -> Tuple[str, Dict]:
        """å¤„ç†PDFæ–‡æ¡£"""
        if not PDF_AVAILABLE:
            raise ImportError("PyPDF2åº“æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†PDFæ–‡ä»¶")
        
        content_parts = []
        metadata = {
            'format': 'pdf',
            'page_count': 0,
            'encrypted': False
        }
        
        try:
            with open(file_path, 'rb') as pdf_file:
                pdf_reader = PdfReader(pdf_file)
                
                # æ£€æŸ¥æ˜¯å¦åŠ å¯†
                if pdf_reader.is_encrypted:
                    metadata['encrypted'] = True
                    # å°è¯•ä½¿ç”¨ç©ºå¯†ç è§£å¯†
                    if not pdf_reader.decrypt(''):
                        raise ValueError("PDFæ–‡ä»¶å·²åŠ å¯†ï¼Œéœ€è¦å¯†ç ")
                
                metadata['page_count'] = len(pdf_reader.pages)
                
                # æå–å…ƒæ•°æ®
                if options.get('extract_metadata', True) and pdf_reader.metadata:
                    pdf_meta = pdf_reader.metadata
                    metadata.update({
                        'title': pdf_meta.get('/Title', ''),
                        'author': pdf_meta.get('/Author', ''),
                        'subject': pdf_meta.get('/Subject', ''),
                        'creator': pdf_meta.get('/Creator', ''),
                        'producer': pdf_meta.get('/Producer', ''),
                        'creation_date': str(pdf_meta.get('/CreationDate', '')),
                        'modification_date': str(pdf_meta.get('/ModDate', ''))
                    })
                
                # æå–æ¯é¡µæ–‡æœ¬
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text.strip():
                            if options.get('preserve_formatting', False):
                                content_parts.append(f"\n--- ç¬¬ {page_num + 1} é¡µ ---\n")
                            content_parts.append(page_text)
                    except Exception as e:
                        content_parts.append(f"\n[ç¬¬ {page_num + 1} é¡µæå–å¤±è´¥: {str(e)}]\n")
        
        except Exception as e:
            raise Exception(f"PDFå¤„ç†å¤±è´¥: {str(e)}")
        
        content = "\n".join(content_parts)
        return content, metadata
    
    def _process_text(self, file_path: Path, options: Dict) -> Tuple[str, Dict]:
        """å¤„ç†çº¯æ–‡æœ¬æ–‡ä»¶"""
        metadata = {
            'format': 'txt',
            'encoding': 'utf-8'
        }
        
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin-1']
        content = None
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.read()
                metadata['encoding'] = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if content is None:
            # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–
            with open(file_path, 'rb') as f:
                content = f.read().decode('utf-8', errors='replace')
            metadata['encoding'] = 'binary_with_replacement'
        
        # ä¼°ç®—é¡µæ•°
        line_count = content.count('\n') + 1
        estimated_pages = max(1, line_count // 50)  # å‡è®¾æ¯é¡µ50è¡Œ
        metadata['page_count'] = estimated_pages
        metadata['page_count_note'] = 'estimated'
        metadata['line_count'] = line_count
        
        return content, metadata
    
    def _process_legacy_doc(self, file_path: Path, options: Dict) -> Tuple[str, Dict]:
        """å¤„ç†æ—§ç‰ˆDOCæ–‡æ¡£"""
        # æ—§ç‰ˆDOCæ–‡æ¡£å¤„ç†æ¯”è¾ƒå¤æ‚ï¼ŒMVPç‰ˆæœ¬å…ˆä½œä¸ºäºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†
        # å®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨python-docx2txtæˆ–å…¶ä»–åº“
        
        # å°è¯•ä½œä¸ºDOCXå¤„ç†ï¼ˆæœ‰äº›.docæ–‡ä»¶å®é™…ä¸Šæ˜¯DOCXæ ¼å¼ï¼‰
        try:
            return self._process_docx(file_path, options)
        except:
            pass
        
        # ä½œä¸ºæ–‡æœ¬æ–‡ä»¶å¤„ç†
        try:
            return self._process_text(file_path, options)
        except:
            pass
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        raise ValueError("æ— æ³•å¤„ç†æ—§ç‰ˆDOCæ–‡æ¡£ï¼Œè¯·è½¬æ¢ä¸ºDOCXæ ¼å¼")
    
    def _analyze_content(self, content: str) -> Dict[str, any]:
        """åˆ†ææ–‡æ¡£å†…å®¹ï¼Œæå–ç»Ÿè®¡ä¿¡æ¯"""
        # åŸºæœ¬ç»Ÿè®¡
        word_count = len(content.split())
        char_count = len(content)
        char_count_no_spaces = len(content.replace(' ', '').replace('\n', '').replace('\t', ''))
        
        # æ®µè½ç»Ÿè®¡
        paragraphs = [p for p in content.split('\n\n') if p.strip()]
        paragraph_count = len(paragraphs)
        
        # å¥å­ç»Ÿè®¡ï¼ˆç®€å•ä¼°ç®—ï¼‰
        sentence_endings = ['.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ']
        sentence_count = sum(content.count(ending) for ending in sentence_endings)
        
        # å¹³å‡å€¼è®¡ç®—
        avg_words_per_paragraph = word_count / paragraph_count if paragraph_count > 0 else 0
        avg_words_per_sentence = word_count / sentence_count if sentence_count > 0 else 0
        
        return {
            'word_count': word_count,
            'character_count': char_count,
            'character_count_no_spaces': char_count_no_spaces,
            'paragraph_count': paragraph_count,
            'sentence_count': sentence_count,
            'avg_words_per_paragraph': round(avg_words_per_paragraph, 1),
            'avg_words_per_sentence': round(avg_words_per_sentence, 1)
        }
    
    def extract_structured_content(self, 
                                 file_path: Union[str, Path],
                                 structure_type: str = 'sections') -> Dict[str, List[str]]:
        """
        æå–ç»“æ„åŒ–å†…å®¹
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            structure_type: ç»“æ„ç±»å‹ ('sections', 'headings', 'lists')
        
        Returns:
            Dict: ç»“æ„åŒ–å†…å®¹
        """
        result = self.process(file_path)
        if not result.is_success:
            return {}
        
        content = result.content
        structured = {}
        
        if structure_type == 'sections':
            # æŒ‰æ ‡é¢˜åˆ†å‰²ç« èŠ‚
            # ç®€å•å®ç°ï¼šæŸ¥æ‰¾å¯èƒ½çš„æ ‡é¢˜æ¨¡å¼
            sections = []
            current_section = []
            
            for line in content.split('\n'):
                # æ£€æµ‹å¯èƒ½çš„æ ‡é¢˜ï¼ˆå…¨å¤§å†™ã€æ•°å­—å¼€å¤´ç­‰ï¼‰
                if (line.isupper() and len(line) > 3) or \
                   (line.strip() and line[0].isdigit() and '.' in line[:3]):
                    if current_section:
                        sections.append('\n'.join(current_section))
                    current_section = [line]
                else:
                    current_section.append(line)
            
            if current_section:
                sections.append('\n'.join(current_section))
            
            structured['sections'] = sections
            
        elif structure_type == 'headings':
            # æå–æ‰€æœ‰æ ‡é¢˜
            headings = []
            for line in content.split('\n'):
                line = line.strip()
                if line and (line.isupper() or 
                           (line[0].isdigit() and '.' in line[:3]) or
                           line.startswith('#')):
                    headings.append(line)
            
            structured['headings'] = headings
            
        elif structure_type == 'lists':
            # æå–åˆ—è¡¨é¡¹
            list_items = []
            for line in content.split('\n'):
                line = line.strip()
                if line and (line.startswith(('â€¢', '-', '*', 'Â·')) or
                           (line[0].isdigit() and ('.' in line[:3] or ')' in line[:3]))):
                    list_items.append(line)
            
            structured['lists'] = list_items
        
        return structured
    
    def convert_to_markdown(self, file_path: Union[str, Path]) -> str:
        """
        å°†æ–‡æ¡£è½¬æ¢ä¸ºMarkdownæ ¼å¼
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
        
        Returns:
            str: Markdownæ ¼å¼çš„å†…å®¹
        """
        result = self.process(file_path, options={'preserve_formatting': True})
        if not result.is_success:
            return f"# é”™è¯¯\n\næ— æ³•å¤„ç†æ–‡æ¡£: {result.error}"
        
        # æ·»åŠ æ–‡æ¡£ä¿¡æ¯å¤´
        markdown_parts = [
            f"# {result.metadata.get('title', 'æ–‡æ¡£å†…å®¹')}\n",
            f"**æ–‡ä»¶**: {result.metadata.get('filename', 'unknown')}  ",
            f"**æ ¼å¼**: {result.metadata.get('format', 'unknown')}  ",
            f"**é¡µæ•°**: {result.metadata.get('page_count', 'unknown')}  ",
            f"**å­—æ•°**: {result.metadata.get('word_count', 'unknown')}  \n",
            "---\n"
        ]
        
        # å¤„ç†å†…å®¹ï¼Œå°è¯•è¯†åˆ«å’Œä¿ç•™ç»“æ„
        content = result.content
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if not line:
                markdown_parts.append('')
                continue
            
            # è¯†åˆ«å¯èƒ½çš„æ ‡é¢˜
            if line.isupper() and len(line) > 3:
                markdown_parts.append(f"\n## {line}\n")
            elif line[0:1].isdigit() and '.' in line[:3]:
                # å¯èƒ½æ˜¯ç¼–å·æ ‡é¢˜
                markdown_parts.append(f"\n### {line}\n")
            else:
                markdown_parts.append(line)
        
        return '\n'.join(markdown_parts)
    
    def get_document_summary(self, file_path: Union[str, Path], max_length: int = 500) -> str:
        """
        è·å–æ–‡æ¡£æ‘˜è¦
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            max_length: æœ€å¤§é•¿åº¦
        
        Returns:
            str: æ–‡æ¡£æ‘˜è¦
        """
        result = self.process(file_path)
        if not result.is_success:
            return f"æ— æ³•ç”Ÿæˆæ‘˜è¦: {result.error}"
        
        content = result.content
        
        # ç®€å•çš„æ‘˜è¦ç”Ÿæˆï¼šå–å‰é¢çš„å†…å®¹
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆæ›´å¥½çš„æ‘˜è¦
        if len(content) <= max_length:
            return content
        
        # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
        truncated = content[:max_length]
        last_period = truncated.rfind('ã€‚')
        if last_period == -1:
            last_period = truncated.rfind('.')
        
        if last_period > max_length * 0.8:
            truncated = truncated[:last_period + 1]
        
        return truncated + "..."
    
    def batch_process_documents(self,
                              file_paths: List[Union[str, Path]],
                              options: Optional[Dict] = None) -> List[ProcessingResult]:
        """
        æ‰¹é‡å¤„ç†æ–‡æ¡£
        
        Args:
            file_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
            options: å¤„ç†é€‰é¡¹
        
        Returns:
            List[ProcessingResult]: å¤„ç†ç»“æœåˆ—è¡¨
        """
        results = []
        options = options or {}
        progress_callback = options.get('progress_callback')
        
        for i, file_path in enumerate(file_paths):
            if progress_callback:
                progress_callback(f"å¤„ç†æ–‡æ¡£ {i + 1}/{len(file_paths)}: {Path(file_path).name}")
            
            result = self.process(file_path, options=options)
            results.append(result)
        
        return results

--- File: services/proposal_service.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/services/proposal_service.py
åŠŸèƒ½è¯´æ˜: æ–¹æ¡ˆç”ŸæˆæœåŠ¡ï¼ŒåŸºäºåˆ†æç»“æœç”Ÿæˆå„ç±»å•†ä¸šæ–‡æ¡£
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""
import re
import os
import sys
import time
import json
from typing import Dict, List, Optional, Union, Tuple, Any
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.base_service import BaseService, ProcessingResult
from services.document_service import DocumentService
from core.prompt_manager import PromptManager
from core.model_interface import ModelInterface
from utils.format_utils import clean_text, format_timestamp, format_money


class ProposalService(BaseService):
    """
    æ–¹æ¡ˆç”ŸæˆæœåŠ¡
    
    ä¸»è¦åŠŸèƒ½:
    1. åŸºäºåˆ†æç»“æœç”Ÿæˆæ–¹æ¡ˆ
    2. æ”¯æŒå¤šç§æ–¹æ¡ˆæ¨¡æ¿
    3. æ•´åˆä¼ä¸šèƒ½åŠ›æ–‡æ¡£ï¼ˆå¯é€‰ï¼‰
    4. ç”Ÿæˆä¸“ä¸šæ ¼å¼çš„è¾“å‡ºæ–‡æ¡£
    
    ä½¿ç”¨ç¤ºä¾‹:
        service = ProposalService()
        result = service.process(
            analysis_report,
            template='project_proposal',
            options={'capability_docs': ['company_intro.docx']}
        )
    """
    
    # é¢„å®šä¹‰çš„æ–¹æ¡ˆç±»å‹
    PROPOSAL_TYPES = {
        'project_proposal': {
            'name': 'é¡¹ç›®å»ºè®®ä¹¦',
            'description': 'å®Œæ•´çš„é¡¹ç›®å®æ–½æ–¹æ¡ˆï¼ŒåŒ…å«èƒŒæ™¯ã€æ–¹æ¡ˆã€è®¡åˆ’ã€é¢„ç®—ç­‰',
            'sections': ['æ‰§è¡Œæ‘˜è¦', 'éœ€æ±‚åˆ†æ', 'è§£å†³æ–¹æ¡ˆ', 'å®æ–½è®¡åˆ’', 'æŠ•èµ„å›æŠ¥', 'å›¢é˜Ÿä»‹ç»', 'å•†åŠ¡æ¡æ¬¾']
        },
        'quotation_proposal': {
            'name': 'å•†åŠ¡æŠ¥ä»·æ–¹æ¡ˆ',
            'description': 'è¯¦ç»†çš„æœåŠ¡æŠ¥ä»·å•ï¼ŒåŒ…å«é¡¹ç›®æ˜ç»†å’Œä»·æ ¼',
            'sections': ['æ–¹æ¡ˆæ¦‚è¿°', 'æœåŠ¡å†…å®¹', 'æŠ¥ä»·æ˜ç»†', 'ä»˜æ¬¾æ–¹å¼', 'æœåŠ¡æ‰¿è¯º']
        },
        'solution_brief': {
            'name': 'è§£å†³æ–¹æ¡ˆç®€æŠ¥',
            'description': 'ç®€æ´çš„æ–¹æ¡ˆè¯´æ˜ï¼Œé€‚åˆå¿«é€Ÿå±•ç¤º',
            'sections': ['é—®é¢˜é™ˆè¿°', 'è§£å†³æ–¹æ¡ˆ', 'å®æ–½æ­¥éª¤', 'é¢„æœŸæ•ˆæœ']
        },
        'meeting_minutes': {
            'name': 'ä¼šè®®çºªè¦åŠè¡ŒåŠ¨è®¡åˆ’',
            'description': 'ä¼šè®®æ€»ç»“å’Œåç»­è¡ŒåŠ¨å®‰æ’',
            'sections': ['ä¼šè®®æ¦‚è¦', 'è®¨è®ºè¦ç‚¹', 'å†³ç­–äº‹é¡¹', 'è¡ŒåŠ¨è®¡åˆ’', 'åç»­å®‰æ’']
        },
        'technical_proposal': {
            'name': 'æŠ€æœ¯æ–¹æ¡ˆä¹¦',
            'description': 'è¯¦ç»†çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆ',
            'sections': ['æŠ€æœ¯èƒŒæ™¯', 'æ¶æ„è®¾è®¡', 'æŠ€æœ¯é€‰å‹', 'å®æ–½æ–¹æ¡ˆ', 'é£é™©è¯„ä¼°']
        }
    }
    
    def __init__(self):
        super().__init__()
        self.prompt_manager = PromptManager()
        self.model_interface = ModelInterface()
        self.document_service = DocumentService()
    
    def get_available_templates(self) -> List[str]:
        """è·å–å¯ç”¨çš„æ–¹æ¡ˆæ¨¡æ¿åˆ—è¡¨"""
        # é¢„å®šä¹‰æ¨¡æ¿
        templates = list(self.PROPOSAL_TYPES.keys())
        
        # æ–‡ä»¶ç³»ç»Ÿä¸­çš„è‡ªå®šä¹‰æ¨¡æ¿
        custom_templates = self.prompt_manager.list_templates('proposal')
        
        # åˆå¹¶å¹¶å»é‡
        all_templates = list(set(templates + custom_templates))
        return all_templates
    
    def get_proposal_type_info(self, proposal_type: str) -> Dict:
        """è·å–æ–¹æ¡ˆç±»å‹çš„è¯¦ç»†ä¿¡æ¯"""
        return self.PROPOSAL_TYPES.get(proposal_type, {})
    
    def validate_input(self, input_data: Union[str, Dict]) -> bool:
        """éªŒè¯è¾“å…¥æ•°æ®"""
        if isinstance(input_data, str):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„åˆ†ææŠ¥å‘Š
            return len(input_data.strip()) > 100
        elif isinstance(input_data, dict):
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            return 'analysis_report' in input_data or 'content' in input_data
        return False
    
    def process(self,
                input_data: Union[str, Dict],
                template: Optional[str] = 'project_proposal',
                options: Optional[Dict] = None) -> ProcessingResult:
        """
        ç”Ÿæˆå•†ä¸šæ–¹æ¡ˆ
        
        Args:
            input_data: åˆ†ææŠ¥å‘Šæˆ–åŒ…å«åˆ†ææŠ¥å‘Šçš„å­—å…¸
            template: æ–¹æ¡ˆæ¨¡æ¿åç§°
            options: ç”Ÿæˆé€‰é¡¹
                - capability_docs: ä¼ä¸šèƒ½åŠ›æ–‡æ¡£åˆ—è¡¨
                - custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
                - include_pricing: æ˜¯å¦åŒ…å«æŠ¥ä»·
                - language: è¯­è¨€ï¼ˆ'zh', 'en'ï¼‰
                - format: è¾“å‡ºæ ¼å¼ï¼ˆ'markdown', 'text'ï¼‰
                - client_info: å®¢æˆ·ä¿¡æ¯
                - progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
        
        Returns:
            ProcessingResult: ç”Ÿæˆçš„æ–¹æ¡ˆ
        """
        start_time = time.time()
        options = options or {}
        progress_callback = options.get('progress_callback')
        
        try:
            # æå–åˆ†ææŠ¥å‘Šå†…å®¹
            if isinstance(input_data, str):
                analysis_report = input_data
                metadata = {}
            else:
                analysis_report = input_data.get('analysis_report') or input_data.get('content', '')
                metadata = input_data.get('metadata', {})
            
            if not self.validate_input(analysis_report):
                raise ValueError("åˆ†ææŠ¥å‘Šå†…å®¹å¤ªçŸ­æˆ–æ ¼å¼ä¸æ­£ç¡®")
            
            if progress_callback:
                progress_callback("æ­£åœ¨å‡†å¤‡ç”Ÿæˆæ–¹æ¡ˆ...")
            
            # å¤„ç†ä¼ä¸šèƒ½åŠ›æ–‡æ¡£
            capability_content = ""
            if options.get('capability_docs'):
                capability_content = self._process_capability_docs(
                    options['capability_docs'],
                    progress_callback
                )
            
            # è·å–ç”Ÿæˆæç¤ºè¯
            if options.get('custom_prompt'):
                # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯
                generation_prompt = options['custom_prompt']
                # æ›¿æ¢å˜é‡
                generation_prompt = generation_prompt.replace('{analysis_report}', analysis_report)
                if capability_content:
                    generation_prompt = generation_prompt.replace('{capability_docs}', capability_content)
            else:
                # ä½¿ç”¨æ¨¡æ¿
                try:
                    # å‡†å¤‡æ¨¡æ¿å˜é‡
                    template_vars = {
                        'analysis_report': analysis_report,
                        'capability_docs': capability_content,
                        'proposal_type_info': self.get_proposal_type_info(template),
                        'client_info': options.get('client_info', {}),
                        'include_pricing': options.get('include_pricing', False),
                        'language': options.get('language', 'zh')
                    }
                    
                    generation_prompt = self.prompt_manager.get_template(
                        'proposal',
                        template,
                        variables=template_vars
                    )
                except Exception as e:
                    # å¦‚æœæ¨¡æ¿ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿
                    print(f"æ¨¡æ¿ {template} åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
                    generation_prompt = self._get_default_prompt(
                        analysis_report,
                        template,
                        capability_content,
                        options
                    )
            
            if progress_callback:
                progress_callback("æ­£åœ¨è°ƒç”¨ AI æ¨¡å‹ç”Ÿæˆæ–¹æ¡ˆ...")
            
            # è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ–¹æ¡ˆ
            response, stats = self.model_interface.generate_content(
                generation_prompt,
                model_type='proposal',
                generation_config={
                    'temperature': 0.7,
                    'top_p': 0.95,
                    'max_output_tokens': 16384
                },
                request_options={"timeout": 1200}  # 20åˆ†é’Ÿè¶…æ—¶
            )
            
            # å¤„ç†è¾“å‡ºæ ¼å¼
            proposal_content = self._format_proposal(
                response,
                template,
                options.get('format', 'markdown')
            )
            
            # æ·»åŠ ç‰ˆæƒå’Œç”Ÿæˆä¿¡æ¯
            proposal_content = self._add_footer(proposal_content, template)
            
            if progress_callback:
                progress_callback(f"æ–¹æ¡ˆç”Ÿæˆå®Œæˆï¼Œè€—æ—¶ {time.time() - start_time:.1f} ç§’")
            
            # æ„å»ºå®Œæ•´çš„å…ƒæ•°æ®
            result_metadata = {
                'proposal_type': template,
                'proposal_name': self.PROPOSAL_TYPES.get(template, {}).get('name', template),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'has_capability_docs': bool(capability_content),
                'output_format': options.get('format', 'markdown'),
                'generation_time': time.time() - start_time,
                **metadata  # ä¿ç•™åŸå§‹å…ƒæ•°æ®
            }
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            result_metadata.update({
                'input_tokens': stats.get('input_tokens', 0),
                'output_tokens': stats.get('output_tokens', 0),
                'total_tokens': stats.get('total_tokens', 0),
                'model_used': stats.get('model_used', ''),
                'estimated_cost': stats.get('estimated_cost', 0)
            })
            
            # æ·»åŠ å†…å®¹ç»Ÿè®¡
            result_metadata.update(self._analyze_proposal(proposal_content))
            
            processing_time = time.time() - start_time
            
            return ProcessingResult(
                content=proposal_content,
                metadata=result_metadata,
                source_type='proposal',
                processing_time=processing_time,
                model_used=stats.get('model_used', ''),
                tokens_consumed={
                    'input': stats.get('input_tokens', 0),
                    'output': stats.get('output_tokens', 0),
                    'total': stats.get('total_tokens', 0)
                }
            )
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ï¼š{e}")
            
            processing_time = time.time() - start_time
            
            return ProcessingResult(
                content='',
                metadata={
                    'error': str(e),
                    'proposal_type': template,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                },
                source_type='proposal',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )
    
    def _process_capability_docs(self, 
                               doc_paths: List[Union[str, Path]], 
                               progress_callback=None) -> str:
        """å¤„ç†ä¼ä¸šèƒ½åŠ›æ–‡æ¡£"""
        capability_parts = []
        
        for i, doc_path in enumerate(doc_paths):
            if progress_callback:
                progress_callback(f"æ­£åœ¨å¤„ç†èƒ½åŠ›æ–‡æ¡£ {i + 1}/{len(doc_paths)}")
            
            # ä½¿ç”¨æ–‡æ¡£æœåŠ¡å¤„ç†æ–‡æ¡£
            result = self.document_service.process(doc_path)
            
            if result.is_success:
                doc_name = Path(doc_path).name
                capability_parts.append(f"## æ–‡æ¡£ï¼š{doc_name}\n\n{result.content}")
            else:
                print(f"å¤„ç†èƒ½åŠ›æ–‡æ¡£å¤±è´¥ {doc_path}: {result.error}")
        
        if capability_parts:
            return "\n\n---\n\n".join(capability_parts)
        
        return ""
    
    def _get_default_prompt(self, 
                          analysis_report: str, 
                          template: str,
                          capability_content: str,
                          options: Dict) -> str:
        """è·å–é»˜è®¤çš„æ–¹æ¡ˆç”Ÿæˆæç¤ºè¯"""
        proposal_info = self.get_proposal_type_info(template)
        proposal_name = proposal_info.get('name', 'å•†ä¸šæ–¹æ¡ˆ')
        sections = proposal_info.get('sections', [])
        
        # æ„å»ºèƒ½åŠ›æ–‡æ¡£éƒ¨åˆ†
        capability_section = ""
        if capability_content:
            capability_section = f"""
## ä¸‰ã€ä¼ä¸šèƒ½åŠ›å‚è€ƒ

è¯·å‚è€ƒä»¥ä¸‹ä¼ä¸šèƒ½åŠ›ä¿¡æ¯ï¼Œåœ¨æ–¹æ¡ˆä¸­é€‚å½“å¼•ç”¨å’Œä½“ç°æˆ‘ä»¬çš„ä¼˜åŠ¿ï¼š

{capability_content}
"""
        
        return f"""# {proposal_name}ç”Ÿæˆä»»åŠ¡

## ä¸€ã€è§’è‰²å®šä½
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å•†ä¸šæ–¹æ¡ˆæ’°å†™ä¸“å®¶ï¼Œæ‹¥æœ‰15å¹´çš„æ–¹æ¡ˆç­–åˆ’ç»éªŒï¼Œæ“…é•¿å°†å¤æ‚çš„æŠ€æœ¯å’Œä¸šåŠ¡éœ€æ±‚è½¬åŒ–ä¸ºæ¸…æ™°ã€æœ‰è¯´æœåŠ›çš„å•†ä¸šæ–‡æ¡£ã€‚

## äºŒã€ä»»åŠ¡è¯´æ˜
åŸºäºä»¥ä¸‹åˆ†ææŠ¥å‘Šï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„{proposal_name}ã€‚

### åˆ†ææŠ¥å‘Šï¼š
{analysis_report}

{capability_section}

## å››ã€æ–¹æ¡ˆç»“æ„è¦æ±‚

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç”Ÿæˆæ–¹æ¡ˆï¼š
{chr(10).join(f'{i+1}. {section}' for i, section in enumerate(sections))}

## äº”ã€å†™ä½œè¦æ±‚

1. **ä¸“ä¸šæ€§**ï¼šä½¿ç”¨ä¸“ä¸šçš„å•†ä¸šè¯­è¨€ï¼Œé€»è¾‘æ¸…æ™°ï¼Œè®ºè¿°ä¸¥è°¨
2. **é’ˆå¯¹æ€§**ï¼šç´§å¯†ç»“åˆå®¢æˆ·éœ€æ±‚ï¼Œæä¾›å®šåˆ¶åŒ–çš„è§£å†³æ–¹æ¡ˆ
3. **å¯è¯»æ€§**ï¼šç»“æ„æ¸…æ™°ï¼Œé‡ç‚¹çªå‡ºï¼Œä¾¿äºå¿«é€Ÿç†è§£
4. **è¯´æœåŠ›**ï¼šçªå‡ºä»·å€¼ä¸»å¼ ï¼Œç”¨æ•°æ®å’Œæ¡ˆä¾‹æ”¯æ’‘è§‚ç‚¹
5. **å®Œæ•´æ€§**ï¼šæ¶µç›–æ‰€æœ‰å¿…è¦çš„å•†ä¸šè¦ç´ ï¼Œå½¢æˆå®Œæ•´çš„æ–¹æ¡ˆä½“ç³»

## å…­ã€æ ¼å¼è¦æ±‚

- ä½¿ç”¨Markdownæ ¼å¼
- æ ‡é¢˜å±‚çº§æ¸…æ™°ï¼ˆæœ€å¤šä½¿ç”¨ä¸‰çº§æ ‡é¢˜ï¼‰
- é‡è¦å†…å®¹ä½¿ç”¨åŠ ç²—æˆ–åˆ—è¡¨çªå‡º
- æ•°æ®ä½¿ç”¨è¡¨æ ¼å±•ç¤º
- ä¿æŒä¸“ä¸šçš„ç‰ˆå¼é£æ ¼

è¯·å¼€å§‹ç”Ÿæˆ{proposal_name}ï¼š"""
    
    def _format_proposal(self, raw_content: str, template: str, output_format: str) -> str:
        """æ ¼å¼åŒ–æ–¹æ¡ˆå†…å®¹"""
        if output_format == 'markdown':
            # ç¡®ä¿æ˜¯è§„èŒƒçš„Markdownæ ¼å¼
            if not raw_content.startswith('#'):
                proposal_name = self.PROPOSAL_TYPES.get(template, {}).get('name', 'å•†ä¸šæ–¹æ¡ˆ')
                raw_content = f"# {proposal_name}\n\n{raw_content}"
            
            # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
            lines = raw_content.split('\n')
            formatted_lines = []
            empty_count = 0
            
            for line in lines:
                if line.strip() == '':
                    empty_count += 1
                    if empty_count <= 2:  # æœ€å¤šä¿ç•™ä¸¤ä¸ªè¿ç»­ç©ºè¡Œ
                        formatted_lines.append(line)
                else:
                    empty_count = 0
                    formatted_lines.append(line)
            
            return '\n'.join(formatted_lines)
            
        elif output_format == 'text':
            # è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼
            # ç§»é™¤Markdownæ ‡è®°
            text = raw_content
            # ç§»é™¤æ ‡é¢˜æ ‡è®°
            text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
            # ç§»é™¤åŠ ç²—
            text = re.sub(r'\*\*([^\*]+)\*\*', r'\1', text)
            # ç§»é™¤å…¶ä»–Markdownå…ƒç´ 
            text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
            
            return text
        
        return raw_content
    
    def _add_footer(self, content: str, template: str) -> str:
        """æ·»åŠ é¡µè„šä¿¡æ¯"""
        footer = f"""

---

*æœ¬æ–¹æ¡ˆç”± SmartProposal Engine è‡ªåŠ¨ç”Ÿæˆ*  
*ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}*  
*æ–¹æ¡ˆç±»å‹ï¼š{self.PROPOSAL_TYPES.get(template, {}).get('name', template)}*  
*ç‰ˆæƒæ‰€æœ‰ Â© 2025 SmartProposal Team*
"""
        return content + footer
    
    def _analyze_proposal(self, content: str) -> Dict[str, Any]:
        """åˆ†ææ–¹æ¡ˆå†…å®¹ï¼Œæå–ç»Ÿè®¡ä¿¡æ¯"""
        # å­—æ•°ç»Ÿè®¡
        word_count = len(content.split())
        char_count = len(content)
        
        # æ®µè½å’Œç« èŠ‚ç»Ÿè®¡
        lines = content.split('\n')
        section_count = sum(1 for line in lines if line.strip().startswith('#'))
        paragraph_count = len([p for p in content.split('\n\n') if p.strip()])
        
        # ç‰¹æ®Šå…ƒç´ ç»Ÿè®¡
        table_count = content.count('|---')  # ç®€å•çš„è¡¨æ ¼æ£€æµ‹
        list_count = sum(1 for line in lines if line.strip().startswith(('- ', '* ', '1. ')))
        
        # é¢„ä¼°é˜…è¯»æ—¶é—´ï¼ˆå‡è®¾æ¯åˆ†é’Ÿé˜…è¯»200ä¸ªä¸­æ–‡å­—ï¼‰
        estimated_reading_time = max(1, char_count // 400)
        
        return {
            'word_count': word_count,
            'character_count': char_count,
            'section_count': section_count,
            'paragraph_count': paragraph_count,
            'table_count': table_count,
            'list_count': list_count,
            'estimated_reading_time_minutes': estimated_reading_time
        }
    
    def generate_proposal(self,
                         analysis_report: str,
                         proposal_type: str = 'project_proposal',
                         capability_docs: Optional[List[str]] = None,
                         progress_callback=None) -> Tuple[str, Dict[str, Any]]:
        """
        ç”Ÿæˆæ–¹æ¡ˆï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        
        Args:
            analysis_report: åˆ†ææŠ¥å‘Š
            proposal_type: æ–¹æ¡ˆç±»å‹
            capability_docs: èƒ½åŠ›æ–‡æ¡£åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒ
        
        Returns:
            (proposal_content, stats): æ–¹æ¡ˆå†…å®¹å’Œç»Ÿè®¡ä¿¡æ¯
        """
        result = self.process(
            analysis_report,
            template=proposal_type,
            options={
                'capability_docs': capability_docs,
                'progress_callback': progress_callback
            }
        )
        
        if result.error:
            return f"æ–¹æ¡ˆç”Ÿæˆå¤±è´¥ï¼š{result.error}", {
                'error': result.error,
                'generation_time': result.processing_time
            }
        
        stats = {
            'generation_time': result.processing_time,
            'input_tokens': result.tokens_consumed.get('input', 0),
            'output_tokens': result.tokens_consumed.get('output', 0),
            'model_used': result.model_used,
            'proposal_type': result.metadata.get('proposal_type', ''),
            'word_count': result.metadata.get('word_count', 0)
        }
        
        return result.content, stats
    
    def merge_capability_docs(self, doc_paths: List[Union[str, Path]]) -> str:
        """
        åˆå¹¶ä¼ä¸šèƒ½åŠ›æ–‡æ¡£
        
        Args:
            doc_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
        
        Returns:
            str: åˆå¹¶åçš„å†…å®¹
        """
        return self._process_capability_docs(doc_paths)
    
    def customize_proposal(self,
                         base_proposal: str,
                         customization_options: Dict[str, Any]) -> str:
        """
        å®šåˆ¶åŒ–æ–¹æ¡ˆ
        
        Args:
            base_proposal: åŸºç¡€æ–¹æ¡ˆ
            customization_options: å®šåˆ¶é€‰é¡¹
                - client_name: å®¢æˆ·åç§°
                - project_name: é¡¹ç›®åç§°
                - special_requirements: ç‰¹æ®Šè¦æ±‚
                - pricing_info: æŠ¥ä»·ä¿¡æ¯
        
        Returns:
            str: å®šåˆ¶åŒ–åçš„æ–¹æ¡ˆ
        """
        customized = base_proposal
        
        # æ›¿æ¢å®¢æˆ·åç§°
        if 'client_name' in customization_options:
            customized = customized.replace(
                '[å®¢æˆ·åç§°]', 
                customization_options['client_name']
            )
            customized = customized.replace(
                '[CLIENT_NAME]', 
                customization_options['client_name']
            )
        
        # æ›¿æ¢é¡¹ç›®åç§°
        if 'project_name' in customization_options:
            customized = customized.replace(
                '[é¡¹ç›®åç§°]',
                customization_options['project_name']
            )
        
        # æ·»åŠ ç‰¹æ®Šè¦æ±‚
        if 'special_requirements' in customization_options:
            requirements = customization_options['special_requirements']
            if isinstance(requirements, list):
                requirements_text = '\n'.join(f"- {req}" for req in requirements)
                customized = customized.replace(
                    '[ç‰¹æ®Šè¦æ±‚]',
                    requirements_text
                )
        
        # æ·»åŠ æŠ¥ä»·ä¿¡æ¯
        if 'pricing_info' in customization_options:
            pricing = customization_options['pricing_info']
            if isinstance(pricing, dict):
                total_price = pricing.get('total', 0)
                currency = pricing.get('currency', 'Â¥')
                customized = customized.replace(
                    '[æ€»ä»·]',
                    format_money(total_price, currency)
                )
        
        return customized
    
    def export_proposal(self,
                       proposal_content: str,
                       export_format: str = 'markdown',
                       file_path: Optional[Union[str, Path]] = None) -> str:
        """
        å¯¼å‡ºæ–¹æ¡ˆåˆ°æ–‡ä»¶
        
        Args:
            proposal_content: æ–¹æ¡ˆå†…å®¹
            export_format: å¯¼å‡ºæ ¼å¼ ('markdown', 'txt', 'json')
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
        
        Returns:
            str: å¯¼å‡ºçš„æ–‡ä»¶è·¯å¾„
        """
        if file_path is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            file_name = f"proposal_{timestamp}.{export_format}"
            file_path = os.path.join('output', file_name)
        
        file_path = Path(file_path)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        if export_format == 'json':
            # å¯¼å‡ºä¸ºJSONæ ¼å¼ï¼ˆåŒ…å«å…ƒæ•°æ®ï¼‰
            export_data = {
                'content': proposal_content,
                'metadata': {
                    'exported_at': datetime.now().isoformat(),
                    'format': export_format,
                    'engine': 'SmartProposal Engine',
                    'version': '1.0.0'
                }
            }
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
        else:
            # å¯¼å‡ºä¸ºæ–‡æœ¬æ ¼å¼
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(proposal_content)
        
        return str(file_path)
    
    def get_proposal_outline(self, proposal_type: str) -> List[Dict[str, Any]]:
        """
        è·å–æ–¹æ¡ˆå¤§çº²
        
        Args:
            proposal_type: æ–¹æ¡ˆç±»å‹
        
        Returns:
            List[Dict]: å¤§çº²ç»“æ„
        """
        proposal_info = self.get_proposal_type_info(proposal_type)
        sections = proposal_info.get('sections', [])
        
        outline = []
        for i, section in enumerate(sections):
            outline.append({
                'level': 1,
                'title': section,
                'number': f"{i + 1}",
                'description': self._get_section_description(proposal_type, section)
            })
        
        return outline
    
    def _get_section_description(self, proposal_type: str, section: str) -> str:
        """è·å–ç« èŠ‚æè¿°"""
        # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºä»é…ç½®æˆ–æ¨¡æ¿ä¸­è¯»å–è¯¦ç»†æè¿°
        descriptions = {
            'æ‰§è¡Œæ‘˜è¦': 'é¡¹ç›®çš„æ ¸å¿ƒä»·å€¼å’Œå…³é”®è¦ç‚¹æ¦‚è¿°',
            'éœ€æ±‚åˆ†æ': 'æ·±å…¥ç†è§£å®¢æˆ·éœ€æ±‚å’Œä¸šåŠ¡æŒ‘æˆ˜',
            'è§£å†³æ–¹æ¡ˆ': 'é’ˆå¯¹æ€§çš„æŠ€æœ¯å’Œä¸šåŠ¡è§£å†³æ–¹æ¡ˆ',
            'å®æ–½è®¡åˆ’': 'è¯¦ç»†çš„é¡¹ç›®å®æ–½æ­¥éª¤å’Œæ—¶é—´å®‰æ’',
            'æŠ•èµ„å›æŠ¥': 'é¡¹ç›®çš„æˆæœ¬æ•ˆç›Šåˆ†æå’ŒROIè®¡ç®—',
            'å›¢é˜Ÿä»‹ç»': 'é¡¹ç›®å›¢é˜Ÿçš„ä¸“ä¸šèƒŒæ™¯å’ŒæˆåŠŸç»éªŒ',
            'å•†åŠ¡æ¡æ¬¾': 'åˆä½œæ¡æ¬¾ã€ä»˜æ¬¾æ–¹å¼å’ŒæœåŠ¡æ‰¿è¯º'
        }
        
        return descriptions.get(section, f'{section}çš„è¯¦ç»†å†…å®¹')

--- File: services/transcription_service.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/services/transcription_service.py
åŠŸèƒ½è¯´æ˜: éŸ³é¢‘è½¬å½•æœåŠ¡æ¨¡å—ï¼Œè´Ÿè´£å¤„ç†éŸ³é¢‘æ–‡ä»¶çš„è½¬å½•å’Œä¼˜åŒ–
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import time
import re
import shutil
import tempfile
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union, Literal
from dataclasses import dataclass
from pathlib import Path

import google.generativeai as genai

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.base_service import BaseService, ProcessingResult
from core.prompt_manager import PromptManager
from core.model_interface import ModelInterface
from utils.file_utils import format_file_size, get_audio_duration
from utils.format_utils import format_duration


@dataclass
class TranscriptionSegment:
    """è½¬å½•ç‰‡æ®µæ•°æ®ç»“æ„"""
    segment_index: int
    start_time: float
    end_time: float
    text: str
    speakers: List[str]
    segment_id: str = ""


@dataclass
class SpeakerMapping:
    """è¯´è¯äººæ˜ å°„æ•°æ®ç»“æ„"""
    segment_speaker: str
    global_speaker: str
    characteristics: str


class TextOptimizer:
    """æ–‡æœ¬ä¼˜åŒ–å™¨ï¼Œä½¿ç”¨Geminiè¿›è¡Œè½¬å½•æ–‡æœ¬çš„æ ¡æ­£å’Œä¼˜åŒ–"""

    def __init__(self, model_interface: ModelInterface, prompt_manager: PromptManager):
        self.model_interface = model_interface
        self.prompt_manager = prompt_manager

    def optimize_transcript(self, original_text: str, progress_callback=None) -> Tuple[str, Dict[str, any]]:
        """ä¼˜åŒ–è½¬å½•æ–‡æœ¬"""
        start_time = time.time()

        if progress_callback:
            progress_callback("æ­£åœ¨è°ƒç”¨Geminiè¿›è¡Œæ–‡æœ¬ä¼˜åŒ–...")

        try:
            # è·å–ä¼˜åŒ–æ¨¡æ¿
            optimization_prompt = self.prompt_manager.get_template(
                'transcription',
                'optimization',
                variables={'transcript': original_text}
            )

            # è°ƒç”¨æ¨¡å‹
            response, stats = self.model_interface.generate_content(
                optimization_prompt,
                model_type='optimization'
            )

            stats['optimization_time'] = time.time() - start_time

            # è§£æä¼˜åŒ–ç»“æœ
            full_response = response
            if "ç¬¬äºŒéƒ¨åˆ†ï¼šä¼˜åŒ–åè½¬å½•æ–‡æœ¬" in full_response:
                parts = full_response.split("ç¬¬äºŒéƒ¨åˆ†ï¼šä¼˜åŒ–åè½¬å½•æ–‡æœ¬")
                if len(parts) > 1:
                    optimized_text = parts[1].strip()
                    optimized_text = optimized_text.replace("```", "").strip()
                else:
                    optimized_text = full_response
            else:
                optimized_text = full_response

            if progress_callback:
                progress_callback(f"æ–‡æœ¬ä¼˜åŒ–å®Œæˆï¼Œè€—æ—¶ {stats['optimization_time']:.1f} ç§’")

            return optimized_text, stats

        except Exception as e:
            if progress_callback:
                progress_callback(f"æ–‡æœ¬ä¼˜åŒ–å¤±è´¥ï¼š{e}")
            return original_text, {'error': str(e), 'optimization_time': time.time() - start_time}


class AudioProcessor:
    """éŸ³é¢‘å¤„ç†ç±»ï¼Œè´Ÿè´£éŸ³é¢‘æ–‡ä»¶çš„åˆ†å‰²å’Œé¢„å¤„ç†"""

    def __init__(self, temp_folder: str):
        self.temp_folder = temp_folder
        self.pydub_available = self._check_pydub_availability()
        self.silence_threshold = -35
        self.min_silence_length = 800

    def _check_pydub_availability(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å®‰è£…äº† pydub åº“"""
        try:
            import pydub
            return True
        except ImportError:
            print("æ³¨æ„ï¼šæœªå®‰è£… pydub åº“ï¼Œæ— æ³•è¿›è¡ŒéŸ³é¢‘åˆ†å‰²ã€‚")
            print("å¦‚éœ€å¤„ç†è¶…é•¿éŸ³é¢‘ï¼Œè¯·è¿è¡Œï¼špip install pydub")
            return False

    def get_audio_duration(self, file_path: str) -> Optional[float]:
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰"""
        if not self.pydub_available:
            return None

        try:
            from pydub import AudioSegment
            audio = AudioSegment.from_file(file_path)
            duration_minutes = len(audio) / (1000 * 60)
            return duration_minutes
        except Exception as e:
            print(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼š{e}")
            return None

    def get_audio_duration_seconds(self, file_path: str) -> Optional[float]:
        """è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰"""
        if not self.pydub_available:
            return None

        try:
            from pydub import AudioSegment
            audio = AudioSegment.from_file(file_path)
            duration_seconds = len(audio) / 1000.0
            return duration_seconds
        except Exception as e:
            print(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼š{e}")
            return None

    def split_audio(self, file_path: str, max_duration_minutes: int) -> List[Tuple[str, float, float]]:
        """å°†éŸ³é¢‘æ–‡ä»¶æŒ‰åˆ†é’Ÿåˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ"""
        if not self.pydub_available:
            return [(file_path, 0, 0)]

        try:
            from pydub import AudioSegment
            from pydub.silence import detect_silence

            print(f"æ­£åœ¨åˆ†æéŸ³é¢‘æ–‡ä»¶...")
            audio = AudioSegment.from_file(file_path)
            total_duration = len(audio)
            max_duration_ms = max_duration_minutes * 60 * 1000

            if total_duration <= max_duration_ms:
                return [(file_path, 0, total_duration / 1000)]

            os.makedirs(self.temp_folder, exist_ok=True)

            print("æ­£åœ¨æ£€æµ‹é™éŸ³ç‰‡æ®µä»¥ä¼˜åŒ–åˆ†å‰²ç‚¹...")
            silence_chunks = detect_silence(
                audio,
                min_silence_len=self.min_silence_length,
                silence_thresh=self.silence_threshold
            )

            segments = []
            current_start = 0
            segment_index = 0

            while current_start < total_duration:
                ideal_end = min(current_start + max_duration_ms, total_duration)
                best_split_point = ideal_end
                search_window = 30000

                for silence_start, silence_end in silence_chunks:
                    if ideal_end - search_window <= silence_start <= ideal_end + search_window:
                        best_split_point = silence_start
                        break

                if best_split_point >= total_duration - 5000:
                    best_split_point = total_duration

                segment = audio[current_start:best_split_point]
                segment_filename = f"segment_{segment_index:03d}.m4a"
                segment_path = os.path.join(self.temp_folder, segment_filename)

                print(f"æ­£åœ¨å¯¼å‡ºç‰‡æ®µ {segment_index + 1}: {current_start / 1000:.1f}s - {best_split_point / 1000:.1f}s")
                segment.export(segment_path, format="mp4", codec="aac")

                segments.append((
                    segment_path,
                    current_start / 1000,
                    best_split_point / 1000
                ))

                current_start = best_split_point
                segment_index += 1

            print(f"éŸ³é¢‘åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(segments)} ä¸ªç‰‡æ®µ")
            return segments

        except Exception as e:
            print(f"éŸ³é¢‘åˆ†å‰²å¤±è´¥ï¼š{e}")
            return [(file_path, 0, 0)]

    def cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if os.path.exists(self.temp_folder):
            try:
                shutil.rmtree(self.temp_folder)
                print("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ï¼š{e}")


class SpeakerAnalyzer:
    """è¯´è¯äººåˆ†æå™¨ï¼Œè´Ÿè´£å¤„ç†è¯´è¯äººè¯†åˆ«å’Œä¸€è‡´æ€§ç»´æŠ¤"""

    def __init__(self):
        self.global_speaker_map: Dict[str, str] = {}
        self.speaker_characteristics: Dict[str, List[str]] = {}
        self.next_global_speaker_id = 1

    def extract_speakers(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–è¯´è¯äººæ ‡è¯†"""
        speaker_pattern = r'(è¯´è¯äºº[A-Z]|è¯´è¯äºº\d+|å‘è¨€äºº[A-Z]|å‘è¨€äºº\d+|Speaker [A-Z]|Speaker \d+)(?=[:ï¼š])'
        speakers = list(set(re.findall(speaker_pattern, text)))
        return speakers

    def extract_speaker_characteristics(self, text: str, speaker: str) -> List[str]:
        """æå–è¯´è¯äººçš„è¯­è¨€ç‰¹å¾"""
        characteristics = []

        pattern = f'{re.escape(speaker)}[:ï¼š](.*?)(?=(è¯´è¯äºº|å‘è¨€äºº|Speaker|$))'
        matches = re.findall(pattern, text, re.DOTALL)

        if matches:
            combined_text = ' '.join(matches)

            # æå–å¸¸ç”¨è¯
            words = re.findall(r'[\u4e00-\u9fa5]+', combined_text)
            word_freq = {}
            for word in words:
                if len(word) >= 2:
                    word_freq[word] = word_freq.get(word, 0) + 1

            frequent_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
            if frequent_words:
                characteristics.append(f"å¸¸ç”¨è¯ï¼š{', '.join([w[0] for w in frequent_words])}")

            # è¯­è¨€ç‰¹å¾åˆ†æ
            if 'å—¯' in combined_text or 'å•Š' in combined_text or 'å‘ƒ' in combined_text:
                characteristics.append("æœ‰å£å¤´ç¦…")
            if 'è¯·' in combined_text or 'è°¢è°¢' in combined_text:
                characteristics.append("ç¤¼è²Œç”¨è¯­å¤š")
            if 'æˆ‘è§‰å¾—' in combined_text or 'æˆ‘è®¤ä¸º' in combined_text:
                characteristics.append("ä¸»è§‚è¡¨è¾¾å¤š")

        return characteristics

    def map_speakers_across_segments(self, segments: List[TranscriptionSegment]) -> Dict[str, str]:
        """è·¨ç‰‡æ®µæ˜ å°„è¯´è¯äººï¼Œä¿æŒä¸€è‡´æ€§"""
        print("\næ­£åœ¨åˆ†æè¯´è¯äººç‰¹å¾ä»¥ä¿æŒä¸€è‡´æ€§...")

        for segment in segments:
            for speaker in segment.speakers:
                characteristics = self.extract_speaker_characteristics(segment.text, speaker)

                best_match = None
                best_score = 0

                for global_speaker, char_list in self.speaker_characteristics.items():
                    score = len(set(characteristics) & set(char_list))
                    if score > best_score:
                        best_score = score
                        best_match = global_speaker

                if best_score >= 2:
                    self.global_speaker_map[f"{segment.segment_index}_{speaker}"] = best_match
                    self.speaker_characteristics[best_match].extend(characteristics)
                    self.speaker_characteristics[best_match] = list(set(self.speaker_characteristics[best_match]))
                else:
                    global_speaker = f"è¯´è¯äºº{self.next_global_speaker_id}"
                    self.next_global_speaker_id += 1
                    self.global_speaker_map[f"{segment.segment_index}_{speaker}"] = global_speaker
                    self.speaker_characteristics[global_speaker] = characteristics

        return self.global_speaker_map

    def apply_speaker_mapping(self, segment: TranscriptionSegment, mapping: Dict[str, str]) -> str:
        """åº”ç”¨è¯´è¯äººæ˜ å°„åˆ°è½¬å½•æ–‡æœ¬"""
        text = segment.text

        for speaker in segment.speakers:
            segment_key = f"{segment.segment_index}_{speaker}"
            if segment_key in mapping:
                global_speaker = mapping[segment_key]
                text = text.replace(f"{speaker}:", f"{global_speaker}:")
                text = text.replace(f"{speaker}ï¼š", f"{global_speaker}ï¼š")

        return text


class TranscriptionService(BaseService):
    """
    éŸ³é¢‘è½¬å½•æœåŠ¡

    ä¸»è¦åŠŸèƒ½:
    - æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼çš„è½¬å½•
    - æ”¯æŒè¶…é•¿éŸ³é¢‘è‡ªåŠ¨åˆ†å‰²
    - æ”¯æŒå¤šäººå¯¹è¯è¯†åˆ«
    - æ”¯æŒæ–‡æœ¬ä¼˜åŒ–

    ä½¿ç”¨ç¤ºä¾‹:
        service = TranscriptionService()
        result = service.process(audio_file, options)
    """

    def __init__(self):
        super().__init__()
        self.audio_processor = None
        self.text_optimizer = None
        self.speaker_analyzer = None
        self.prompt_manager = PromptManager()
        self.model_interface = ModelInterface()
        self.temp_folder = "temp_segments"
        self.max_retries = 3
        self.delete_uploaded_files = True

    def get_available_templates(self) -> List[str]:
        """è·å–å¯ç”¨çš„è½¬å½•ä¼˜åŒ–æ¨¡æ¿"""
        return self.prompt_manager.list_templates('transcription')

    def validate_input(self, input_data: Union[str, bytes, Path]) -> bool:
        """éªŒè¯è¾“å…¥æ˜¯å¦ä¸ºæ”¯æŒçš„éŸ³é¢‘æ ¼å¼"""
        if isinstance(input_data, str):
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            supported_formats = ['.m4a', '.mp3', '.wav', '.aac', '.ogg', '.flac', '.mp4']
            return any(input_data.lower().endswith(fmt) for fmt in supported_formats)
        return True

    def process(self,
                input_data: Union[str, bytes, Path],
                template: Optional[str] = None,
                options: Optional[Dict] = None) -> ProcessingResult:
        """
        å¤„ç†éŸ³é¢‘æ–‡ä»¶è½¬å½•

        Args:
            input_data: éŸ³é¢‘æ–‡ä»¶è·¯å¾„æˆ–æ•°æ®
            template: è½¬å½•æ¨¡æ¿ï¼ˆæœªä½¿ç”¨ï¼Œä¿æŒæ¥å£ä¸€è‡´ï¼‰
            options: å¤„ç†é€‰é¡¹
                - enable_speaker_diarization: æ˜¯å¦å¯ç”¨è¯´è¯äººè¯†åˆ«
                - maintain_speaker_consistency: æ˜¯å¦ä¿æŒè¯´è¯äººä¸€è‡´æ€§
                - max_segment_duration_minutes: æœ€å¤§ç‰‡æ®µæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
                - enable_text_optimization: æ˜¯å¦å¯ç”¨æ–‡æœ¬ä¼˜åŒ–
                - mode: è¿è¡Œæ¨¡å¼ ("standard", "enhanced")

        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        start_time = time.time()

        # è§£æé€‰é¡¹
        options = options or {}
        enable_speaker_diarization = options.get('enable_speaker_diarization', True)
        maintain_speaker_consistency = options.get('maintain_speaker_consistency', True)
        max_segment_duration_minutes = options.get('max_segment_duration_minutes', 20)
        enable_text_optimization = options.get('enable_text_optimization', False)
        mode = options.get('mode', 'standard')
        progress_callback = options.get('progress_callback', None)

        try:
            # ç¡®ä¿è¾“å…¥æ˜¯æ–‡ä»¶è·¯å¾„
            if isinstance(input_data, (bytes, str)) and not os.path.exists(str(input_data)):
                # å¦‚æœæ˜¯å­—èŠ‚æ•°æ®ï¼Œå…ˆä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix='.m4a') as tmp_file:
                    if isinstance(input_data, bytes):
                        tmp_file.write(input_data)
                    file_path = tmp_file.name
            else:
                file_path = str(input_data)

            # åˆå§‹åŒ–å¤„ç†å™¨
            self.audio_processor = AudioProcessor(self.temp_folder)
            if enable_text_optimization:
                self.text_optimizer = TextOptimizer(self.model_interface, self.prompt_manager)
            if enable_speaker_diarization and maintain_speaker_consistency:
                self.speaker_analyzer = SpeakerAnalyzer()

            # è·å–æ–‡ä»¶ä¿¡æ¯
            file_size = os.path.getsize(file_path)
            duration_minutes = self.audio_processor.get_audio_duration(file_path)
            duration_seconds = duration_minutes * 60 if duration_minutes else None

            # æ‰§è¡Œè½¬å½•
            transcribed_text, metadata = self._transcribe_audio(
                file_path=file_path,
                duration_minutes=duration_minutes,
                enable_speaker_diarization=enable_speaker_diarization,
                maintain_speaker_consistency=maintain_speaker_consistency,
                max_segment_duration_minutes=max_segment_duration_minutes,
                enable_text_optimization=enable_text_optimization,
                progress_callback=progress_callback
            )

            # æ„å»ºå…ƒæ•°æ®
            metadata.update({
                'original_file': os.path.basename(file_path),
                'file_size': format_file_size(file_size),
                'duration': format_duration(duration_seconds) if duration_seconds else 'æœªçŸ¥',
                'processing_mode': mode,
                'enable_text_optimization': enable_text_optimization
            })

            # ç»Ÿè®¡è¯´è¯äººä¿¡æ¯
            if transcribed_text and enable_speaker_diarization:
                speakers = self.speaker_analyzer.extract_speakers(transcribed_text) if self.speaker_analyzer else []
                metadata['speakers_count'] = len(speakers)
                metadata['speakers'] = sorted(speakers)

            processing_time = time.time() - start_time

            return ProcessingResult(
                content=transcribed_text,
                metadata=metadata,
                source_type='audio',
                processing_time=processing_time,
                model_used=metadata.get('model_used', ''),
                tokens_consumed={
                    'input': metadata.get('input_tokens', 0),
                    'output': metadata.get('output_tokens', 0),
                    'total': metadata.get('total_tokens', 0)
                }
            )

        except Exception as e:
            processing_time = time.time() - start_time
            return ProcessingResult(
                content='',
                metadata={'error': str(e)},
                source_type='audio',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )
        finally:
            # æ¸…ç†èµ„æº
            if self.audio_processor:
                self.audio_processor.cleanup_temp_files()

    def _transcribe_audio(self,
                          file_path: str,
                          duration_minutes: Optional[float],
                          enable_speaker_diarization: bool,
                          maintain_speaker_consistency: bool,
                          max_segment_duration_minutes: int,
                          enable_text_optimization: bool,
                          progress_callback) -> Tuple[str, Dict]:
        """å†…éƒ¨æ–¹æ³•ï¼šæ‰§è¡ŒéŸ³é¢‘è½¬å½•"""

        total_input_tokens = 0
        total_output_tokens = 0
        model_used = self.model_interface.get_model_name('transcription')

        # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†å‰²
        if duration_minutes and duration_minutes > max_segment_duration_minutes:
            if progress_callback:
                progress_callback(f"æ£€æµ‹åˆ°é•¿éŸ³é¢‘æ–‡ä»¶ï¼ˆ{format_duration(duration_minutes * 60)}ï¼‰ï¼Œå°†è¿›è¡Œåˆ†æ®µå¤„ç†...")

            segments_info = self.audio_processor.split_audio(file_path, max_segment_duration_minutes)

            if len(segments_info) == 1:
                # æ— éœ€åˆ†å‰²
                transcribed_text, tokens = self._transcribe_single_segment(
                    segments_info[0][0],
                    enable_speaker_diarization,
                    progress_callback
                )
                total_input_tokens += tokens['input']
                total_output_tokens += tokens['output']
            else:
                # å¤šæ®µå¤„ç†
                transcription_segments = []
                for i, (segment_path, start_time, end_time) in enumerate(segments_info):
                    if progress_callback:
                        progress_callback(f"æ­£åœ¨å¤„ç†ç‰‡æ®µ {i + 1}/{len(segments_info)}...")

                    segment_text, tokens = self._transcribe_single_segment(
                        segment_path,
                        enable_speaker_diarization,
                        progress_callback
                    )

                    total_input_tokens += tokens['input']
                    total_output_tokens += tokens['output']

                    if segment_text:
                        segment = TranscriptionSegment(
                            segment_index=i,
                            start_time=start_time,
                            end_time=end_time,
                            text=segment_text,
                            speakers=self.speaker_analyzer.extract_speakers(
                                segment_text) if self.speaker_analyzer else [],
                            segment_id=f"seg{i:03d}"
                        )
                        transcription_segments.append(segment)

                    if i < len(segments_info) - 1:
                        time.sleep(3)

                # å¤„ç†è¯´è¯äººä¸€è‡´æ€§
                speaker_mapping = {}
                if maintain_speaker_consistency and self.speaker_analyzer and transcription_segments:
                    speaker_mapping = self.speaker_analyzer.map_speakers_across_segments(transcription_segments)

                # åˆå¹¶ç»“æœ
                transcribed_text = self._merge_segments(transcription_segments, speaker_mapping, duration_minutes)
        else:
            # çŸ­éŸ³é¢‘ç›´æ¥å¤„ç†
            transcribed_text, tokens = self._transcribe_single_segment(
                file_path,
                enable_speaker_diarization,
                progress_callback
            )
            total_input_tokens += tokens['input']
            total_output_tokens += tokens['output']

        # æ–‡æœ¬ä¼˜åŒ–
        original_text = transcribed_text
        if enable_text_optimization and self.text_optimizer and transcribed_text:
            optimized_text, opt_stats = self.text_optimizer.optimize_transcript(
                transcribed_text,
                progress_callback
            )
            if not opt_stats.get('error'):
                transcribed_text = optimized_text
                total_input_tokens += opt_stats.get('input_tokens', 0)
                total_output_tokens += opt_stats.get('output_tokens', 0)

        # æ„å»ºå…ƒæ•°æ®
        metadata = {
            'model_used': model_used,
            'input_tokens': total_input_tokens,
            'output_tokens': total_output_tokens,
            'total_tokens': total_input_tokens + total_output_tokens,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }

        if enable_text_optimization:
            metadata['original_text'] = original_text
            metadata['optimized_text'] = transcribed_text

        # è®¡ç®—è´¹ç”¨
        cost = self.model_interface.calculate_cost(
            total_input_tokens,
            total_output_tokens,
            'transcription'
        )
        metadata['estimated_cost'] = cost

        return transcribed_text, metadata

    def _transcribe_single_segment(self,
                                   file_path: str,
                                   enable_speaker_diarization: bool,
                                   progress_callback,
                                   retry_count: int = 0) -> Tuple[str, Dict[str, int]]:
        """è½¬å½•å•ä¸ªéŸ³é¢‘ç‰‡æ®µ"""

        audio_file = None

        try:
            # ä¸Šä¼ æ–‡ä»¶
            if progress_callback:
                progress_callback("æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ° Google...")

            try:
                audio_file = genai.upload_file(path=file_path)
            except Exception as e:
                if retry_count < self.max_retries:
                    time.sleep(2 ** retry_count)
                    return self._transcribe_single_segment(
                        file_path, enable_speaker_diarization,
                        progress_callback, retry_count + 1
                    )
                else:
                    raise Exception(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")

            # ç­‰å¾…æ–‡ä»¶å¤„ç†
            while audio_file.state.name == "PROCESSING":
                time.sleep(10)
                audio_file = genai.get_file(audio_file.name)

            if audio_file.state.name == "FAILED":
                raise Exception(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {audio_file.state}")

            # è·å–è½¬å½•æç¤ºè¯
            if enable_speaker_diarization:
                prompt = self.prompt_manager.get_template('transcription', 'multi_speaker')
            else:
                prompt = self.prompt_manager.get_template('transcription', 'single_speaker')

            if progress_callback:
                progress_callback(f"æ­£åœ¨è°ƒç”¨æ¨¡å‹è¿›è¡Œè½¬å½•...")

            # è°ƒç”¨æ¨¡å‹
            response, stats = self.model_interface.generate_content(
                [prompt, audio_file],
                model_type='transcription'
            )

            return response, {
                'input': stats.get('input_tokens', 0),
                'output': stats.get('output_tokens', 0)
            }

        except Exception as e:
            if retry_count < self.max_retries:
                time.sleep(2 ** retry_count)
                return self._transcribe_single_segment(
                    file_path, enable_speaker_diarization,
                    progress_callback, retry_count + 1
                )
            else:
                raise Exception(f"è½¬å½•å¤±è´¥: {e}")

        finally:
            # æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
            if audio_file and self.delete_uploaded_files:
                try:
                    genai.delete_file(audio_file.name)
                except:
                    pass

    def _merge_segments(self,
                        segments: List[TranscriptionSegment],
                        speaker_mapping: Dict[str, str],
                        duration_minutes: Optional[float]) -> str:
        """åˆå¹¶è½¬å½•ç‰‡æ®µ"""
        if not segments:
            return ""

        final_text_parts = []

        # æ·»åŠ æ‘˜è¦ä¿¡æ¯
        if speaker_mapping:
            unique_speakers = set(speaker_mapping.values())
            summary = f"===== è½¬å½•æ‘˜è¦ =====\n"
            summary += f"æ€»æ—¶é•¿ï¼š{format_duration(duration_minutes * 60) if duration_minutes else 'æœªçŸ¥'}\n"
            summary += f"è¯†åˆ«åˆ°çš„è¯´è¯äººæ•°ï¼š{len(unique_speakers)}\n"
            summary += f"è¯´è¯äººåˆ—è¡¨ï¼š{', '.join(sorted(unique_speakers))}\n"
            summary += "=" * 50 + "\n"
            final_text_parts.append(summary)

        # å¤„ç†æ¯ä¸ªç‰‡æ®µ
        for segment in segments:
            # æ·»åŠ æ—¶é—´æˆ³æ ‡è®°
            time_marker = f"\n[{format_duration(segment.start_time)} - {format_duration(segment.end_time)}]\n"
            final_text_parts.append(time_marker)

            # åº”ç”¨è¯´è¯äººæ˜ å°„
            if speaker_mapping and self.speaker_analyzer:
                mapped_text = self.speaker_analyzer.apply_speaker_mapping(segment, speaker_mapping)
                final_text_parts.append(mapped_text)
            else:
                final_text_parts.append(segment.text)

        return "\n".join(final_text_parts)

    def process_web_text(self, text: str, options: Optional[Dict] = None) -> ProcessingResult:
        """
        å¤„ç†Webè¾“å…¥çš„æ–‡æœ¬ï¼ˆé¢„ç•™æ¥å£ï¼‰

        Args:
            text: è¾“å…¥çš„æ–‡æœ¬å†…å®¹
            options: å¤„ç†é€‰é¡¹

        Returns:
            ProcessingResult: å¤„ç†ç»“æœ
        """
        # å¯¹äºçº¯æ–‡æœ¬è¾“å…¥ï¼Œå¦‚æœéœ€è¦ä¼˜åŒ–ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨æ–‡æœ¬ä¼˜åŒ–å™¨
        start_time = time.time()
        options = options or {}

        try:
            if options.get('enable_text_optimization', False):
                if not self.text_optimizer:
                    self.text_optimizer = TextOptimizer(self.model_interface, self.prompt_manager)

                optimized_text, stats = self.text_optimizer.optimize_transcript(
                    text,
                    options.get('progress_callback')
                )

                metadata = {
                    'original_text': text,
                    'optimized_text': optimized_text,
                    'optimization_stats': stats,
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

                content = optimized_text
            else:
                content = text
                metadata = {
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }

            processing_time = time.time() - start_time

            return ProcessingResult(
                content=content,
                metadata=metadata,
                source_type='text',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={}
            )

        except Exception as e:
            processing_time = time.time() - start_time
            return ProcessingResult(
                content=text,
                metadata={'error': str(e)},
                source_type='text',
                processing_time=processing_time,
                model_used='',
                tokens_consumed={},
                error=str(e)
            )

--- File: utils/__init__.py ---

--- File: utils/file_utils.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/utils/file_utils.py
åŠŸèƒ½è¯´æ˜: æ–‡ä»¶å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import shutil
import tempfile
import hashlib
import mimetypes
from pathlib import Path
from typing import Optional, Tuple, List, Dict, Union
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


# æ–‡ä»¶å¤§å°å•ä½
SIZE_UNITS = ['B', 'KB', 'MB', 'GB', 'TB']

# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_AUDIO_FORMATS = ['.m4a', '.mp3', '.wav', '.aac', '.ogg', '.flac', '.mp4', '.wma', '.opus']
SUPPORTED_DOCUMENT_FORMATS = ['.docx', '.pdf', '.txt', '.doc', '.rtf', '.odt']
SUPPORTED_IMAGE_FORMATS = ['.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff', '.svg']
SUPPORTED_VIDEO_FORMATS = ['.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm']


def format_file_size(size_bytes: int) -> str:
    """
    æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º
    
    Args:
        size_bytes: å­—èŠ‚æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„å¤§å°å­—ç¬¦ä¸²ï¼ˆå¦‚ "1.5 MB"ï¼‰
    """
    if size_bytes == 0:
        return "0 B"
    
    size = float(size_bytes)
    unit_index = 0
    
    while size >= 1024 and unit_index < len(SIZE_UNITS) - 1:
        size /= 1024
        unit_index += 1
    
    # æ ¹æ®å¤§å°å†³å®šå°æ•°ä½æ•°
    if unit_index == 0:  # å­—èŠ‚
        return f"{int(size)} {SIZE_UNITS[unit_index]}"
    elif size >= 100:
        return f"{size:.0f} {SIZE_UNITS[unit_index]}"
    elif size >= 10:
        return f"{size:.1f} {SIZE_UNITS[unit_index]}"
    else:
        return f"{size:.2f} {SIZE_UNITS[unit_index]}"


def get_file_extension(file_path: Union[str, Path]) -> str:
    """
    è·å–æ–‡ä»¶æ‰©å±•åï¼ˆå°å†™ï¼‰
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        str: å°å†™çš„æ–‡ä»¶æ‰©å±•åï¼ˆåŒ…å«ç‚¹å·ï¼‰
    """
    return Path(file_path).suffix.lower()


def get_file_type(file_path: Union[str, Path]) -> str:
    """
    åˆ¤æ–­æ–‡ä»¶ç±»å‹
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        str: æ–‡ä»¶ç±»å‹ ('audio', 'document', 'image', 'video', 'unknown')
    """
    ext = get_file_extension(file_path)
    
    if ext in SUPPORTED_AUDIO_FORMATS:
        return 'audio'
    elif ext in SUPPORTED_DOCUMENT_FORMATS:
        return 'document'
    elif ext in SUPPORTED_IMAGE_FORMATS:
        return 'image'
    elif ext in SUPPORTED_VIDEO_FORMATS:
        return 'video'
    else:
        return 'unknown'


def validate_file_size(file_path: Union[str, Path], max_size_mb: float = 200) -> Tuple[bool, str]:
    """
    éªŒè¯æ–‡ä»¶å¤§å°æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        max_size_mb: æœ€å¤§å…è®¸å¤§å°ï¼ˆMBï¼‰
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    try:
        file_size = os.path.getsize(file_path)
        max_size_bytes = max_size_mb * 1024 * 1024
        
        if file_size > max_size_bytes:
            return False, f"æ–‡ä»¶å¤ªå¤§ï¼ˆ{format_file_size(file_size)}ï¼‰ï¼Œæœ€å¤§å…è®¸ {max_size_mb} MB"
        
        return True, f"æ–‡ä»¶å¤§å°: {format_file_size(file_size)}"
        
    except Exception as e:
        return False, f"æ— æ³•è·å–æ–‡ä»¶å¤§å°: {str(e)}"


def validate_file_format(file_path: Union[str, Path], allowed_formats: List[str]) -> Tuple[bool, str]:
    """
    éªŒè¯æ–‡ä»¶æ ¼å¼æ˜¯å¦å…è®¸
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        allowed_formats: å…è®¸çš„æ ¼å¼åˆ—è¡¨
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    ext = get_file_extension(file_path)
    
    if ext in allowed_formats:
        return True, f"æ–‡ä»¶æ ¼å¼: {ext}"
    else:
        return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}ï¼Œå…è®¸çš„æ ¼å¼: {', '.join(allowed_formats)}"


def create_temp_directory(prefix: str = "smartproposal_") -> str:
    """
    åˆ›å»ºä¸´æ—¶ç›®å½•
    
    Args:
        prefix: ç›®å½•å‰ç¼€
    
    Returns:
        str: ä¸´æ—¶ç›®å½•è·¯å¾„
    """
    temp_dir = tempfile.mkdtemp(prefix=prefix)
    return temp_dir


def cleanup_directory(directory: Union[str, Path], safe_mode: bool = True) -> bool:
    """
    æ¸…ç†ç›®å½•
    
    Args:
        directory: è¦æ¸…ç†çš„ç›®å½•
        safe_mode: å®‰å…¨æ¨¡å¼ï¼ˆåªæ¸…ç†ä¸´æ—¶ç›®å½•ï¼‰
    
    Returns:
        bool: æ˜¯å¦æ¸…ç†æˆåŠŸ
    """
    try:
        directory = Path(directory)
        
        # å®‰å…¨æ£€æŸ¥
        if safe_mode:
            temp_dir = Path(tempfile.gettempdir())
            if not str(directory).startswith(str(temp_dir)):
                print(f"å®‰å…¨æ¨¡å¼ä¸‹åªèƒ½æ¸…ç†ä¸´æ—¶ç›®å½•: {directory}")
                return False
        
        if directory.exists():
            shutil.rmtree(directory)
            return True
        
        return True
        
    except Exception as e:
        print(f"æ¸…ç†ç›®å½•å¤±è´¥: {e}")
        return False


def save_uploaded_file(uploaded_file, save_directory: Union[str, Path], 
                      new_filename: Optional[str] = None) -> Tuple[bool, str, str]:
    """
    ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆStreamlitæ–‡ä»¶å¯¹è±¡ï¼‰
    
    Args:
        uploaded_file: Streamlitçš„ä¸Šä¼ æ–‡ä»¶å¯¹è±¡
        save_directory: ä¿å­˜ç›®å½•
        new_filename: æ–°æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
    
    Returns:
        (success, file_path, message): ä¿å­˜ç»“æœ
    """
    try:
        save_directory = Path(save_directory)
        save_directory.mkdir(parents=True, exist_ok=True)
        
        # ç¡®å®šæ–‡ä»¶å
        if new_filename:
            filename = new_filename
        else:
            # ä½¿ç”¨åŸå§‹æ–‡ä»¶åï¼Œä½†æ·»åŠ æ—¶é—´æˆ³é¿å…å†²çª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            name_parts = uploaded_file.name.rsplit('.', 1)
            if len(name_parts) == 2:
                filename = f"{name_parts[0]}_{timestamp}.{name_parts[1]}"
            else:
                filename = f"{uploaded_file.name}_{timestamp}"
        
        file_path = save_directory / filename
        
        # ä¿å­˜æ–‡ä»¶
        with open(file_path, 'wb') as f:
            f.write(uploaded_file.getbuffer())
        
        return True, str(file_path), f"æ–‡ä»¶ä¿å­˜æˆåŠŸ: {filename}"
        
    except Exception as e:
        return False, "", f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}"


def generate_file_hash(file_path: Union[str, Path], algorithm: str = 'md5') -> str:
    """
    ç”Ÿæˆæ–‡ä»¶å“ˆå¸Œå€¼
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        algorithm: å“ˆå¸Œç®—æ³• ('md5', 'sha1', 'sha256')
    
    Returns:
        str: æ–‡ä»¶å“ˆå¸Œå€¼
    """
    hash_func = getattr(hashlib, algorithm)()
    
    with open(file_path, 'rb') as f:
        while chunk := f.read(8192):
            hash_func.update(chunk)
    
    return hash_func.hexdigest()


def get_file_metadata(file_path: Union[str, Path]) -> Dict[str, any]:
    """
    è·å–æ–‡ä»¶å…ƒæ•°æ®
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        Dict: æ–‡ä»¶å…ƒæ•°æ®
    """
    file_path = Path(file_path)
    
    if not file_path.exists():
        return {'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}
    
    stat = file_path.stat()
    
    metadata = {
        'filename': file_path.name,
        'path': str(file_path.absolute()),
        'size': stat.st_size,
        'size_formatted': format_file_size(stat.st_size),
        'extension': file_path.suffix.lower(),
        'file_type': get_file_type(file_path),
        'created_time': datetime.fromtimestamp(stat.st_ctime).strftime('%Y-%m-%d %H:%M:%S'),
        'modified_time': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
        'mime_type': mimetypes.guess_type(str(file_path))[0] or 'unknown'
    }
    
    return metadata


def prepare_download_file(file_path: Union[str, Path], download_name: Optional[str] = None) -> Tuple[bytes, str, str]:
    """
    å‡†å¤‡æ–‡ä»¶ä¾›ä¸‹è½½
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        download_name: ä¸‹è½½æ—¶çš„æ–‡ä»¶å
    
    Returns:
        (file_data, download_name, mime_type): æ–‡ä»¶æ•°æ®ã€ä¸‹è½½åç§°ã€MIMEç±»å‹
    """
    file_path = Path(file_path)
    
    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    # è¯»å–æ–‡ä»¶æ•°æ®
    with open(file_path, 'rb') as f:
        file_data = f.read()
    
    # ç¡®å®šä¸‹è½½æ–‡ä»¶å
    if not download_name:
        download_name = file_path.name
    
    # è·å–MIMEç±»å‹
    mime_type = mimetypes.guess_type(str(file_path))[0] or 'application/octet-stream'
    
    return file_data, download_name, mime_type


def batch_process_files(file_list: List[Union[str, Path]], 
                       process_func: callable,
                       progress_callback: Optional[callable] = None) -> List[Dict[str, any]]:
    """
    æ‰¹é‡å¤„ç†æ–‡ä»¶
    
    Args:
        file_list: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        process_func: å¤„ç†å‡½æ•°
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
    
    Returns:
        List[Dict]: å¤„ç†ç»“æœåˆ—è¡¨
    """
    results = []
    total_files = len(file_list)
    
    for i, file_path in enumerate(file_list):
        if progress_callback:
            progress_callback(f"å¤„ç†æ–‡ä»¶ {i + 1}/{total_files}: {Path(file_path).name}")
        
        try:
            result = process_func(file_path)
            results.append({
                'file': str(file_path),
                'success': True,
                'result': result
            })
        except Exception as e:
            results.append({
                'file': str(file_path),
                'success': False,
                'error': str(e)
            })
    
    return results


def get_audio_duration(file_path: Union[str, Path]) -> Optional[float]:
    """
    è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿ï¼ˆç§’ï¼‰
    
    Args:
        file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    
    Returns:
        float: æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›None
    """
    try:
        # å°è¯•ä½¿ç”¨pydubè·å–æ—¶é•¿
        from pydub import AudioSegment
        audio = AudioSegment.from_file(file_path)
        duration_seconds = len(audio) / 1000.0
        return duration_seconds
    except ImportError:
        # pydubæœªå®‰è£…ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
        pass
    except Exception as e:
        print(f"ä½¿ç”¨pydubè·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–è·å–éŸ³é¢‘æ—¶é•¿çš„æ–¹æ³•
    # ä¾‹å¦‚ä½¿ç”¨ffprobeæˆ–å…¶ä»–åº“
    
    return None


def ensure_directory_exists(directory: Union[str, Path]) -> Path:
    """
    ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    
    Args:
        directory: ç›®å½•è·¯å¾„
    
    Returns:
        Path: ç›®å½•Pathå¯¹è±¡
    """
    directory = Path(directory)
    directory.mkdir(parents=True, exist_ok=True)
    return directory


def copy_file_safe(source: Union[str, Path], destination: Union[str, Path], 
                  overwrite: bool = False) -> Tuple[bool, str]:
    """
    å®‰å…¨åœ°å¤åˆ¶æ–‡ä»¶
    
    Args:
        source: æºæ–‡ä»¶è·¯å¾„
        destination: ç›®æ ‡è·¯å¾„
        overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
    
    Returns:
        (success, message): æ“ä½œç»“æœ
    """
    try:
        source = Path(source)
        destination = Path(destination)
        
        if not source.exists():
            return False, f"æºæ–‡ä»¶ä¸å­˜åœ¨: {source}"
        
        # å¦‚æœç›®æ ‡æ˜¯ç›®å½•ï¼Œä½¿ç”¨æºæ–‡ä»¶å
        if destination.is_dir():
            destination = destination / source.name
        
        # æ£€æŸ¥æ˜¯å¦è¦†ç›–
        if destination.exists() and not overwrite:
            return False, f"ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨: {destination}"
        
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        destination.parent.mkdir(parents=True, exist_ok=True)
        
        # å¤åˆ¶æ–‡ä»¶
        shutil.copy2(source, destination)
        
        return True, f"æ–‡ä»¶å¤åˆ¶æˆåŠŸ: {destination}"
        
    except Exception as e:
        return False, f"æ–‡ä»¶å¤åˆ¶å¤±è´¥: {str(e)}"


def list_files_in_directory(directory: Union[str, Path], 
                           pattern: str = "*",
                           recursive: bool = False) -> List[Path]:
    """
    åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶
    
    Args:
        directory: ç›®å½•è·¯å¾„
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆå¦‚ "*.txt"ï¼‰
        recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
    
    Returns:
        List[Path]: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    directory = Path(directory)
    
    if not directory.exists():
        return []
    
    if recursive:
        return list(directory.rglob(pattern))
    else:
        return list(directory.glob(pattern))


def get_recent_files(directory: Union[str, Path], 
                    count: int = 10,
                    file_types: Optional[List[str]] = None) -> List[Dict[str, any]]:
    """
    è·å–ç›®å½•ä¸­æœ€è¿‘çš„æ–‡ä»¶
    
    Args:
        directory: ç›®å½•è·¯å¾„
        count: è·å–æ•°é‡
        file_types: æ–‡ä»¶ç±»å‹è¿‡æ»¤ï¼ˆå¦‚ ['.txt', '.pdf']ï¼‰
    
    Returns:
        List[Dict]: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
    """
    directory = Path(directory)
    
    if not directory.exists():
        return []
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    files = []
    for file_path in directory.iterdir():
        if file_path.is_file():
            if file_types:
                if file_path.suffix.lower() not in file_types:
                    continue
            
            files.append({
                'path': str(file_path),
                'name': file_path.name,
                'size': format_file_size(file_path.stat().st_size),
                'modified': file_path.stat().st_mtime,
                'modified_str': datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
            })
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
    files.sort(key=lambda x: x['modified'], reverse=True)
    
    return files[:count]


def create_unique_filename(directory: Union[str, Path], 
                         base_name: str,
                         extension: str) -> str:
    """
    åœ¨ç›®å½•ä¸­åˆ›å»ºå”¯ä¸€çš„æ–‡ä»¶å
    
    Args:
        directory: ç›®å½•è·¯å¾„
        base_name: åŸºç¡€æ–‡ä»¶å
        extension: æ–‡ä»¶æ‰©å±•å
    
    Returns:
        str: å”¯ä¸€çš„æ–‡ä»¶å
    """
    directory = Path(directory)
    counter = 1
    
    # ç¡®ä¿æ‰©å±•åä»¥ç‚¹å¼€å¤´
    if not extension.startswith('.'):
        extension = f'.{extension}'
    
    # åŸºç¡€æ–‡ä»¶å
    filename = f"{base_name}{extension}"
    file_path = directory / filename
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ•°å­—åç¼€
    while file_path.exists():
        filename = f"{base_name}_{counter}{extension}"
        file_path = directory / filename
        counter += 1
    
    return filename

--- File: utils/format_utils.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/utils/format_utils.py
åŠŸèƒ½è¯´æ˜: æ ¼å¼åŒ–ç›¸å…³å·¥å…·å‡½æ•°
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import re
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Any
import html
import markdown

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def format_duration(seconds: Optional[Union[int, float]]) -> str:
    """
    æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º
    
    Args:
        seconds: ç§’æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ—¶é•¿å­—ç¬¦ä¸²ï¼ˆå¦‚ "1å°æ—¶23åˆ†45ç§’"ï¼‰
    """
    if seconds is None:
        return "æœªçŸ¥"
    
    if seconds < 0:
        return "æ— æ•ˆæ—¶é•¿"
    
    # è½¬æ¢ä¸ºæ•´æ•°ç§’
    total_seconds = int(seconds)
    
    # è®¡ç®—æ—¶åˆ†ç§’
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    secs = total_seconds % 60
    
    # æ„å»ºç»“æœå­—ç¬¦ä¸²
    parts = []
    
    if hours > 0:
        parts.append(f"{hours}å°æ—¶")
    
    if minutes > 0:
        parts.append(f"{minutes}åˆ†")
    
    if secs > 0 or len(parts) == 0:  # å¦‚æœæ²¡æœ‰æ—¶åˆ†ï¼Œè‡³å°‘æ˜¾ç¤ºç§’
        parts.append(f"{secs}ç§’")
    
    return "".join(parts)


def format_timestamp(timestamp: Union[int, float, datetime], 
                    format_string: str = "%Y-%m-%d %H:%M:%S") -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´æˆ³
    
    Args:
        timestamp: æ—¶é—´æˆ³ï¼ˆç§’ï¼‰æˆ–datetimeå¯¹è±¡
        format_string: æ ¼å¼åŒ–å­—ç¬¦ä¸²
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²
    """
    if isinstance(timestamp, (int, float)):
        dt = datetime.fromtimestamp(timestamp)
    elif isinstance(timestamp, datetime):
        dt = timestamp
    else:
        return "æ— æ•ˆæ—¶é—´"
    
    return dt.strftime(format_string)


def format_metadata_display(metadata: Dict[str, Any], 
                          exclude_keys: Optional[List[str]] = None) -> str:
    """
    æ ¼å¼åŒ–å…ƒæ•°æ®ç”¨äºæ˜¾ç¤º
    
    Args:
        metadata: å…ƒæ•°æ®å­—å…¸
        exclude_keys: è¦æ’é™¤çš„é”®åˆ—è¡¨
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ˜¾ç¤ºå­—ç¬¦ä¸²
    """
    if not metadata:
        return "æ— å…ƒæ•°æ®"
    
    exclude_keys = exclude_keys or []
    
    display_parts = []
    
    # å®šä¹‰é”®çš„æ˜¾ç¤ºåç§°æ˜ å°„
    key_display_names = {
        'file_size': 'æ–‡ä»¶å¤§å°',
        'duration': 'æ—¶é•¿',
        'speakers_count': 'è¯´è¯äººæ•°',
        'processing_time': 'å¤„ç†æ—¶é—´',
        'model_used': 'ä½¿ç”¨æ¨¡å‹',
        'total_tokens': 'Tokenæ€»æ•°',
        'estimated_cost': 'é¢„ä¼°è´¹ç”¨',
        'timestamp': 'å¤„ç†æ—¶é—´',
        'analysis_template': 'åˆ†ææ¨¡æ¿',
        'source_type': 'æ¥æºç±»å‹',
        'page_count': 'é¡µæ•°',
        'word_count': 'å­—æ•°'
    }
    
    # æŒ‰ä¼˜å…ˆçº§æ’åºçš„é”®
    priority_keys = [
        'file_size', 'duration', 'page_count', 'word_count',
        'speakers_count', 'processing_time', 'model_used'
    ]
    
    # å…ˆæ˜¾ç¤ºä¼˜å…ˆçº§é«˜çš„é”®
    for key in priority_keys:
        if key in metadata and key not in exclude_keys:
            display_name = key_display_names.get(key, key)
            value = metadata[key]
            
            # ç‰¹æ®Šæ ¼å¼åŒ–
            if key == 'processing_time' and isinstance(value, (int, float)):
                value = f"{value:.1f}ç§’"
            elif key == 'estimated_cost' and isinstance(value, (int, float)):
                value = f"${value:.4f}"
            elif key == 'total_tokens' and isinstance(value, int):
                value = f"{value:,}"
            
            display_parts.append(f"{display_name}: {value}")
    
    # å†æ˜¾ç¤ºå…¶ä»–é”®
    for key, value in metadata.items():
        if key not in priority_keys and key not in exclude_keys:
            display_name = key_display_names.get(key, key)
            display_parts.append(f"{display_name}: {value}")
    
    return " | ".join(display_parts)


def format_number(number: Union[int, float], 
                 decimal_places: int = 2,
                 use_comma: bool = True) -> str:
    """
    æ ¼å¼åŒ–æ•°å­—æ˜¾ç¤º
    
    Args:
        number: æ•°å­—
        decimal_places: å°æ•°ä½æ•°
        use_comma: æ˜¯å¦ä½¿ç”¨åƒä½åˆ†éš”ç¬¦
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ•°å­—å­—ç¬¦ä¸²
    """
    if isinstance(number, int):
        if use_comma:
            return f"{number:,}"
        else:
            return str(number)
    
    if use_comma:
        return f"{number:,.{decimal_places}f}"
    else:
        return f"{number:.{decimal_places}f}"


def format_percentage(value: float, decimal_places: int = 1) -> str:
    """
    æ ¼å¼åŒ–ç™¾åˆ†æ¯”æ˜¾ç¤º
    
    Args:
        value: æ•°å€¼ï¼ˆ0-1ä¹‹é—´è¡¨ç¤ºç™¾åˆ†æ¯”ï¼Œå¤§äº1è¡¨ç¤ºå·²ç»æ˜¯ç™¾åˆ†æ•°ï¼‰
        decimal_places: å°æ•°ä½æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„ç™¾åˆ†æ¯”å­—ç¬¦ä¸²
    """
    if value <= 1:
        percentage = value * 100
    else:
        percentage = value
    
    return f"{percentage:.{decimal_places}f}%"


def format_money(amount: Union[int, float], 
                currency: str = "Â¥",
                decimal_places: int = 2) -> str:
    """
    æ ¼å¼åŒ–è´§å¸æ˜¾ç¤º
    
    Args:
        amount: é‡‘é¢
        currency: è´§å¸ç¬¦å·
        decimal_places: å°æ•°ä½æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„è´§å¸å­—ç¬¦ä¸²
    """
    formatted_number = format_number(amount, decimal_places, use_comma=True)
    return f"{currency}{formatted_number}"


def clean_text(text: str, 
              remove_extra_spaces: bool = True,
              remove_empty_lines: bool = True) -> str:
    """
    æ¸…ç†æ–‡æœ¬
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        remove_extra_spaces: æ˜¯å¦ç§»é™¤å¤šä½™ç©ºæ ¼
        remove_empty_lines: æ˜¯å¦ç§»é™¤ç©ºè¡Œ
    
    Returns:
        str: æ¸…ç†åçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # ç§»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    
    if remove_extra_spaces:
        # å°†å¤šä¸ªç©ºæ ¼æ›¿æ¢ä¸ºä¸€ä¸ª
        text = re.sub(r'\s+', ' ', text)
        # ä½†ä¿ç•™æ¢è¡Œç¬¦
        text = re.sub(r' *\n *', '\n', text)
    
    if remove_empty_lines:
        # ç§»é™¤ç©ºè¡Œ
        lines = [line for line in text.split('\n') if line.strip()]
        text = '\n'.join(lines)
    
    return text


def truncate_text(text: str, 
                 max_length: int = 100,
                 suffix: str = "...") -> str:
    """
    æˆªæ–­æ–‡æœ¬
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦
        suffix: æˆªæ–­åç¼€
    
    Returns:
        str: æˆªæ–­åçš„æ–‡æœ¬
    """
    if not text or len(text) <= max_length:
        return text
    
    # åœ¨è¯è¾¹ç•Œæˆªæ–­
    truncated = text[:max_length]
    
    # å°è¯•åœ¨æœ€åä¸€ä¸ªå®Œæ•´è¯å¤„æˆªæ–­
    last_space = truncated.rfind(' ')
    if last_space > max_length * 0.8:  # å¦‚æœç©ºæ ¼ä½ç½®åˆç†
        truncated = truncated[:last_space]
    
    return truncated + suffix


def markdown_to_text(markdown_text: str) -> str:
    """
    å°†Markdownè½¬æ¢ä¸ºçº¯æ–‡æœ¬
    
    Args:
        markdown_text: Markdownæ ¼å¼æ–‡æœ¬
    
    Returns:
        str: çº¯æ–‡æœ¬
    """
    # ç§»é™¤Markdownæ ‡è®°
    # ç§»é™¤æ ‡é¢˜æ ‡è®°
    text = re.sub(r'^#{1,6}\s+', '', markdown_text, flags=re.MULTILINE)
    
    # ç§»é™¤åŠ ç²—å’Œæ–œä½“
    text = re.sub(r'\*{1,2}([^\*]+)\*{1,2}', r'\1', text)
    text = re.sub(r'_{1,2}([^_]+)_{1,2}', r'\1', text)
    
    # ç§»é™¤é“¾æ¥
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)
    
    # ç§»é™¤å›¾ç‰‡
    text = re.sub(r'!\[([^\]]*)\]\([^\)]+\)', '', text)
    
    # ç§»é™¤ä»£ç å—
    text = re.sub(r'```[^`]*```', '', text, flags=re.DOTALL)
    text = re.sub(r'`([^`]+)`', r'\1', text)
    
    # ç§»é™¤åˆ—è¡¨æ ‡è®°
    text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
    
    # ç§»é™¤å¼•ç”¨æ ‡è®°
    text = re.sub(r'^\s*>\s+', '', text, flags=re.MULTILINE)
    
    # ç§»é™¤æ°´å¹³çº¿
    text = re.sub(r'^-{3,}$', '', text, flags=re.MULTILINE)
    
    # æ¸…ç†å¤šä½™ç©ºè¡Œ
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


def markdown_to_html(markdown_text: str, 
                    safe_mode: bool = True) -> str:
    """
    å°†Markdownè½¬æ¢ä¸ºHTML
    
    Args:
        markdown_text: Markdownæ ¼å¼æ–‡æœ¬
        safe_mode: æ˜¯å¦å¯ç”¨å®‰å…¨æ¨¡å¼ï¼ˆè½¬ä¹‰HTMLï¼‰
    
    Returns:
        str: HTMLæ ¼å¼æ–‡æœ¬
    """
    if safe_mode:
        # è½¬ä¹‰HTMLæ ‡ç­¾
        markdown_text = html.escape(markdown_text)
    
    # ä½¿ç”¨markdownåº“è½¬æ¢
    html_text = markdown.markdown(
        markdown_text,
        extensions=['extra', 'codehilite', 'toc']
    )
    
    return html_text


def format_list_as_text(items: List[Any], 
                       style: str = "bullet",
                       indent: int = 0) -> str:
    """
    å°†åˆ—è¡¨æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
    
    Args:
        items: é¡¹ç›®åˆ—è¡¨
        style: æ ·å¼ ('bullet', 'number', 'dash')
        indent: ç¼©è¿›çº§åˆ«
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ–‡æœ¬
    """
    if not items:
        return ""
    
    indent_str = "  " * indent
    formatted_items = []
    
    for i, item in enumerate(items):
        if style == "number":
            prefix = f"{i + 1}."
        elif style == "dash":
            prefix = "-"
        else:  # bullet
            prefix = "â€¢"
        
        formatted_items.append(f"{indent_str}{prefix} {item}")
    
    return "\n".join(formatted_items)


def format_dict_as_text(data: Dict[str, Any],
                       indent: int = 0,
                       exclude_keys: Optional[List[str]] = None) -> str:
    """
    å°†å­—å…¸æ ¼å¼åŒ–ä¸ºæ–‡æœ¬
    
    Args:
        data: æ•°æ®å­—å…¸
        indent: ç¼©è¿›çº§åˆ«
        exclude_keys: è¦æ’é™¤çš„é”®
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ–‡æœ¬
    """
    if not data:
        return ""
    
    exclude_keys = exclude_keys or []
    indent_str = "  " * indent
    formatted_parts = []
    
    for key, value in data.items():
        if key in exclude_keys:
            continue
        
        # æ ¼å¼åŒ–é”®åï¼ˆå°†ä¸‹åˆ’çº¿è½¬æ¢ä¸ºç©ºæ ¼ï¼Œé¦–å­—æ¯å¤§å†™ï¼‰
        display_key = key.replace('_', ' ').title()
        
        if isinstance(value, dict):
            formatted_parts.append(f"{indent_str}{display_key}:")
            formatted_parts.append(format_dict_as_text(value, indent + 1))
        elif isinstance(value, list):
            formatted_parts.append(f"{indent_str}{display_key}:")
            formatted_parts.append(format_list_as_text(value, indent=indent + 1))
        else:
            formatted_parts.append(f"{indent_str}{display_key}: {value}")
    
    return "\n".join(formatted_parts)


def escape_markdown(text: str) -> str:
    """
    è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦
    
    Args:
        text: åŸå§‹æ–‡æœ¬
    
    Returns:
        str: è½¬ä¹‰åçš„æ–‡æœ¬
    """
    # Markdownç‰¹æ®Šå­—ç¬¦
    special_chars = ['*', '_', '`', '[', ']', '(', ')', '#', '+', '-', '!', '|', '{', '}']
    
    for char in special_chars:
        text = text.replace(char, f'\\{char}')
    
    return text


def format_json_pretty(data: Union[Dict, List], 
                      indent: int = 2,
                      ensure_ascii: bool = False) -> str:
    """
    ç¾åŒ–JSONæ ¼å¼
    
    Args:
        data: æ•°æ®
        indent: ç¼©è¿›ç©ºæ ¼æ•°
        ensure_ascii: æ˜¯å¦ç¡®ä¿ASCIIç¼–ç 
    
    Returns:
        str: ç¾åŒ–åçš„JSONå­—ç¬¦ä¸²
    """
    return json.dumps(
        data,
        indent=indent,
        ensure_ascii=ensure_ascii,
        sort_keys=True,
        default=str  # å¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
    )


def format_table_text(headers: List[str], 
                     rows: List[List[Any]],
                     align: str = "left") -> str:
    """
    æ ¼å¼åŒ–è¡¨æ ¼æ–‡æœ¬ï¼ˆMarkdownæ ¼å¼ï¼‰
    
    Args:
        headers: è¡¨å¤´åˆ—è¡¨
        rows: æ•°æ®è¡Œåˆ—è¡¨
        align: å¯¹é½æ–¹å¼ ('left', 'center', 'right')
    
    Returns:
        str: Markdownæ ¼å¼çš„è¡¨æ ¼
    """
    if not headers or not rows:
        return ""
    
    # è®¡ç®—æ¯åˆ—çš„æœ€å¤§å®½åº¦
    col_widths = [len(str(h)) for h in headers]
    
    for row in rows:
        for i, cell in enumerate(row[:len(headers)]):
            col_widths[i] = max(col_widths[i], len(str(cell)))
    
    # æ„å»ºè¡¨å¤´
    header_parts = []
    separator_parts = []
    
    for i, header in enumerate(headers):
        header_parts.append(str(header).ljust(col_widths[i]))
        
        if align == "center":
            separator_parts.append(":" + "-" * (col_widths[i] - 2) + ":")
        elif align == "right":
            separator_parts.append("-" * (col_widths[i] - 1) + ":")
        else:  # left
            separator_parts.append("-" * col_widths[i])
    
    # æ„å»ºè¡¨æ ¼
    table_lines = [
        "| " + " | ".join(header_parts) + " |",
        "| " + " | ".join(separator_parts) + " |"
    ]
    
    # æ·»åŠ æ•°æ®è¡Œ
    for row in rows:
        row_parts = []
        for i, cell in enumerate(row[:len(headers)]):
            if i < len(col_widths):
                if align == "right":
                    row_parts.append(str(cell).rjust(col_widths[i]))
                elif align == "center":
                    row_parts.append(str(cell).center(col_widths[i]))
                else:
                    row_parts.append(str(cell).ljust(col_widths[i]))
        
        table_lines.append("| " + " | ".join(row_parts) + " |")
    
    return "\n".join(table_lines)


def format_relative_time(timestamp: Union[datetime, float]) -> str:
    """
    æ ¼å¼åŒ–ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚"5åˆ†é’Ÿå‰"ï¼‰
    
    Args:
        timestamp: æ—¶é—´æˆ³æˆ–datetimeå¯¹è±¡
    
    Returns:
        str: ç›¸å¯¹æ—¶é—´å­—ç¬¦ä¸²
    """
    if isinstance(timestamp, (int, float)):
        dt = datetime.fromtimestamp(timestamp)
    else:
        dt = timestamp
    
    now = datetime.now()
    delta = now - dt
    
    # è½¬æ¢ä¸ºç§’
    total_seconds = int(delta.total_seconds())
    
    if total_seconds < 60:
        return "åˆšåˆš"
    elif total_seconds < 3600:
        minutes = total_seconds // 60
        return f"{minutes}åˆ†é’Ÿå‰"
    elif total_seconds < 86400:
        hours = total_seconds // 3600
        return f"{hours}å°æ—¶å‰"
    elif total_seconds < 604800:
        days = total_seconds // 86400
        return f"{days}å¤©å‰"
    elif total_seconds < 2592000:
        weeks = total_seconds // 604800
        return f"{weeks}å‘¨å‰"
    elif total_seconds < 31536000:
        months = total_seconds // 2592000
        return f"{months}ä¸ªæœˆå‰"
    else:
        years = total_seconds // 31536000
        return f"{years}å¹´å‰"


def highlight_text(text: str, 
                  keywords: List[str],
                  highlight_style: str = "**{text}**") -> str:
    """
    é«˜äº®æ–‡æœ¬ä¸­çš„å…³é”®è¯
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        keywords: å…³é”®è¯åˆ—è¡¨
        highlight_style: é«˜äº®æ ·å¼æ¨¡æ¿
    
    Returns:
        str: é«˜äº®åçš„æ–‡æœ¬
    """
    if not text or not keywords:
        return text
    
    # æŒ‰å…³é”®è¯é•¿åº¦é™åºæ’åºï¼Œé¿å…çŸ­è¯å½±å“é•¿è¯
    sorted_keywords = sorted(keywords, key=len, reverse=True)
    
    for keyword in sorted_keywords:
        if keyword in text:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œå¤§å°å†™ä¸æ•æ„Ÿçš„æ›¿æ¢
            pattern = re.compile(re.escape(keyword), re.IGNORECASE)
            text = pattern.sub(
                lambda m: highlight_style.format(text=m.group(0)),
                text
            )
    
    return text

--- File: utils/ui_utils.py ---
# ==============================================================================
# File: utils/ui_utils.py (å·²æ›´æ­£)
# ==============================================================================
# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/utils/ui_utils.py
åŠŸèƒ½è¯´æ˜: æä¾›ä¸Streamlit UIç›¸å…³çš„è¾…åŠ©å‡½æ•°ï¼Œæ—¨åœ¨æå‡ç”¨æˆ·ä½“éªŒå’Œä»£ç å¤ç”¨æ€§ã€‚
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-29
ç‰ˆæœ¬: 1.0.1 (å·²æ›´æ­£)
"""

import streamlit as st
import configparser
from typing import Optional


def check_api_key_setup():
    """
    æ£€æŸ¥API Keyæ˜¯å¦å·²åœ¨ä¼šè¯ä¸­é…ç½®ã€‚

    è¿™æ˜¯ä¸€ä¸ª"é¡µé¢å®ˆå«"å‡½æ•°ï¼Œåº”åœ¨æ¯ä¸ªéœ€è¦ä½¿ç”¨AIåŠŸèƒ½çš„Streamlitå­é¡µé¢çš„å¼€å¤´è°ƒç”¨ã€‚
    å®ƒçš„å·¥ä½œé€»è¾‘å¦‚ä¸‹ï¼š
    1. è¯»å– `app_config.ini` ä¸­çš„ `use_internal_api_key` è®¾ç½®ã€‚
    2. å¦‚æœè®¾ç½®ä¸º `true`ï¼Œåˆ™è®¤ä¸ºç³»ç»Ÿå·²é…ç½®ï¼Œå‡½æ•°ç›´æ¥è¿”å›ã€‚
    3. å¦‚æœè®¾ç½®ä¸º `false`ï¼Œåˆ™æ£€æŸ¥ `st.session_state.api_key_configured` æ ‡å¿—ä½ã€‚
    4. å¦‚æœæ ‡å¿—ä½ä¸º `False` æˆ–ä¸å­˜åœ¨ï¼Œè¯´æ˜ç”¨æˆ·å°šæœªåœ¨UIä¸­æä¾›API Keyã€‚æ­¤æ—¶ï¼Œ
       å‡½æ•°ä¼šæ˜¾ç¤ºä¸€æ¡è­¦å‘Šæ¶ˆæ¯ï¼Œæä¾›ä¸€ä¸ªè¿”å›ä¸»é¡µçš„é“¾æ¥ï¼Œå¹¶è°ƒç”¨ `st.stop()`
       æ¥ç»ˆæ­¢å½“å‰é¡µé¢çš„è¿›ä¸€æ­¥æ¸²æŸ“ï¼Œé˜²æ­¢åç»­ä»£ç å› æ¨¡å‹æœªåˆå§‹åŒ–è€ŒæŠ¥é”™ã€‚
    """
    # ç¡®ä¿åº”ç”¨çš„é…ç½®å·²ç»åŠ è½½åˆ°ä¼šè¯çŠ¶æ€ä¸­
    if 'config' not in st.session_state or not isinstance(st.session_state.config, configparser.ConfigParser):
        # å¦‚æœé…ç½®ä¸å­˜åœ¨ï¼Œå¯èƒ½æ˜¯åœ¨åº”ç”¨å¯åŠ¨çš„ææ—©æœŸé˜¶æ®µï¼Œç›´æ¥è·³è¿‡æ£€æŸ¥ã€‚
        # è¿™ç§æƒ…å†µä¸‹ï¼Œä¸»åº”ç”¨`app.py`ä¼šå¤„ç†åˆå§‹åŒ–ã€‚
        return

    # ä»é…ç½®ä¸­è¯»å–æ˜¯å¦ä½¿ç”¨å†…éƒ¨å¯†é’¥
    use_internal = st.session_state.config.getboolean(
        'API_SETTINGS',
        'use_internal_api_key',
        fallback=False
    )

    # å¦‚æœé…ç½®ä¸ºä½¿ç”¨å†…éƒ¨å¯†é’¥ï¼Œåˆ™æˆ‘ä»¬å‡å®šå®ƒæ€»æ˜¯å·²é…ç½®çš„ã€‚
    # çœŸæ­£çš„åˆå§‹åŒ–å’ŒçŠ¶æ€è®¾ç½®åœ¨ app.py ä¸­å®Œæˆã€‚
    if use_internal:
        return

    # å¦‚æœä¸ä½¿ç”¨å†…éƒ¨å¯†é’¥ï¼Œåˆ™å¿…é¡»æ£€æŸ¥ç”¨æˆ·æ˜¯å¦é€šè¿‡UIè¿›è¡Œäº†é…ç½®ã€‚
    # 'api_key_configured' è¿™ä¸ª session_state å˜é‡åœ¨ app.py ä¸­æˆåŠŸåˆå§‹åŒ–æ¨¡å‹åè¢«è®¾ä¸º Trueã€‚
    if not st.session_state.get('api_key_configured'):
        # å¦‚æœæœªé…ç½®ï¼Œæ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        st.warning("ç³»ç»Ÿæœªé…ç½®ï¼Œè¯·å…ˆåœ¨ä¸»é¡µé¢è®¾ç½®æ‚¨çš„ API å¯†é’¥ä»¥ä½¿ç”¨æœ¬åŠŸèƒ½ã€‚")

        # æä¾›ä¸€ä¸ªè¿”å›ä¸»é¡µçš„é“¾æ¥ï¼Œæ–¹ä¾¿ç”¨æˆ·æ“ä½œ
        st.page_link("app.py", label="è¿”å›ä¸»é¡µè¿›è¡Œè®¾ç½®", icon="ğŸ ")

        # åœæ­¢æ‰§è¡Œå½“å‰é¡µé¢çš„å…¶ä½™éƒ¨åˆ†ï¼Œè¿™æ˜¯é˜²æ­¢åç»­ä»£ç å‡ºé”™çš„å…³é”®
        st.stop()


def display_info_sidebar():
    """
    åœ¨ä¾§è¾¹æ æ˜¾ç¤ºä¸€ä¸ªæ ‡å‡†çš„ä¿¡æ¯æç¤ºæ¡†ã€‚
    ï¼ˆè¿™æ˜¯ä¸€ä¸ªå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ çš„é¢å¤–UIè¾…åŠ©å‡½æ•°ç¤ºä¾‹ï¼‰
    """
    with st.sidebar:
        st.info(
            """
            **ğŸ’¡ æç¤º**: 
            - ç¡®ä¿åœ¨ä¾§è¾¹æ é€‰æ‹©äº†åˆé€‚çš„æ¨¡å‹ã€‚
            - å¤„ç†å¤§æ–‡ä»¶å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚
            - æ‰€æœ‰ç»“æœéƒ½å¯ä»¥å¯¼å‡ºä¿å­˜ã€‚
            """
        )


# ä¸»ç¨‹åºå…¥å£ï¼Œç”¨äºæ¨¡å—ç‹¬ç«‹æµ‹è¯•æˆ–æ¼”ç¤º
if __name__ == "__main__":
    st.title("UI Utils - æ¨¡å—æµ‹è¯•")

    st.markdown("è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯• `utils/ui_utils.py` ä¸­å‡½æ•°çš„é¡µé¢ã€‚")
    st.markdown("---")

    st.header("1. æµ‹è¯• `check_api_key_setup` å‡½æ•°")
    st.write("è¯·åœ¨ä¸‹æ–¹æ¨¡æ‹Ÿä¼šè¯çŠ¶æ€ï¼Œç„¶åç‚¹å‡»æŒ‰é’®è¿›è¡Œæµ‹è¯•ã€‚")

    # æ¨¡æ‹Ÿ session_state
    if 'config' not in st.session_state:
        st.session_state.config = configparser.ConfigParser()
        st.session_state.config.read_string("""
        [API_SETTINGS]
        use_internal_api_key = false
        """)

    if 'api_key_configured' not in st.session_state:
        st.session_state.api_key_configured = False

    st.write("å½“å‰æ¨¡æ‹ŸçŠ¶æ€:")
    st.json({
        'use_internal_api_key': st.session_state.config.getboolean('API_SETTINGS', 'use_internal_api_key'),
        'api_key_configured': st.session_state.get('api_key_configured')
    })

    col1, col2 = st.columns(2)
    with col1:
        if st.button("æ¨¡æ‹Ÿ: API Key å·²é…ç½®"):
            st.session_state.api_key_configured = True
            st.rerun()
    with col2:
        if st.button("æ¨¡æ‹Ÿ: API Key æœªé…ç½®"):
            st.session_state.api_key_configured = False
            st.rerun()

    # ç›´æ¥è°ƒç”¨å®ˆå«å‡½æ•°ã€‚
    # å¦‚æœæ¡ä»¶æ»¡è¶³ï¼Œå®ƒä¼šæ˜¾ç¤ºè­¦å‘Šå¹¶è°ƒç”¨ st.stop()ï¼Œæ­¤æ—¶ä¸‹é¢çš„ st.success ä¸ä¼šè¢«æ‰§è¡Œã€‚
    # å¦‚æœæ¡ä»¶ä¸æ»¡è¶³ï¼Œå®ƒä¼šç›´æ¥é€šè¿‡ï¼Œç„¶åæ‰§è¡Œä¸‹é¢çš„ st.successã€‚
    # è¿™ç§æ–¹å¼æ¯”æ•è·å†…éƒ¨å¼‚å¸¸æ›´æ¸…æ™°åœ°æ¼”ç¤ºäº†å‡½æ•°çš„è¡Œä¸ºã€‚
    check_api_key_setup()

    # åªæœ‰å½“ check_api_key_setup() æ²¡æœ‰åœæ­¢è„šæœ¬æ—¶ï¼Œè¿™è¡Œä»£ç æ‰ä¼šæ‰§è¡Œ
    st.success("âœ… `check_api_key_setup` æ£€æŸ¥é€šè¿‡ï¼Œé¡µé¢å¯ä»¥ç»§ç»­åŠ è½½ã€‚")

--- File: utils/validation_utils.py ---
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶è·¯å¾„: smart_proposal_engine/utils/validation_utils.py
åŠŸèƒ½è¯´æ˜: éªŒè¯ç›¸å…³å·¥å…·å‡½æ•°
ä½œè€…: SmartProposal Team
åˆ›å»ºæ—¥æœŸ: 2025-06-27
æœ€åä¿®æ”¹: 2025-06-27
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import re
from typing import Dict, List, Optional, Union, Tuple, Any
from pathlib import Path
import mimetypes

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.file_utils import (
    SUPPORTED_AUDIO_FORMATS, 
    SUPPORTED_DOCUMENT_FORMATS,
    get_file_extension
)


# éªŒè¯è§„åˆ™é…ç½®
VALIDATION_RULES = {
    'file_size': {
        'max_audio_mb': 200,
        'max_document_mb': 50,
        'max_total_mb': 500
    },
    'text_length': {
        'min_analysis_chars': 50,
        'max_analysis_chars': 100000,
        'min_proposal_chars': 100,
        'max_proposal_chars': 200000
    },
    'api_limits': {
        'max_tokens_per_request': 32768,
        'max_requests_per_minute': 60
    }
}


def validate_file_type(file_path: Union[str, Path], 
                      allowed_types: Optional[List[str]] = None) -> Tuple[bool, str]:
    """
    éªŒè¯æ–‡ä»¶ç±»å‹
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        allowed_types: å…è®¸çš„æ–‡ä»¶ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ ['audio', 'document']ï¼‰
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    file_path = Path(file_path)
    
    if not file_path.exists():
        return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
    
    ext = get_file_extension(file_path)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå…è®¸ç±»å‹ï¼Œåˆ™å…è®¸æ‰€æœ‰å·²çŸ¥ç±»å‹
    if allowed_types is None:
        all_formats = SUPPORTED_AUDIO_FORMATS + SUPPORTED_DOCUMENT_FORMATS
        if ext in all_formats:
            return True, f"æ–‡ä»¶ç±»å‹æœ‰æ•ˆ: {ext}"
        else:
            return False, f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {ext}"
    
    # æ£€æŸ¥ç‰¹å®šç±»å‹
    valid = False
    file_type = None
    
    if 'audio' in allowed_types and ext in SUPPORTED_AUDIO_FORMATS:
        valid = True
        file_type = 'audio'
    elif 'document' in allowed_types and ext in SUPPORTED_DOCUMENT_FORMATS:
        valid = True
        file_type = 'document'
    
    if valid:
        return True, f"æ–‡ä»¶ç±»å‹æœ‰æ•ˆ: {file_type} ({ext})"
    else:
        return False, f"æ–‡ä»¶ç±»å‹ {ext} ä¸åœ¨å…è®¸çš„ç±»å‹ä¸­: {allowed_types}"


def validate_text_input(text: str, 
                       min_length: Optional[int] = None,
                       max_length: Optional[int] = None,
                       required_patterns: Optional[List[str]] = None) -> Tuple[bool, str]:
    """
    éªŒè¯æ–‡æœ¬è¾“å…¥
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        min_length: æœ€å°é•¿åº¦
        max_length: æœ€å¤§é•¿åº¦
        required_patterns: å¿…é¡»åŒ…å«çš„æ¨¡å¼åˆ—è¡¨ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not text:
        return False, "æ–‡æœ¬ä¸èƒ½ä¸ºç©º"
    
    text = text.strip()
    text_length = len(text)
    
    # æ£€æŸ¥æœ€å°é•¿åº¦
    if min_length is not None and text_length < min_length:
        return False, f"æ–‡æœ¬å¤ªçŸ­ï¼Œæœ€å°‘éœ€è¦ {min_length} ä¸ªå­—ç¬¦ï¼Œå½“å‰ {text_length} ä¸ª"
    
    # æ£€æŸ¥æœ€å¤§é•¿åº¦
    if max_length is not None and text_length > max_length:
        return False, f"æ–‡æœ¬å¤ªé•¿ï¼Œæœ€å¤šå…è®¸ {max_length} ä¸ªå­—ç¬¦ï¼Œå½“å‰ {text_length} ä¸ª"
    
    # æ£€æŸ¥å¿…éœ€çš„æ¨¡å¼
    if required_patterns:
        for pattern in required_patterns:
            if not re.search(pattern, text):
                return False, f"æ–‡æœ¬ä¸ç¬¦åˆè¦æ±‚çš„æ ¼å¼: ç¼ºå°‘ {pattern}"
    
    return True, f"æ–‡æœ¬æœ‰æ•ˆï¼Œé•¿åº¦: {text_length}"


def validate_email(email: str) -> Tuple[bool, str]:
    """
    éªŒè¯é‚®ç®±åœ°å€
    
    Args:
        email: é‚®ç®±åœ°å€
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not email:
        return False, "é‚®ç®±åœ°å€ä¸èƒ½ä¸ºç©º"
    
    # åŸºæœ¬çš„é‚®ç®±æ­£åˆ™è¡¨è¾¾å¼
    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    
    if re.match(email_pattern, email):
        return True, "é‚®ç®±åœ°å€æ ¼å¼æ­£ç¡®"
    else:
        return False, "é‚®ç®±åœ°å€æ ¼å¼æ— æ•ˆ"


def validate_phone(phone: str, region: str = 'CN') -> Tuple[bool, str]:
    """
    éªŒè¯ç”µè¯å·ç 
    
    Args:
        phone: ç”µè¯å·ç 
        region: åœ°åŒºä»£ç ï¼ˆ'CN' ä¸­å›½ï¼Œ'US' ç¾å›½ç­‰ï¼‰
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not phone:
        return False, "ç”µè¯å·ç ä¸èƒ½ä¸ºç©º"
    
    # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
    phone = re.sub(r'[\s\-\(\)]', '', phone)
    
    # æ ¹æ®åœ°åŒºéªŒè¯
    if region == 'CN':
        # ä¸­å›½æ‰‹æœºå·ç 
        if re.match(r'^1[3-9]\d{9}$', phone):
            return True, "æ‰‹æœºå·ç æ ¼å¼æ­£ç¡®"
        # ä¸­å›½å›ºå®šç”µè¯
        elif re.match(r'^0\d{2,3}\d{7,8}$', phone):
            return True, "å›ºå®šç”µè¯æ ¼å¼æ­£ç¡®"
        else:
            return False, "ç”µè¯å·ç æ ¼å¼æ— æ•ˆï¼ˆéœ€è¦11ä½æ‰‹æœºå·æˆ–åŒºå·+ç”µè¯ï¼‰"
    
    elif region == 'US':
        # ç¾å›½ç”µè¯å·ç 
        if re.match(r'^1?\d{10}$', phone):
            return True, "ç”µè¯å·ç æ ¼å¼æ­£ç¡®"
        else:
            return False, "ç”µè¯å·ç æ ¼å¼æ— æ•ˆï¼ˆéœ€è¦10ä½æ•°å­—ï¼‰"
    
    else:
        # é€šç”¨éªŒè¯ï¼ˆåªæ£€æŸ¥æ˜¯å¦ä¸ºæ•°å­—ï¼‰
        if re.match(r'^\+?\d{7,15}$', phone):
            return True, "ç”µè¯å·ç æ ¼å¼æ­£ç¡®"
        else:
            return False, "ç”µè¯å·ç æ ¼å¼æ— æ•ˆ"


def validate_url(url: str) -> Tuple[bool, str]:
    """
    éªŒè¯URLåœ°å€
    
    Args:
        url: URLåœ°å€
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not url:
        return False, "URLä¸èƒ½ä¸ºç©º"
    
    # URLæ­£åˆ™è¡¨è¾¾å¼
    url_pattern = r'^https?://(?:www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b(?:[-a-zA-Z0-9()@:%_\+.~#?&/=]*)$'
    
    if re.match(url_pattern, url):
        return True, "URLæ ¼å¼æ­£ç¡®"
    else:
        return False, "URLæ ¼å¼æ— æ•ˆ"


def validate_api_key(api_key: str, 
                    key_type: str = 'google') -> Tuple[bool, str]:
    """
    éªŒè¯APIå¯†é’¥æ ¼å¼
    
    Args:
        api_key: APIå¯†é’¥
        key_type: å¯†é’¥ç±»å‹ï¼ˆ'google', 'openai'ç­‰ï¼‰
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not api_key:
        return False, "APIå¯†é’¥ä¸èƒ½ä¸ºç©º"
    
    api_key = api_key.strip()
    
    if key_type == 'google':
        # Google APIå¯†é’¥é€šå¸¸æ˜¯39ä¸ªå­—ç¬¦
        if len(api_key) == 39 and api_key.startswith('AIza'):
            return True, "Google APIå¯†é’¥æ ¼å¼æ­£ç¡®"
        else:
            return False, "Google APIå¯†é’¥æ ¼å¼æ— æ•ˆï¼ˆåº”ä¸º39ä¸ªå­—ç¬¦ï¼Œä»¥AIzaå¼€å¤´ï¼‰"
    
    elif key_type == 'openai':
        # OpenAI APIå¯†é’¥
        if api_key.startswith('sk-') and len(api_key) > 20:
            return True, "OpenAI APIå¯†é’¥æ ¼å¼æ­£ç¡®"
        else:
            return False, "OpenAI APIå¯†é’¥æ ¼å¼æ— æ•ˆï¼ˆåº”ä»¥sk-å¼€å¤´ï¼‰"
    
    else:
        # é€šç”¨éªŒè¯
        if len(api_key) >= 16:
            return True, "APIå¯†é’¥æ ¼å¼æ­£ç¡®"
        else:
            return False, "APIå¯†é’¥å¤ªçŸ­ï¼ˆè‡³å°‘éœ€è¦16ä¸ªå­—ç¬¦ï¼‰"


def validate_json_structure(data: Dict[str, Any], 
                          required_fields: List[str],
                          field_types: Optional[Dict[str, type]] = None) -> Tuple[bool, str]:
    """
    éªŒè¯JSON/å­—å…¸ç»“æ„
    
    Args:
        data: è¦éªŒè¯çš„æ•°æ®
        required_fields: å¿…éœ€çš„å­—æ®µåˆ—è¡¨
        field_types: å­—æ®µç±»å‹æ˜ å°„ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not isinstance(data, dict):
        return False, "æ•°æ®å¿…é¡»æ˜¯å­—å…¸ç±»å‹"
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    missing_fields = []
    for field in required_fields:
        if field not in data:
            missing_fields.append(field)
    
    if missing_fields:
        return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}"
    
    # æ£€æŸ¥å­—æ®µç±»å‹
    if field_types:
        type_errors = []
        for field, expected_type in field_types.items():
            if field in data and not isinstance(data[field], expected_type):
                actual_type = type(data[field]).__name__
                expected_name = expected_type.__name__
                type_errors.append(f"{field} åº”ä¸º {expected_name} ç±»å‹ï¼Œå®é™…ä¸º {actual_type}")
        
        if type_errors:
            return False, "å­—æ®µç±»å‹é”™è¯¯: " + "; ".join(type_errors)
    
    return True, "æ•°æ®ç»“æ„æœ‰æ•ˆ"


def validate_template_variables(template: str, 
                              provided_vars: Dict[str, Any]) -> Tuple[bool, List[str]]:
    """
    éªŒè¯æ¨¡æ¿å˜é‡
    
    Args:
        template: æ¨¡æ¿å­—ç¬¦ä¸²
        provided_vars: æä¾›çš„å˜é‡å­—å…¸
    
    Returns:
        (is_valid, missing_vars): æ˜¯å¦æœ‰æ•ˆå’Œç¼ºå¤±çš„å˜é‡åˆ—è¡¨
    """
    # æå–æ¨¡æ¿ä¸­çš„å˜é‡
    pattern = r'\{([^}]+)\}'
    required_vars = set(re.findall(pattern, template))
    
    # æ£€æŸ¥ç¼ºå¤±çš„å˜é‡
    provided_keys = set(provided_vars.keys())
    missing_vars = list(required_vars - provided_keys)
    
    is_valid = len(missing_vars) == 0
    
    return is_valid, missing_vars


def validate_batch_files(file_paths: List[Union[str, Path]], 
                        max_total_size_mb: Optional[float] = None,
                        max_file_count: Optional[int] = None) -> Tuple[bool, str, List[str]]:
    """
    éªŒè¯æ‰¹é‡æ–‡ä»¶
    
    Args:
        file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        max_total_size_mb: æœ€å¤§æ€»å¤§å°ï¼ˆMBï¼‰
        max_file_count: æœ€å¤§æ–‡ä»¶æ•°é‡
    
    Returns:
        (is_valid, message, invalid_files): éªŒè¯ç»“æœã€æ¶ˆæ¯å’Œæ— æ•ˆæ–‡ä»¶åˆ—è¡¨
    """
    invalid_files = []
    total_size = 0
    
    # æ£€æŸ¥æ–‡ä»¶æ•°é‡
    if max_file_count and len(file_paths) > max_file_count:
        return False, f"æ–‡ä»¶æ•°é‡è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤š {max_file_count} ä¸ªï¼‰", []
    
    # éªŒè¯æ¯ä¸ªæ–‡ä»¶
    for file_path in file_paths:
        file_path = Path(file_path)
        
        # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        if not file_path.exists():
            invalid_files.append(str(file_path))
            continue
        
        # ç´¯è®¡æ–‡ä»¶å¤§å°
        total_size += file_path.stat().st_size
    
    # æ£€æŸ¥æ€»å¤§å°
    total_size_mb = total_size / (1024 * 1024)
    if max_total_size_mb and total_size_mb > max_total_size_mb:
        return False, f"æ–‡ä»¶æ€»å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆ{total_size_mb:.1f} MB > {max_total_size_mb} MBï¼‰", invalid_files
    
    if invalid_files:
        return False, f"æœ‰ {len(invalid_files)} ä¸ªæ–‡ä»¶æ— æ•ˆ", invalid_files
    
    return True, f"æ‰€æœ‰æ–‡ä»¶æœ‰æ•ˆï¼Œæ€»å¤§å°: {total_size_mb:.1f} MB", []


def validate_model_input(text: str, 
                        model_type: str = 'gemini') -> Tuple[bool, str]:
    """
    éªŒè¯æ¨¡å‹è¾“å…¥
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        model_type: æ¨¡å‹ç±»å‹
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    if not text:
        return False, "è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º"
    
    # ä¼°ç®—tokenæ•°é‡ï¼ˆç®€å•ä¼°ç®—ï¼‰
    estimated_tokens = len(text) // 4  # è‹±æ–‡çº¦4ä¸ªå­—ç¬¦ä¸€ä¸ªtoken
    chinese_chars = len([c for c in text if '\u4e00' <= c <= '\u9fff'])
    estimated_tokens += chinese_chars * 0.5  # ä¸­æ–‡å­—ç¬¦é¢å¤–è®¡ç®—
    
    max_tokens = VALIDATION_RULES['api_limits']['max_tokens_per_request']
    
    if estimated_tokens > max_tokens:
        return False, f"è¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼Œé¢„ä¼° {int(estimated_tokens)} tokensï¼Œè¶…è¿‡é™åˆ¶ {max_tokens}"
    
    return True, f"è¾“å…¥æœ‰æ•ˆï¼Œé¢„ä¼° {int(estimated_tokens)} tokens"


def validate_workflow_state(state: Dict[str, Any], 
                          workflow_type: str) -> Tuple[bool, str]:
    """
    éªŒè¯å·¥ä½œæµçŠ¶æ€
    
    Args:
        state: å·¥ä½œæµçŠ¶æ€
        workflow_type: å·¥ä½œæµç±»å‹
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    # å®šä¹‰å„å·¥ä½œæµçš„å¿…éœ€æ­¥éª¤
    workflow_requirements = {
        'full_process': ['transcription', 'analysis', 'proposal'],
        'analysis_only': ['input', 'analysis'],
        'proposal_only': ['analysis', 'proposal']
    }
    
    required_steps = workflow_requirements.get(workflow_type, [])
    
    if not required_steps:
        return True, "å·¥ä½œæµç±»å‹æœªå®šä¹‰è¦æ±‚"
    
    # æ£€æŸ¥å¿…éœ€æ­¥éª¤æ˜¯å¦å®Œæˆ
    missing_steps = []
    for step in required_steps:
        if not state.get(f'{step}_completed', False):
            missing_steps.append(step)
    
    if missing_steps:
        return False, f"å·¥ä½œæµæœªå®Œæˆï¼Œç¼ºå°‘æ­¥éª¤: {', '.join(missing_steps)}"
    
    return True, "å·¥ä½œæµçŠ¶æ€æœ‰æ•ˆ"


def sanitize_filename(filename: str, 
                     max_length: int = 255) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œä½¿å…¶å®‰å…¨
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
        max_length: æœ€å¤§é•¿åº¦
    
    Returns:
        str: æ¸…ç†åçš„æ–‡ä»¶å
    """
    # ç§»é™¤è·¯å¾„åˆ†éš”ç¬¦
    filename = filename.replace('/', '_').replace('\\', '_')
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    invalid_chars = '<>:"|?*'
    for char in invalid_chars:
        filename = filename.replace(char, '_')
    
    # ç§»é™¤æ§åˆ¶å­—ç¬¦
    filename = ''.join(char for char in filename if ord(char) >= 32)
    
    # å¤„ç†ä¿ç•™åç§°ï¼ˆWindowsï¼‰
    reserved_names = ['CON', 'PRN', 'AUX', 'NUL'] + \
                    [f'COM{i}' for i in range(1, 10)] + \
                    [f'LPT{i}' for i in range(1, 10)]
    
    name_without_ext = filename.rsplit('.', 1)[0].upper()
    if name_without_ext in reserved_names:
        filename = f'_{filename}'
    
    # é™åˆ¶é•¿åº¦
    if len(filename) > max_length:
        # ä¿ç•™æ‰©å±•å
        name_parts = filename.rsplit('.', 1)
        if len(name_parts) == 2:
            name, ext = name_parts
            max_name_length = max_length - len(ext) - 1
            filename = f"{name[:max_name_length]}.{ext}"
        else:
            filename = filename[:max_length]
    
    # ç¡®ä¿ä¸ä¸ºç©º
    if not filename:
        filename = 'unnamed_file'
    
    return filename


def validate_date_range(start_date: str, 
                       end_date: str,
                       date_format: str = '%Y-%m-%d') -> Tuple[bool, str]:
    """
    éªŒè¯æ—¥æœŸèŒƒå›´
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        date_format: æ—¥æœŸæ ¼å¼
    
    Returns:
        (is_valid, message): éªŒè¯ç»“æœå’Œæ¶ˆæ¯
    """
    from datetime import datetime
    
    try:
        start = datetime.strptime(start_date, date_format)
        end = datetime.strptime(end_date, date_format)
        
        if start > end:
            return False, "å¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ"
        
        # æ£€æŸ¥æ—¥æœŸèŒƒå›´æ˜¯å¦åˆç†ï¼ˆä¾‹å¦‚ä¸è¶…è¿‡1å¹´ï¼‰
        delta = end - start
        if delta.days > 365:
            return False, "æ—¥æœŸèŒƒå›´ä¸èƒ½è¶…è¿‡1å¹´"
        
        return True, f"æ—¥æœŸèŒƒå›´æœ‰æ•ˆ: {delta.days} å¤©"
        
    except ValueError as e:
        return False, f"æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}"


def validate_config_file(config_path: Union[str, Path]) -> Tuple[bool, str, Dict[str, List[str]]]:
    """
    éªŒè¯é…ç½®æ–‡ä»¶
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    
    Returns:
        (is_valid, message, issues): éªŒè¯ç»“æœã€æ¶ˆæ¯å’Œé—®é¢˜è¯¦æƒ…
    """
    import configparser
    
    config_path = Path(config_path)
    issues = {'errors': [], 'warnings': []}
    
    if not config_path.exists():
        return False, f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}", issues
    
    try:
        config = configparser.ConfigParser()
        config.read(config_path)
        
        # æ£€æŸ¥å¿…éœ€çš„éƒ¨åˆ†
        required_sections = ['API_SETTINGS', 'MODEL_SETTINGS', 'FILE_SETTINGS']
        for section in required_sections:
            if section not in config:
                issues['errors'].append(f"ç¼ºå°‘å¿…éœ€çš„é…ç½®éƒ¨åˆ†: [{section}]")
        
        # æ£€æŸ¥APIè®¾ç½®
        if 'API_SETTINGS' in config:
            if config.getboolean('API_SETTINGS', 'use_internal_api_key', fallback=False):
                api_key_file = config.get('API_SETTINGS', 'api_key_file', fallback='')
                if not api_key_file:
                    issues['errors'].append("ä½¿ç”¨å†…éƒ¨APIå¯†é’¥ä½†æœªæŒ‡å®šå¯†é’¥æ–‡ä»¶")
        
        # æ£€æŸ¥æ–‡ä»¶è®¾ç½®
        if 'FILE_SETTINGS' in config:
            max_size = config.getint('FILE_SETTINGS', 'max_file_size_mb', fallback=0)
            if max_size <= 0:
                issues['warnings'].append("æœªè®¾ç½®æœ‰æ•ˆçš„æœ€å¤§æ–‡ä»¶å¤§å°é™åˆ¶")
        
        if issues['errors']:
            return False, "é…ç½®æ–‡ä»¶æœ‰é”™è¯¯", issues
        elif issues['warnings']:
            return True, "é…ç½®æ–‡ä»¶æœ‰æ•ˆä½†æœ‰è­¦å‘Š", issues
        else:
            return True, "é…ç½®æ–‡ä»¶å®Œå…¨æœ‰æ•ˆ", issues
        
    except Exception as e:
        issues['errors'].append(f"é…ç½®æ–‡ä»¶è§£æé”™è¯¯: {str(e)}")
        return False, "é…ç½®æ–‡ä»¶è§£æå¤±è´¥", issues
